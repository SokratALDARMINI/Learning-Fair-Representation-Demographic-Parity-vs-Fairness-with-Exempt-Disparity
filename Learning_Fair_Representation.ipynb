{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Fair Representation: Demographic Parity vs Exempt and Non-Exempt Disparity Notations\n",
        "\n",
        "This project has been build on top of the implementation code of the Learning Adversarially Fair and Transferable Representations paper ([project link](https://github.com/VectorInstitute/laftr/tree/master)). However, we have included the following modifications:\n",
        "\n",
        "1. We modified the main files so that one can directly specify which type of experiment (Demographic Parity or Non-exempt Disparity experiment) from the terminal input.\n",
        "2. We modified the trainer object to provide a plot of the training losses at the end of the training in the experiment file.\n",
        "3. We modified the dataset loader to take into account the existence of the feature xc for the Non-exempt Disparity experiment.\n",
        "4. We created a new trainer function for the trainer object to take into account the existence of the feature xc for training.\n",
        "5. We modified the tester to evaluate the Non-exempt Disparity measure.\n",
        "6. We created a new model class inspired by the model class \"WeightedEqoddsWassGan\" and called it \"WeightedEqoddsWassGanNEW,\" which considers the feature xc as an input to the adversary. (This also included the creation of new parent model classes for the model WeightedEqoddsWassGanNEW.)\n",
        "7. Added new configuration files of type .json that contains specifications about the dataset ACSIncome and the training specifications.\n",
        "For more details, please see ([Project repository](https://github.com/VectorInstitute/laftr/tree/master))."
      ],
      "metadata": {
        "id": "zisgSgxUSgGn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uqUHgp6ySd33",
        "outputId": "ea018f78-9a0f-4c80-80ff-4b35b56e0fe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Representation_Learning'...\n",
            "remote: Enumerating objects: 89, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 89 (delta 9), reused 86 (delta 9), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (89/89), 1.18 MiB | 972.00 KiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "/content/Representation_Learning\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "token = 'git@github.com:SokratALDARMINI/Learning-Fair-Representation-Demographic-Parity-vs-Fairness-with-Exempt-Disparity.git'\n",
        "!git clone https://{token}@github.com/SokratALDARMINI/Representation_Learning.git\n",
        "\n",
        "# Change directory to the repository\n",
        "%cd Representation_Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*italicized text*# Dataset preparation\n",
        "## Adult Dataset (This section can be neglected)\n",
        "To run the code, the datasets have to be placed in the correct directories. **It is worth notting that the Adult datasets is already included inside the project files, and one can neglect the next three cells.** Adult dataset exists in: /content/Representation_Learning/data/adult/."
      ],
      "metadata": {
        "id": "Bv2DkJImSoP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Change directory to the dataset directoy\n",
        "%cd /content/Representation_Learning/data/adult/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6ZUIoRuYSnTG",
        "outputId": "4cdd29fc-08f7-412b-dee7-4b4102e5d8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Representation_Learning/data/adult\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset cloning"
      ],
      "metadata": {
        "id": "DaBiHw0US2KM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
        "column_names = [\n",
        "    'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
        "    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'\n",
        "]\n",
        "\n",
        "# Read the dataset without headers\n",
        "adult_data = pd.read_csv(url, names=column_names, header=None)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "train_data, test_data = train_test_split(adult_data, test_size=0.2, random_state=42)\n",
        "print(adult_data.shape)\n",
        "\n",
        "# Save the datasets without headers\n",
        "train_data.to_csv('adult.data', index=False, header=False)\n",
        "test_data.to_csv('adult.test', index=False, header=False)\n",
        "\n",
        "# # Print the first few rows of each dataset to verify\n",
        "# print(\"Training Data:\")\n",
        "# print(train_data.head())\n",
        "# print(\"\\nTest Data:\")\n",
        "# print(test_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZTUiwwruStcF",
        "outputId": "3949d0f4-f008-44c3-c112-aa8ab7c2edda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32561, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset preprocessing: Project expect files of type .npz\n"
      ],
      "metadata": {
        "id": "KTol0DMPS5BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "# Define a small epsilon to prevent division by zero\n",
        "EPS = 1e-8\n",
        "\n",
        "# Function to bucketize a value based on given bucket thresholds\n",
        "def bucket(x, buckets):\n",
        "    x = float(x)\n",
        "    n = len(buckets)\n",
        "    label = n\n",
        "    for i in range(len(buckets)):\n",
        "        if x <= buckets[i]:\n",
        "            label = i\n",
        "            break\n",
        "    template = [0. for j in range(n + 1)]\n",
        "    template[label] = 1.\n",
        "    return template\n",
        "\n",
        "# Function to one-hot encode a value based on given choices\n",
        "def onehot(x, choices):\n",
        "    if not x in choices:\n",
        "        print('could not find \"{}\" in choices'.format(x))\n",
        "        print(choices)\n",
        "        raise Exception()\n",
        "    label = choices.index(x)\n",
        "    template = [0. for j in range(len(choices))]\n",
        "    template[label] = 1.\n",
        "    return template\n",
        "\n",
        "# Function to return a value as a continuous float\n",
        "def continuous(x):\n",
        "    return [float(x)]\n",
        "\n",
        "# Function to parse a row of data and return the processed features, label, and sensitive attribute\n",
        "def parse_row(row, headers, headers_use):\n",
        "    new_row_dict = {}\n",
        "    for i in range(len(row)):\n",
        "        x = row[i]\n",
        "        hdr = headers[i]\n",
        "        new_row_dict[hdr] = fns[hdr](x)\n",
        "\n",
        "    sens_att = new_row_dict[sensitive]\n",
        "    label = new_row_dict[target]\n",
        "    new_row = []\n",
        "\n",
        "    for h in headers_use:\n",
        "        new_row = new_row + new_row_dict[h]\n",
        "    return new_row, label, sens_att\n",
        "\n",
        "# Function to standardize (whiten) the data by subtracting the mean and dividing by the standard deviation\n",
        "def whiten(X, mn, std):\n",
        "    mntile = np.tile(mn, (X.shape[0], 1))\n",
        "    stdtile = np.maximum(np.tile(std, (X.shape[0], 1)), EPS)\n",
        "    X = X - mntile\n",
        "    X = np.divide(X, stdtile)\n",
        "    return X\n",
        "\n",
        "# Main function to process the dataset\n",
        "if __name__ == '__main__':\n",
        "    f_in_tr = 'adult.data'\n",
        "    f_in_te = 'adult.test'\n",
        "\n",
        "    f_out_np = 'adult.npz'\n",
        "    hd_file = 'adult.headers'\n",
        "    f_out_csv = 'adult.csv'\n",
        "\n",
        "    header_list = open(hd_file, 'w')\n",
        "\n",
        "    REMOVE_MISSING = True\n",
        "    MISSING_TOKEN = '?'\n",
        "\n",
        "    # Define headers and columns to use\n",
        "    headers = 'age,workclass,fnlwgt,education,education-num,marital-status,occupation,relationship,race,sex,capital-gain,capital-loss,hours-per-week,native-country,income'.split(',')\n",
        "    headers_use = 'age,workclass,education,education-num,marital-status,occupation,relationship,race,capital-gain,capital-loss,hours-per-week,native-country'.split(',')\n",
        "    target = 'income'\n",
        "    sensitive = 'sex'\n",
        "\n",
        "    # Define processing options for each feature\n",
        "    options = {\n",
        "        'age': 'buckets',\n",
        "        'workclass': 'Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked',\n",
        "        'fnlwgt': 'continuous',\n",
        "        'education': 'Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool',\n",
        "        'education-num': 'continuous',\n",
        "        'marital-status': 'Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse',\n",
        "        'occupation': 'Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces',\n",
        "        'relationship': 'Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried',\n",
        "        'race': 'White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black',\n",
        "        'sex': 'Female, Male',\n",
        "        'capital-gain': 'continuous',\n",
        "        'capital-loss': 'continuous',\n",
        "        'hours-per-week': 'continuous',\n",
        "        'native-country': 'United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands',\n",
        "        'income': ' <=50K,>50K'\n",
        "    }\n",
        "\n",
        "    # Define bucket thresholds for age\n",
        "    buckets = {'age': [18, 25, 30, 35, 40 ,45, 50, 55, 60, 65]}\n",
        "\n",
        "    # Process options into sorted lists\n",
        "    options = {k: [s.strip() for s in sorted(options[k].split(','))] for k in options}\n",
        "\n",
        "    # Define processing functions for each feature\n",
        "    fns = {\n",
        "        'age': lambda x: bucket(x, buckets['age']),\n",
        "        'workclass': lambda x: onehot(x, options['workclass']),\n",
        "        'fnlwgt': lambda x: continuous(x),\n",
        "        'education': lambda x: onehot(x, options['education']),\n",
        "        'education-num': lambda x: continuous(x),\n",
        "        'marital-status': lambda x: onehot(x, options['marital-status']),\n",
        "        'occupation': lambda x: onehot(x, options['occupation']),\n",
        "        'relationship': lambda x: onehot(x, options['relationship']),\n",
        "        'race': lambda x: onehot(x, options['race']),\n",
        "        'sex': lambda x: onehot(x, options['sex']),\n",
        "        'capital-gain': lambda x: continuous(x),\n",
        "        'capital-loss': lambda x: continuous(x),\n",
        "        'hours-per-week': lambda x: continuous(x),\n",
        "        'native-country': lambda x: onehot(x, options['native-country']),\n",
        "        'income': lambda x: onehot(x.strip('.'), options['income']),\n",
        "    }\n",
        "\n",
        "    D = {}\n",
        "    for f, phase in [(f_in_tr, 'training'), (f_in_te, 'test')]:\n",
        "        dat = [s.strip().split(',') for s in open(f, 'r').readlines()]\n",
        "\n",
        "        X = []\n",
        "        Y = []\n",
        "        A = []\n",
        "        print(phase)\n",
        "\n",
        "        for r in dat:\n",
        "            row = [s.strip() for s in r]\n",
        "            if MISSING_TOKEN in row and REMOVE_MISSING:\n",
        "                continue\n",
        "            if row in ([''], ['|1x3 Cross validator']):\n",
        "                continue\n",
        "            newrow, label, sens_att = parse_row(row, headers, headers_use)\n",
        "            X.append(newrow)\n",
        "            Y.append(label)\n",
        "            A.append(sens_att)\n",
        "\n",
        "        npX = np.array(X)\n",
        "        npY = np.array(Y)\n",
        "        npA = np.array(A)\n",
        "        npA = np.expand_dims(npA[:, 1], 1)\n",
        "\n",
        "        D[phase] = {}\n",
        "        D[phase]['X'] = npX\n",
        "        D[phase]['Y'] = npY\n",
        "        D[phase]['A'] = npA\n",
        "\n",
        "        print(npX.shape)\n",
        "        print(npY.shape)\n",
        "        print(npA.shape)\n",
        "\n",
        "    # Standardize the data\n",
        "    mn = np.mean(D['training']['X'], axis=0)\n",
        "    std = np.std(D['training']['X'], axis=0)\n",
        "\n",
        "    D['training']['X'] = whiten(D['training']['X'], mn, std)\n",
        "    D['test']['X'] = whiten(D['test']['X'], mn, std)\n",
        "\n",
        "    # Write headers to file\n",
        "    f = open(hd_file, 'w')\n",
        "    i = 0\n",
        "    for h in headers_use:\n",
        "        if options[h] == 'continuous':\n",
        "            f.write('{:d},{}\\n'.format(i, h))\n",
        "            i += 1\n",
        "        elif options[h][0] == 'buckets':\n",
        "            for b in buckets[h]:\n",
        "                colname = '{}_{:d}'.format(h, b)\n",
        "                f.write('{:d},{}\\n'.format(i, colname))\n",
        "                i += 1\n",
        "        else:\n",
        "            for opt in options[h]:\n",
        "                colname = '{}_{}'.format(h, opt)\n",
        "                f.write('{:d},{}\\n'.format(i, colname))\n",
        "                i += 1\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    n = D['training']['X'].shape[0]\n",
        "    shuf = np.random.permutation(n)\n",
        "    valid_pct = 0.2\n",
        "    valid_ct = int(n * valid_pct)\n",
        "    valid_inds = shuf[:valid_ct]\n",
        "    train_inds = shuf[valid_ct:]\n",
        "\n",
        "    # Save processed data to .npz file\n",
        "    np.savez(f_out_np, x_train=D['training']['X'], x_test=D['test']['X'],\n",
        "             y_train=D['training']['Y'], y_test=D['test']['Y'],\n",
        "             attr_train=D['training']['A'], attr_test=D['test']['A'],\n",
        "             train_inds=train_inds, valid_inds=valid_inds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u-tMQUjVV2_e",
        "outputId": "dd23493c-70e0-45b1-91a4-660380b228ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training\n",
            "(24157, 112)\n",
            "(24157, 2)\n",
            "(24157, 1)\n",
            "test\n",
            "(6005, 112)\n",
            "(6005, 2)\n",
            "(6005, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ACSIncome Dataset (This section can not be neglected)\n",
        "**This section can not be neglected as the ACS Income data set is not included in the repository due to its huge size.**"
      ],
      "metadata": {
        "id": "zVf5R2SNTPp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory for the ACSIncome dataset.\n",
        "%cd /content/Representation_Learning/data/\n",
        "!mkdir ACSIncome\n",
        "%cd ACSIncome"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fAEuSYQoTJBt",
        "outputId": "df2432e8-257b-4a4a-a18d-ee1f75aba40f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Representation_Learning/data\n",
            "/content/Representation_Learning/data/ACSIncome\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install folktables package. See https://github.com/socialfoundations/folktables/tree/main for more details about the usage of the folktable datasets\n",
        "!pip install folktables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "P9UBSmguTUxd",
        "outputId": "01ef4127-7ea3-4946-e2f3-9f68e5de8b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting folktables\n",
            "  Downloading folktables-0.0.12-py3-none-any.whl.metadata (533 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from folktables) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from folktables) (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from folktables) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from folktables) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->folktables) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->folktables) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->folktables) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->folktables) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->folktables) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->folktables) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->folktables) (2024.8.30)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->folktables) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->folktables) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->folktables) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->folktables) (1.16.0)\n",
            "Downloading folktables-0.0.12-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: folktables\n",
            "Successfully installed folktables-0.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get ACSDataSource dataset for Michigan state"
      ],
      "metadata": {
        "id": "n7fbUf-OToMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from folktables import ACSDataSource, ACSIncome, ACSPublicCoverage, ACSMobility, ACSEmployment, ACSTravelTime\n",
        "from folktables import generate_categories\n",
        "import math\n",
        "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
        "acs_data = data_source.get_data(states = ['MI'], download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6Zi1_LqPTb4N",
        "outputId": "d4928851-1af5-471a-8fc6-a305cf913af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for 2018 1-Year person survey for MI...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define new filtering task to filter to create the ACSIncome dataset."
      ],
      "metadata": {
        "id": "-nM0IVOOT2z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from folktables import BasicProblem\n",
        "from folktables import acs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "def target_fun(v):\n",
        "    v [ACSIncome.target]= v[ACSIncome.target]>50000\n",
        "    v [ACSEmployment.target]= v[ACSEmployment.target]==1\n",
        "    return v\n",
        "\n",
        "New_Task = BasicProblem(\n",
        "    features= ACSIncome.features +[ACSIncome.target],\n",
        "    target= ACSIncome.target,\n",
        "    target_transform=lambda x: x > 50000,\n",
        "    group='SEX',\n",
        "    preprocess=acs.adult_filter,\n",
        ")\n",
        "\n",
        "df = New_Task.df_to_pandas(acs_data)\n",
        "# print('Number of missing values for each attribute')\n",
        "# print(df[0].isna().sum())\n",
        "# print('DataFrame shape')\n",
        "# print(df[0].shape)\n",
        "data_frame = df[0]\n",
        "data_frame[ACSIncome.target] = data_frame[ACSIncome.target].apply(lambda x: x>50000)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(data_frame, test_size=0.2, random_state=42)\n",
        "train_df.to_csv('new_dataset.data', index=False, header=False)\n",
        "test_df.to_csv('new_dataset.test', index=False, header=False)"
      ],
      "metadata": {
        "id": "7NAJ3Do7VI79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get categories defintions"
      ],
      "metadata": {
        "id": "y75sGQogVLZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from folktables import generate_categories\n",
        "import math\n",
        "definition_df = data_source.get_definitions(download=True)\n",
        "categories = generate_categories(features=New_Task.features, definition_df=definition_df)\n",
        "print(categories['SCHL'].keys())\n",
        "print(data_frame.columns.values.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vqxB9rPVOS-",
        "outputId": "09335935-331c-41e1-a4e2-e26d2e7992f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, nan])\n",
            "['AGEP', 'COW', 'SCHL', 'MAR', 'OCCP', 'POBP', 'RELP', 'WKHP', 'SEX', 'RAC1P', 'PINCP']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset preprocessing"
      ],
      "metadata": {
        "id": "CAVFFSe0VUQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is a similar version of the one for the Adult dataset, with modifictioan related to the name of the features and the categories.\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "# make noNULL file with: grep -v NULL rawdata_mkmk01.csv | cut -f1,3,4,6- -d, > rawdata_mkmk01_noNULL.csv\n",
        "EPS = 1e-8\n",
        "#### LOOK AT THIS FUNCTION!!!! GETTING STD = 0\n",
        "def bucket(x, buckets):\n",
        "    x = float(x)\n",
        "    n = len(buckets)\n",
        "    label = n\n",
        "    for i in range(len(buckets)):\n",
        "        if x <= buckets[i]:\n",
        "            label = i\n",
        "            break\n",
        "    template = [0. for j in range(n + 1)]\n",
        "    template[label] = 1.\n",
        "    return template\n",
        "\n",
        "def onehot(x, choices):\n",
        "    # g = False\n",
        "    # print('First',x)\n",
        "    try:\n",
        "      x = float(x)\n",
        "      # print('is numeric')\n",
        "    except:\n",
        "      x = (x == 'True')\n",
        "      # print('is not numeric')\n",
        "      # print('Second',x)\n",
        "      # g = True\n",
        "    # print('x=',x)\n",
        "    if not x in choices:\n",
        "        print('could not find \"{}\" in choices'.format(x))\n",
        "        print(choices)\n",
        "        print(type(choices))\n",
        "        print(type(x))\n",
        "        raise Exception()\n",
        "    label = choices.index(x)\n",
        "    # if g:\n",
        "      # print(choices)\n",
        "      # print(label)\n",
        "    template = [0. for j in range(len(choices))]\n",
        "    template[label] = 1.\n",
        "    return template\n",
        "\n",
        "def continuous(x):\n",
        "    return [float(x)]\n",
        "\n",
        "\n",
        "def parse_row(row, headers, headers_use):\n",
        "    new_row_dict = {}\n",
        "    # print(headers)\n",
        "    # print(row)\n",
        "    for i in range(len(row)):\n",
        "        x = row[i]\n",
        "        hdr = headers[i]\n",
        "        # print('hdr=',hdr)\n",
        "        # print('x=',x)\n",
        "        new_row_dict[hdr] = funs[hdr](x)\n",
        "    sens_att = new_row_dict[sensitive]\n",
        "    label = new_row_dict[target]\n",
        "    # print(label)\n",
        "    new_row = []\n",
        "    for h in headers_use:\n",
        "        new_row = new_row + new_row_dict[h]\n",
        "        # if h =='SCHL':\n",
        "          #  print(len(new_row))\n",
        "    return new_row, label, sens_att\n",
        "\n",
        "def whiten(X, mn, std):\n",
        "    mntile = np.tile(mn, (X.shape[0], 1))\n",
        "    stdtile = np.maximum(np.tile(std, (X.shape[0], 1)), EPS)\n",
        "    X = X - mntile\n",
        "    X = np.divide(X, stdtile)\n",
        "    return X\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    f_in_tr = 'new_dataset.data'\n",
        "    f_in_te = 'new_dataset.test'\n",
        "\n",
        "    f_out_np = 'ACSIncome.npz'\n",
        "    hd_file = 'ACSIncome.headers'\n",
        "    f_out_csv = 'ACSIncome.csv'\n",
        "\n",
        "    header_list = open(hd_file, 'w')\n",
        "\n",
        "    REMOVE_MISSING = True\n",
        "    MISSING_TOKEN = '-1'\n",
        "\n",
        "    headers =  data_frame.columns.values.tolist()\n",
        "    headers_use = [item for item in headers if item != ACSIncome.target and item != 'SEX']\n",
        "    target = ACSIncome.target\n",
        "    sensitive = 'SEX'\n",
        "    #['MIG', 'DIS', 'ANC', 'ESP', 'DEYE', 'NATIVITY', 'SCHL', 'AGEP', 'MAR', 'POBP', 'CIT', 'DEAR', 'COW', 'OCCP', 'MIL', 'DREM', 'WKHP', 'RAC1P', 'RELP', 'SEX', 'PINCP', 'ESR']\n",
        "    # WKHP\n",
        "    options = {\n",
        "        'AGEP': 'continuous',\n",
        "        'WKHP': 'continuous',\n",
        "        'SCHL': 'Continuous',\n",
        "        'COW': [x for x in categories['COW'].keys() if not math.isnan(x)],\n",
        "        'POBP': [x for x in categories['POBP'].keys() if not math.isnan(x)],\n",
        "        'MAR': [x for x in categories['MAR'].keys() if not math.isnan(x)],\n",
        "        'OCCP': [x for x in categories['OCCP'].keys() if not math.isnan(x)],\n",
        "        'RELP': [x for x in categories['RELP'].keys() if not math.isnan(x)],\n",
        "        'RAC1P': [x for x in categories['RAC1P'].keys() if not math.isnan(x)],\n",
        "        'SEX': [x for x in categories['SEX'].keys() if not math.isnan(x)],\n",
        "        ACSIncome.target: [False, True]\n",
        "    }\n",
        "\n",
        "    buckets = {'age': [18, 25, 30, 35, 40 ,45, 50, 55, 60, 65]}\n",
        "\n",
        "    # options = {k: [s.strip() for s in sorted(options[k].split(','))] for k in options}\n",
        "    #['MIG', 'DIS', 'ANC', 'ESP', 'DEYE', 'NATIVITY', 'SCHL', 'AGEP', 'MAR', 'POBP', 'CIT', 'DEAR', 'COW', 'OCCP', 'MIL', 'DREM', 'WKHP', 'RAC1P', 'RELP', 'SEX', 'PINCP', 'ESR']\n",
        "\n",
        "    funs ={\n",
        "        'AGEP': lambda x: continuous(x),\n",
        "        'WKHP': lambda x: continuous(x),\n",
        "        'SCHL': lambda x: continuous(x),\n",
        "        'COW': lambda x: onehot(x, options['COW']),\n",
        "        'POBP': lambda x: onehot(x, options['POBP']),\n",
        "        'MAR': lambda x: onehot(x, options['MAR']),\n",
        "        'OCCP': lambda x: onehot(x, options['OCCP']),\n",
        "        'RELP': lambda x: onehot(x, options['RELP']),\n",
        "        'RAC1P': lambda x: onehot(x, options['RAC1P']),\n",
        "        'SEX': lambda x: onehot(x, options['SEX']),\n",
        "        ACSIncome.target: lambda x: onehot(x, options[ACSIncome.target])\n",
        "    }\n",
        "\n",
        "    D = {}\n",
        "    for f, phase in [(f_in_tr, 'training'), (f_in_te, 'test')]:\n",
        "        dat = [s.strip().split(',') for s in open(f, 'r').readlines()]\n",
        "\n",
        "        X = []\n",
        "        Y = []\n",
        "        A = []\n",
        "        print(phase)\n",
        "\n",
        "        for r in dat:\n",
        "            row = [s.strip() for s in r]\n",
        "            # print(row)\n",
        "            # print(headers)\n",
        "            # print(headers_use)\n",
        "            if MISSING_TOKEN in row and REMOVE_MISSING:\n",
        "                continue\n",
        "            if row in ([''], ['|1x3 Cross validator']):\n",
        "                continue\n",
        "            newrow, label, sens_att = parse_row(row, headers, headers_use)\n",
        "            X.append(newrow)\n",
        "            Y.append(label)\n",
        "            A.append(sens_att)\n",
        "\n",
        "        npX = np.array(X)\n",
        "        npY = np.array(Y)\n",
        "        npA = np.array(A)\n",
        "        npA = np.expand_dims(npA[:,1], 1)\n",
        "\n",
        "        D[phase] = {}\n",
        "        D[phase]['X'] = npX\n",
        "        D[phase]['Y'] = npY\n",
        "        D[phase]['A'] = npA\n",
        "\n",
        "        print(npX.shape)\n",
        "        print(npY.shape)\n",
        "        print(npA.shape)\n",
        "\n",
        "    #should do normalization and centring\n",
        "    mn = np.mean(D['training']['X'], axis=0)\n",
        "    std = np.std(D['training']['X'], axis=0)\n",
        "    print(mn, std)\n",
        "    D['training']['X'] = whiten(D['training']['X'], mn, std)\n",
        "    D['test']['X'] = whiten(D['test']['X'], mn, std)\n",
        "\n",
        "    #should write headers file\n",
        "    f = open(hd_file, 'w')\n",
        "    i = 0\n",
        "    for h in headers_use:\n",
        "        if options[h] == 'continuous':\n",
        "            f.write('{:d},{}\\n'.format(i, h))\n",
        "            i += 1\n",
        "        elif options[h][0] == 'buckets':\n",
        "            for b in buckets[h]:\n",
        "                colname = '{}_{:d}'.format(h, b)\n",
        "                f.write('{:d},{}\\n'.format(i, colname))\n",
        "                i += 1\n",
        "        else:\n",
        "            for opt in options[h]:\n",
        "                colname = '{}_{}'.format(h, opt)\n",
        "                f.write('{:d},{}\\n'.format(i, colname))\n",
        "                i += 1\n",
        "\n",
        "    n = D['training']['X'].shape[0]\n",
        "    shuf = np.random.permutation(n)\n",
        "    valid_pct = 0.2\n",
        "    valid_ct = int(n * valid_pct)\n",
        "    valid_inds = shuf[:valid_ct]\n",
        "    train_inds = shuf[valid_ct:]\n",
        "\n",
        "    np.savez(f_out_np, x_train=D['training']['X'], x_test=D['test']['X'],\n",
        "                y_train=D['training']['Y'], y_test=D['test']['Y'],\n",
        "                attr_train=D['training']['A'], attr_test=D['test']['A'],\n",
        "             train_inds=train_inds, valid_inds=valid_inds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "RXihQvRTTrDD",
        "outputId": "a97de950-7f79-49ed-9e35-7acee3f66333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3255.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 6260.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8990.0\n",
            "First 53.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6260.0\n",
            "First 303.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 10.0\n",
            "First 13.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 750.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 9122.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 6250.0\n",
            "First 39.0\n",
            "First 13.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1450.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7925.0\n",
            "First 26.0\n",
            "First 10.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 2014.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3090.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9130.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4720.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6825.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 2640.0\n",
            "First 17.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 5840.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 7750.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 3.0\n",
            "First 2205.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 3255.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 3647.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4720.0\n",
            "First 26.0\n",
            "First 7.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4220.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5240.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 800.0\n",
            "First 39.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 350.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 8990.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 800.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5240.0\n",
            "First 36.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 4.0\n",
            "First 4140.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 5120.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 5.0\n",
            "First 4020.0\n",
            "First 12.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 1105.0\n",
            "First 39.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6230.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4110.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 4.0\n",
            "First 1.0\n",
            "First 110.0\n",
            "First 55.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 5.0\n",
            "First 1.0\n",
            "First 5250.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 3500.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 9130.0\n",
            "First 26.0\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 9141.0\n",
            "First 210.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 138.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1460.0\n",
            "First 240.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 6.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 9620.0\n",
            "First 223.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 6.0\n",
            "First False\n",
            "First 3.0\n",
            "First 3.0\n",
            "First 3602.0\n",
            "First 18.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 9130.0\n",
            "First 55.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 6.0\n",
            "First 5.0\n",
            "First 4055.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8740.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 205.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9130.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 4000.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4150.0\n",
            "First 26.0\n",
            "First 17.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 120.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 1460.0\n",
            "First 48.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 2640.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9600.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 6260.0\n",
            "First 128.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 205.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 2440.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6520.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 39.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 4.0\n",
            "First 3.0\n",
            "First 2310.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 9645.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1010.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4400.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4030.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7200.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 800.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4700.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3424.0\n",
            "First 36.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 5.0\n",
            "First 2310.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6442.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 5810.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 10.0\n",
            "First 301.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 6040.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4020.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 9645.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 9130.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1650.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 9645.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4020.0\n",
            "First 303.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 4.0\n",
            "First 5.0\n",
            "First 4020.0\n",
            "First 26.0\n",
            "First 16.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 20.0\n",
            "First 26.0\n",
            "First 9.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3646.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 3160.0\n",
            "First 210.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 6.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 1555.0\n",
            "First 242.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 6.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 9130.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 2360.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 205.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5120.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6230.0\n",
            "First 303.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5860.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 7330.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 8225.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 5.0\n",
            "First 6240.0\n",
            "First 26.0\n",
            "First 12.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 5.0\n",
            "First 4220.0\n",
            "First 36.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 31.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4720.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 8.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 6230.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 630.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5600.0\n",
            "First 39.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4760.0\n",
            "First 8.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 1555.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4700.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 2100.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 3.0\n",
            "First 5710.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 8740.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7750.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7700.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4760.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 230.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 4.0\n",
            "First 5740.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 52.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6442.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 6260.0\n",
            "First 26.0\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7220.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4720.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1860.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3090.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 4.0\n",
            "First 1.0\n",
            "First 2310.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 102.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 3255.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 7315.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 5940.0\n",
            "First 48.0\n",
            "First 6.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 1460.0\n",
            "First 12.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 7.0\n",
            "First 5.0\n",
            "First 51.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 2545.0\n",
            "First 20.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 8225.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 3655.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3255.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 4220.0\n",
            "First 213.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4500.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 530.0\n",
            "First 5.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 2100.0\n",
            "First 18.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 3150.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4720.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1430.0\n",
            "First 210.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 6.0\n",
            "First True\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 3255.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 7750.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4621.0\n",
            "First 36.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7750.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 5000.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 20.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 9130.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4251.0\n",
            "First 6.0\n",
            "First 5.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7720.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9620.0\n",
            "First 303.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7925.0\n",
            "First 303.0\n",
            "First 5.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 5240.0\n",
            "First 25.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 2002.0\n",
            "First 26.0\n",
            "First 15.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 2640.0\n",
            "First 210.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 6.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 6305.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7315.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 6260.0\n",
            "First 26.0\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4340.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 3255.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5740.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 5300.0\n",
            "First 26.0\n",
            "First 7.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 7.0\n",
            "First 3.0\n",
            "First 2910.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 5240.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4600.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 9620.0\n",
            "First 55.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 8990.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 6130.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 8990.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 5.0\n",
            "First 2905.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4030.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 7700.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 3.0\n",
            "First 5.0\n",
            "First 6050.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 8.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4330.0\n",
            "First 51.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7750.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8650.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7925.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4700.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7640.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7750.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4700.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 6305.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4930.0\n",
            "First 39.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 39.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4920.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4110.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 350.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4030.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 5920.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 2360.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 4700.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3255.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 4510.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4720.0\n",
            "First 248.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 5.0\n",
            "First 4020.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 20.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 230.0\n",
            "First 37.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4850.0\n",
            "First 18.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 2002.0\n",
            "First 48.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4840.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 4.0\n",
            "First 1.0\n",
            "First 3603.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4760.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5820.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 102.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 5320.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4720.0\n",
            "First 202.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 6.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 6410.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 4350.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 3930.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3256.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 4.0\n",
            "First 20.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 1460.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 6.0\n",
            "First 5.0\n",
            "First 4760.0\n",
            "First 329.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 8.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 5940.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 137.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 3230.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 2040.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4965.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4110.0\n",
            "First 26.0\n",
            "First 5.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 4965.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4700.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 4700.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4110.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7220.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 5000.0\n",
            "First 26.0\n",
            "First 12.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4720.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1021.0\n",
            "First 210.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 6.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4140.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 52.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 5110.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9610.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9620.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 3.0\n",
            "First 3515.0\n",
            "First 17.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 5400.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 2310.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 530.0\n",
            "First 49.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4710.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4760.0\n",
            "First 26.0\n",
            "First 3.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 2100.0\n",
            "First 55.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 220.0\n",
            "First 27.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 6.0\n",
            "First 5.0\n",
            "First 4220.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 9.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 5740.0\n",
            "First 26.0\n",
            "First 5.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7700.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4020.0\n",
            "First 26.0\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4220.0\n",
            "First 26.0\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5240.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 8800.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 5.0\n",
            "First 6260.0\n",
            "First 26.0\n",
            "First 15.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5720.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7640.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7315.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4020.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 2.0\n",
            "First 3.0\n",
            "First 5820.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4110.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1021.0\n",
            "First 362.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5160.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 4.0\n",
            "First 1.0\n",
            "First 2310.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 1900.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4700.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 2350.0\n",
            "First 36.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 9.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6200.0\n",
            "First 39.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 5000.0\n",
            "First 36.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 5.0\n",
            "First 3960.0\n",
            "First 26.0\n",
            "First 17.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 5240.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4240.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3645.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 735.0\n",
            "First 303.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 6442.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 5.0\n",
            "First 2310.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4000.0\n",
            "First 110.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4020.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 3930.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 26.0\n",
            "First 5.0\n",
            "First 2.0\n",
            "First 3.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3630.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5000.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 7700.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 3601.0\n",
            "First 39.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 1360.0\n",
            "First 213.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 3515.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 3010.0\n",
            "First 301.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 20.0\n",
            "First 224.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 440.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6355.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 350.0\n",
            "First 210.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 6.0\n",
            "First True\n",
            "First 2.0\n",
            "First 5.0\n",
            "First 1050.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4120.0\n",
            "First 36.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 5810.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 5240.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9130.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 9645.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 1108.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 4.0\n",
            "First 1.0\n",
            "First 3750.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7200.0\n",
            "First 36.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 3255.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3421.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4720.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 750.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 2320.0\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9130.0\n",
            "First 22.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 3.0\n",
            "First 2060.0\n",
            "First 42.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4760.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 4.0\n",
            "First 5.0\n",
            "First 845.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 5.0\n",
            "First 9121.0\n",
            "First 18.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3322.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 9130.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7750.0\n",
            "First 33.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 3050.0\n",
            "First 21.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 5.0\n",
            "First 1.0\n",
            "First 3090.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 3603.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1320.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6305.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 4.0\n",
            "First 3255.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 9130.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4030.0\n",
            "First 18.0\n",
            "First 12.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 3.0\n",
            "First 440.0\n",
            "First 110.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 3.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1010.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7750.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First True\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 2545.0\n",
            "First 27.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5710.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 3.0\n",
            "First 5.0\n",
            "First 4030.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8650.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3255.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9130.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1430.0\n",
            "First 210.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 6.0\n",
            "First True\n",
            "First 8.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6260.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 1430.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8740.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4850.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 9620.0\n",
            "First 6.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 630.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 4251.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3090.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4720.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 750.0\n",
            "First 26.0\n",
            "First 17.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4720.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 4.0\n",
            "First 3.0\n",
            "First 2310.0\n",
            "First 440.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8130.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 5350.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4251.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4220.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3300.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4110.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4030.0\n",
            "First 36.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 5.0\n",
            "First 1.0\n",
            "First 820.0\n",
            "First 26.0\n",
            "First 15.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 5740.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 3.0\n",
            "First 5.0\n",
            "First 9620.0\n",
            "First 26.0\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 10.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 3.0\n",
            "First 850.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 800.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1360.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8990.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First True\n",
            "First 1.0\n",
            "First 4.0\n",
            "First 6260.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5740.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 2320.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6410.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 750.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 3323.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 120.0\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 6355.0\n",
            "First 26.0\n",
            "First 17.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4030.0\n",
            "First 26.0\n",
            "First 5.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 20.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 4700.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1541.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 8.0\n",
            "First 5.0\n",
            "First 4251.0\n",
            "First 42.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4965.0\n",
            "First 21.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 9620.0\n",
            "First 26.0\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 5240.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 5610.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4760.0\n",
            "First 26.0\n",
            "First 12.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 5.0\n",
            "First 9640.0\n",
            "First 26.0\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 700.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 2310.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4810.0\n",
            "First 42.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4510.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4110.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 2545.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5260.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5610.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 4.0\n",
            "First 1.0\n",
            "First 2310.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3230.0\n",
            "First 51.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 1750.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1305.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 2310.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4150.0\n",
            "First 26.0\n",
            "First 7.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6050.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4740.0\n",
            "First 26.0\n",
            "First 11.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9645.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4850.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 9142.0\n",
            "First 231.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6.0\n",
            "First False\n",
            "First 3.0\n",
            "First 3.0\n",
            "First 3802.0\n",
            "First 21.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 630.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 8810.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1106.0\n",
            "First 39.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1021.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 4220.0\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8720.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9130.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5260.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 2310.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 2752.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 5.0\n",
            "First 1.0\n",
            "First 5550.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 136.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 2631.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 360.0\n",
            "First 26.0\n",
            "First 9.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 5740.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3421.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7220.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7420.0\n",
            "First 39.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5000.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 5.0\n",
            "First 1.0\n",
            "First 5000.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4710.0\n",
            "First 213.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 4.0\n",
            "First 1.0\n",
            "First 5120.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1050.0\n",
            "First 8.0\n",
            "First 9.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1760.0\n",
            "First 210.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 6.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 7905.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 3255.0\n",
            "First 26.0\n",
            "First 12.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4760.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4700.0\n",
            "First 26.0\n",
            "First 5.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4020.0\n",
            "First 26.0\n",
            "First 11.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3255.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 5.0\n",
            "First 5.0\n",
            "First 4230.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 8.0\n",
            "First False\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 52.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 3.0\n",
            "First 5.0\n",
            "First 4710.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4600.0\n",
            "First 18.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 410.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 102.0\n",
            "First 6.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6355.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4760.0\n",
            "First 26.0\n",
            "First 4.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 4700.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 8610.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8140.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 110.0\n",
            "First 210.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 6.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4055.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4700.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4710.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4055.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4040.0\n",
            "First 303.0\n",
            "First 4.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 2014.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9600.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 6442.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4710.0\n",
            "First 39.0\n",
            "First 13.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 9620.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6355.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4760.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8140.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1021.0\n",
            "First 39.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 5240.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 9.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 9600.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8740.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1005.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 4.0\n",
            "First 3500.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4700.0\n",
            "First 55.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 9130.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First False\n",
            "First 7.0\n",
            "First 3.0\n",
            "First 4760.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7330.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9600.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3602.0\n",
            "First 53.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 5120.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1430.0\n",
            "First 240.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 6.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4830.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 630.0\n",
            "First 207.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 6.0\n",
            "First True\n",
            "First 2.0\n",
            "First 5.0\n",
            "First 3030.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 8800.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 4251.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4510.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 1545.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7730.0\n",
            "First 26.0\n",
            "First 4.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 9620.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 5.0\n",
            "First 9645.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9630.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1108.0\n",
            "First 39.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1010.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3245.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 4810.0\n",
            "First 39.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 2100.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 5.0\n",
            "First 420.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 4.0\n",
            "First 8810.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5600.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5120.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 9600.0\n",
            "First 17.0\n",
            "First 4.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1530.0\n",
            "First 17.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 10.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7000.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4720.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9150.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 2310.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 8740.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5240.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 5.0\n",
            "First 2205.0\n",
            "First 17.0\n",
            "First 13.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 9130.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7700.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7700.0\n",
            "First 18.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 2002.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4220.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 10.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4760.0\n",
            "First 39.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5160.0\n",
            "First 152.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8140.0\n",
            "First 34.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7700.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 910.0\n",
            "First 213.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7750.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 8030.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4840.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 3.0\n",
            "First 3630.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 800.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 5740.0\n",
            "First 303.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 2360.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 5.0\n",
            "First 4220.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1305.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 1105.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 9.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5240.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7340.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4700.0\n",
            "First 17.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8350.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 9620.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5000.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6260.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 2205.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7700.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 3.0\n",
            "First 3090.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 5.0\n",
            "First 6410.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 4.0\n",
            "First 1.0\n",
            "First 5740.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 5740.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 8990.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3930.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 26.0\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 6260.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 5.0\n",
            "First 1.0\n",
            "First 5560.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 2005.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4040.0\n",
            "First 26.0\n",
            "First 12.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4622.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3255.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 3.0\n",
            "First 4720.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7810.0\n",
            "First 26.0\n",
            "First 15.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4220.0\n",
            "First 303.0\n",
            "First 16.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4055.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 340.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 3645.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4760.0\n",
            "First 40.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 7640.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 8740.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4030.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 2100.0\n",
            "First 25.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 3401.0\n",
            "First 26.0\n",
            "First 15.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7200.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3255.0\n",
            "First 210.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 6.0\n",
            "First True\n",
            "First 4.0\n",
            "First 1.0\n",
            "First 1980.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 6.0\n",
            "First 2.0\n",
            "First 4600.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5740.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 800.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4110.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 7810.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1006.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 4000.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8990.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4850.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4110.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 4350.0\n",
            "First 19.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 3655.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8990.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4220.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5740.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7750.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3323.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 2920.0\n",
            "First 34.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 3515.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 5120.0\n",
            "First 39.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4435.0\n",
            "First 39.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 3310.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 5610.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4710.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 2545.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 3.0\n",
            "First 2014.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 8950.0\n",
            "First 36.0\n",
            "First 17.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4760.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 440.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 3402.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1240.0\n",
            "First 6.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 6.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 4251.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4760.0\n",
            "First 18.0\n",
            "First 13.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 6050.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7700.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 4.0\n",
            "First 8990.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 4.0\n",
            "First 5.0\n",
            "First 2310.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 7.0\n",
            "First 5.0\n",
            "First 4240.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 6355.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 5740.0\n",
            "First 39.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 8320.0\n",
            "First 17.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 2014.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 9645.0\n",
            "First 39.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 6.0\n",
            "First 3.0\n",
            "First 4510.0\n",
            "First 110.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 3601.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 8000.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 6230.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 7200.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 3640.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 6.0\n",
            "First 1.0\n",
            "First 2723.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 2145.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 3.0\n",
            "First 1305.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 2.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 540.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 9620.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3220.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 230.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 1.0\n",
            "First 5940.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 3620.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8530.0\n",
            "First 26.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 8760.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 3.0\n",
            "First 5.0\n",
            "First 3602.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 5610.0\n",
            "First 26.0\n",
            "First 13.0\n",
            "First 1.0\n",
            "First 9.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 5510.0\n",
            "First 301.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4700.0\n",
            "First 213.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 3245.0\n",
            "First 26.0\n",
            "First 2.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4110.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 2310.0\n",
            "First 120.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 7.0\n",
            "First 1.0\n",
            "First 8740.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 630.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First True\n",
            "First 2.0\n",
            "First 3.0\n",
            "First 2360.0\n",
            "First 138.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 3.0\n",
            "First 4522.0\n",
            "First 26.0\n",
            "First 0.0\n",
            "First 2.0\n",
            "First 1.0\n",
            "First False\n",
            "First 1.0\n",
            "First 5.0\n",
            "First 4251.0\n",
            "First 12.0\n",
            "First 13.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 2.0\n",
            "First 1.0\n",
            "First 5940.0\n",
            "First 301.0\n",
            "First 17.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First False\n",
            "First 4.0\n",
            "First 3.0\n",
            "First 2205.0\n",
            "First 55.0\n",
            "First 0.0\n",
            "First 1.0\n",
            "First 1.0\n",
            "First True\n",
            "First 1.0\n",
            "First 1.0\n",
            "First 8225.0\n",
            "First 26.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8541d9968d03>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'|1x3 Cross validator'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mnewrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msens_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-8541d9968d03>\u001b[0m in \u001b[0;36mparse_row\u001b[0;34m(row, headers, headers_use)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# print('hdr=',hdr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# print('x=',x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mnew_row_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhdr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhdr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0msens_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_row_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msensitive\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_row_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-8541d9968d03>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m'SCHL'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontinuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;34m'COW'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0monehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'COW'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;34m'POBP'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0monehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'POBP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;34m'MAR'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0monehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MAR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;34m'OCCP'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0monehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OCCP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-8541d9968d03>\u001b[0m in \u001b[0;36monehot\u001b[0;34m(x, choices)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0monehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# g = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'First'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    618\u001b[0m                 )\n\u001b[1;32m    619\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the environment\n",
        "\n",
        "First, download conda and create environment with python 3.6 as the code has been implemented using Tensorflow 1.x which is not supported by python later than 3.6. Also, Colab does not support python version 3.6 without using Anaconda."
      ],
      "metadata": {
        "id": "4snT8XhzXCKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigate to Representation_Learning directory\n",
        "%cd /content/Representation_Learning/\n",
        "%env PYTHONPATH = # /env/python\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
        "!./Miniconda3-py38_4.12.0-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda update conda\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.8/site-packages')\n",
        "!conda create -n myenv python=3.6\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SWDTOGyKYAwd",
        "outputId": "6594ac0f-40a4-47fb-c974-a960d07256b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Representation_Learning\n",
            "env: PYTHONPATH=# /env/python\n",
            "--2024-06-19 17:25:29--  https://repo.anaconda.com/miniconda/Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.32.241, 104.16.191.158, 2606:4700::6810:20f1, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.32.241|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76120962 (73M) [application/x-sh]\n",
            "Saving to: Miniconda3-py38_4.12.0-Linux-x86_64.sh\n",
            "\n",
            "Miniconda3-py38_4.1 100%[===================>]  72.59M   196MB/s    in 0.4s    \n",
            "\n",
            "2024-06-19 17:25:29 (196 MB/s) - Miniconda3-py38_4.12.0-Linux-x86_64.sh saved [76120962/76120962]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - _openmp_mutex==4.5=1_gnu\n",
            "    - brotlipy==0.7.0=py38h27cfd23_1003\n",
            "    - ca-certificates==2022.3.29=h06a4308_1\n",
            "    - certifi==2021.10.8=py38h06a4308_2\n",
            "    - cffi==1.15.0=py38hd667e15_1\n",
            "    - charset-normalizer==2.0.4=pyhd3eb1b0_0\n",
            "    - colorama==0.4.4=pyhd3eb1b0_0\n",
            "    - conda-content-trust==0.1.1=pyhd3eb1b0_0\n",
            "    - conda-package-handling==1.8.1=py38h7f8727e_0\n",
            "    - conda==4.12.0=py38h06a4308_0\n",
            "    - cryptography==36.0.0=py38h9ce1e76_0\n",
            "    - idna==3.3=pyhd3eb1b0_0\n",
            "    - ld_impl_linux-64==2.35.1=h7274673_9\n",
            "    - libffi==3.3=he6710b0_2\n",
            "    - libgcc-ng==9.3.0=h5101ec6_17\n",
            "    - libgomp==9.3.0=h5101ec6_17\n",
            "    - libstdcxx-ng==9.3.0=hd4cf53a_17\n",
            "    - ncurses==6.3=h7f8727e_2\n",
            "    - openssl==1.1.1n=h7f8727e_0\n",
            "    - pip==21.2.4=py38h06a4308_0\n",
            "    - pycosat==0.6.3=py38h7b6447c_1\n",
            "    - pycparser==2.21=pyhd3eb1b0_0\n",
            "    - pyopenssl==22.0.0=pyhd3eb1b0_0\n",
            "    - pysocks==1.7.1=py38h06a4308_0\n",
            "    - python==3.8.13=h12debd9_0\n",
            "    - readline==8.1.2=h7f8727e_1\n",
            "    - requests==2.27.1=pyhd3eb1b0_0\n",
            "    - ruamel_yaml==0.15.100=py38h27cfd23_0\n",
            "    - setuptools==61.2.0=py38h06a4308_0\n",
            "    - six==1.16.0=pyhd3eb1b0_1\n",
            "    - sqlite==3.38.2=hc218d9a_0\n",
            "    - tk==8.6.11=h1ccaba5_0\n",
            "    - tqdm==4.63.0=pyhd3eb1b0_0\n",
            "    - urllib3==1.26.8=pyhd3eb1b0_0\n",
            "    - wheel==0.37.1=pyhd3eb1b0_0\n",
            "    - xz==5.2.5=h7b6447c_0\n",
            "    - yaml==0.2.5=h7b6447c_0\n",
            "    - zlib==1.2.12=h7f8727e_1\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-4.5-1_gnu\n",
            "  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py38h27cfd23_1003\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2022.3.29-h06a4308_1\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.10.8-py38h06a4308_2\n",
            "  cffi               pkgs/main/linux-64::cffi-1.15.0-py38hd667e15_1\n",
            "  charset-normalizer pkgs/main/noarch::charset-normalizer-2.0.4-pyhd3eb1b0_0\n",
            "  colorama           pkgs/main/noarch::colorama-0.4.4-pyhd3eb1b0_0\n",
            "  conda              pkgs/main/linux-64::conda-4.12.0-py38h06a4308_0\n",
            "  conda-content-tru~ pkgs/main/noarch::conda-content-trust-0.1.1-pyhd3eb1b0_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.8.1-py38h7f8727e_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-36.0.0-py38h9ce1e76_0\n",
            "  idna               pkgs/main/noarch::idna-3.3-pyhd3eb1b0_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.35.1-h7274673_9\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.3.0-h5101ec6_17\n",
            "  libgomp            pkgs/main/linux-64::libgomp-9.3.0-h5101ec6_17\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.3.0-hd4cf53a_17\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.3-h7f8727e_2\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1n-h7f8727e_0\n",
            "  pip                pkgs/main/linux-64::pip-21.2.4-py38h06a4308_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py38h7b6447c_1\n",
            "  pycparser          pkgs/main/noarch::pycparser-2.21-pyhd3eb1b0_0\n",
            "  pyopenssl          pkgs/main/noarch::pyopenssl-22.0.0-pyhd3eb1b0_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py38h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.8.13-h12debd9_0\n",
            "  readline           pkgs/main/linux-64::readline-8.1.2-h7f8727e_1\n",
            "  requests           pkgs/main/noarch::requests-2.27.1-pyhd3eb1b0_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.100-py38h27cfd23_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-61.2.0-py38h06a4308_0\n",
            "  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_1\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.38.2-hc218d9a_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.11-h1ccaba5_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.63.0-pyhd3eb1b0_0\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.26.8-pyhd3eb1b0_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.12-h7f8727e_1\n",
            "\n",
            "\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.12.0\n",
            "  latest version: 24.5.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-5.1          |            1_gnu          21 KB\n",
            "    brotli-python-1.0.9        |   py38h6a678d5_8         356 KB\n",
            "    ca-certificates-2024.3.11  |       h06a4308_0         127 KB\n",
            "    certifi-2024.6.2           |   py38h06a4308_0         160 KB\n",
            "    cffi-1.16.0                |   py38h5eee18b_1         250 KB\n",
            "    conda-package-handling-2.3.0|   py38h06a4308_0         269 KB\n",
            "    conda-package-streaming-0.10.0|   py38h06a4308_0          27 KB\n",
            "    cryptography-42.0.5        |   py38hdda0065_1         2.1 MB\n",
            "    idna-3.7                   |   py38h06a4308_0         113 KB\n",
            "    ld_impl_linux-64-2.38      |       h1181459_1         654 KB\n",
            "    libffi-3.4.4               |       h6a678d5_1         141 KB\n",
            "    libgcc-ng-11.2.0           |       h1234567_1         5.3 MB\n",
            "    libgomp-11.2.0             |       h1234567_1         474 KB\n",
            "    libstdcxx-ng-11.2.0        |       h1234567_1         4.7 MB\n",
            "    lz4-c-1.9.4                |       h6a678d5_1         156 KB\n",
            "    ncurses-6.4                |       h6a678d5_0         914 KB\n",
            "    openssl-3.0.14             |       h5eee18b_0         5.2 MB\n",
            "    pip-24.0                   |   py38h06a4308_0         2.6 MB\n",
            "    pycosat-0.6.6              |   py38h5eee18b_1          93 KB\n",
            "    pyopenssl-24.0.0           |   py38h06a4308_0          98 KB\n",
            "    python-3.8.19              |       h955ad1f_0        23.8 MB\n",
            "    readline-8.2               |       h5eee18b_0         357 KB\n",
            "    requests-2.32.2            |   py38h06a4308_0         101 KB\n",
            "    setuptools-69.5.1          |   py38h06a4308_0        1002 KB\n",
            "    sqlite-3.45.3              |       h5eee18b_0         1.2 MB\n",
            "    tk-8.6.14                  |       h39e8969_0         3.4 MB\n",
            "    urllib3-2.2.1              |   py38h06a4308_0         174 KB\n",
            "    wheel-0.43.0               |   py38h06a4308_0         109 KB\n",
            "    xz-5.4.6                   |       h5eee18b_1         643 KB\n",
            "    zlib-1.2.13                |       h5eee18b_1         111 KB\n",
            "    zstandard-0.22.0           |   py38h2c38b39_0         427 KB\n",
            "    zstd-1.5.5                 |       hc292b87_2         643 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        55.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  brotli-python      pkgs/main/linux-64::brotli-python-1.0.9-py38h6a678d5_8\n",
            "  conda-package-str~ pkgs/main/linux-64::conda-package-streaming-0.10.0-py38h06a4308_0\n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.4-h6a678d5_1\n",
            "  zstandard          pkgs/main/linux-64::zstandard-0.22.0-py38h2c38b39_0\n",
            "  zstd               pkgs/main/linux-64::zstd-1.5.5-hc292b87_2\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  brotlipy-0.7.0-py38h27cfd23_1003\n",
            "  colorama-0.4.4-pyhd3eb1b0_0\n",
            "  conda-content-trust-0.1.1-pyhd3eb1b0_0\n",
            "  six-1.16.0-pyhd3eb1b0_1\n",
            "  tqdm-4.63.0-pyhd3eb1b0_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  _openmp_mutex                                   4.5-1_gnu --> 5.1-1_gnu\n",
            "  ca-certificates                      2022.3.29-h06a4308_1 --> 2024.3.11-h06a4308_0\n",
            "  certifi                          2021.10.8-py38h06a4308_2 --> 2024.6.2-py38h06a4308_0\n",
            "  cffi                                1.15.0-py38hd667e15_1 --> 1.16.0-py38h5eee18b_1\n",
            "  conda-package-han~                   1.8.1-py38h7f8727e_0 --> 2.3.0-py38h06a4308_0\n",
            "  cryptography                        36.0.0-py38h9ce1e76_0 --> 42.0.5-py38hdda0065_1\n",
            "  idna               pkgs/main/noarch::idna-3.3-pyhd3eb1b0~ --> pkgs/main/linux-64::idna-3.7-py38h06a4308_0\n",
            "  ld_impl_linux-64                        2.35.1-h7274673_9 --> 2.38-h1181459_1\n",
            "  libffi                                     3.3-he6710b0_2 --> 3.4.4-h6a678d5_1\n",
            "  libgcc-ng                               9.3.0-h5101ec6_17 --> 11.2.0-h1234567_1\n",
            "  libgomp                                 9.3.0-h5101ec6_17 --> 11.2.0-h1234567_1\n",
            "  libstdcxx-ng                            9.3.0-hd4cf53a_17 --> 11.2.0-h1234567_1\n",
            "  ncurses                                    6.3-h7f8727e_2 --> 6.4-h6a678d5_0\n",
            "  openssl                                 1.1.1n-h7f8727e_0 --> 3.0.14-h5eee18b_0\n",
            "  pip                                 21.2.4-py38h06a4308_0 --> 24.0-py38h06a4308_0\n",
            "  pycosat                              0.6.3-py38h7b6447c_1 --> 0.6.6-py38h5eee18b_1\n",
            "  pyopenssl          pkgs/main/noarch::pyopenssl-22.0.0-py~ --> pkgs/main/linux-64::pyopenssl-24.0.0-py38h06a4308_0\n",
            "  python                                  3.8.13-h12debd9_0 --> 3.8.19-h955ad1f_0\n",
            "  readline                                 8.1.2-h7f8727e_1 --> 8.2-h5eee18b_0\n",
            "  requests           pkgs/main/noarch::requests-2.27.1-pyh~ --> pkgs/main/linux-64::requests-2.32.2-py38h06a4308_0\n",
            "  setuptools                          61.2.0-py38h06a4308_0 --> 69.5.1-py38h06a4308_0\n",
            "  sqlite                                  3.38.2-hc218d9a_0 --> 3.45.3-h5eee18b_0\n",
            "  tk                                      8.6.11-h1ccaba5_0 --> 8.6.14-h39e8969_0\n",
            "  urllib3            pkgs/main/noarch::urllib3-1.26.8-pyhd~ --> pkgs/main/linux-64::urllib3-2.2.1-py38h06a4308_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3e~ --> pkgs/main/linux-64::wheel-0.43.0-py38h06a4308_0\n",
            "  xz                                       5.2.5-h7b6447c_0 --> 5.4.6-h5eee18b_1\n",
            "  zlib                                    1.2.12-h7f8727e_1 --> 1.2.13-h5eee18b_1\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "readline-8.2         | 357 KB    | : 100% 1.0/1 [00:00<00:00,  4.57it/s]\n",
            "ld_impl_linux-64-2.3 | 654 KB    | : 100% 1.0/1 [00:00<00:00,  5.93it/s]\n",
            "pip-24.0             | 2.6 MB    | : 100% 1.0/1 [00:00<00:00,  2.76it/s]\n",
            "brotli-python-1.0.9  | 356 KB    | : 100% 1.0/1 [00:00<00:00,  5.99it/s]\n",
            "ca-certificates-2024 | 127 KB    | : 100% 1.0/1 [00:00<00:00,  6.67it/s]\n",
            "conda-package-handli | 269 KB    | : 100% 1.0/1 [00:00<00:00,  6.27it/s]\n",
            "libstdcxx-ng-11.2.0  | 4.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.66it/s]\n",
            "wheel-0.43.0         | 109 KB    | : 100% 1.0/1 [00:00<00:00,  6.38it/s]\n",
            "zstandard-0.22.0     | 427 KB    | : 100% 1.0/1 [00:00<00:00,  6.11it/s]\n",
            "cffi-1.16.0          | 250 KB    | : 100% 1.0/1 [00:00<00:00,  5.91it/s]\n",
            "tk-8.6.14            | 3.4 MB    | : 100% 1.0/1 [00:00<00:00,  3.82it/s]\n",
            "openssl-3.0.14       | 5.2 MB    | : 100% 1.0/1 [00:00<00:00,  3.61it/s]\n",
            "ncurses-6.4          | 914 KB    | : 100% 1.0/1 [00:00<00:00,  2.05it/s]\n",
            "urllib3-2.2.1        | 174 KB    | : 100% 1.0/1 [00:00<00:00,  6.44it/s]\n",
            "libgomp-11.2.0       | 474 KB    | : 100% 1.0/1 [00:00<00:00,  5.97it/s]\n",
            "sqlite-3.45.3        | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  5.41it/s]\n",
            "python-3.8.19        | 23.8 MB   | : 100% 1.0/1 [00:02<00:00,  2.02s/it]               \n",
            "zstd-1.5.5           | 643 KB    | : 100% 1.0/1 [00:00<00:00,  3.15it/s]\n",
            "idna-3.7             | 113 KB    | : 100% 1.0/1 [00:00<00:00,  2.69it/s]\n",
            "pyopenssl-24.0.0     | 98 KB     | : 100% 1.0/1 [00:00<00:00,  3.76it/s]\n",
            "xz-5.4.6             | 643 KB    | : 100% 1.0/1 [00:00<00:00,  2.57it/s]\n",
            "_openmp_mutex-5.1    | 21 KB     | : 100% 1.0/1 [00:00<00:00,  4.19it/s]\n",
            "libffi-3.4.4         | 141 KB    | : 100% 1.0/1 [00:00<00:00,  2.55it/s]\n",
            "lz4-c-1.9.4          | 156 KB    | : 100% 1.0/1 [00:00<00:00,  3.79it/s]\n",
            "certifi-2024.6.2     | 160 KB    | : 100% 1.0/1 [00:00<00:00,  3.63it/s]\n",
            "setuptools-69.5.1    | 1002 KB   | : 100% 1.0/1 [00:00<00:00,  1.67it/s]\n",
            "pycosat-0.6.6        | 93 KB     | : 100% 1.0/1 [00:00<00:00,  5.00it/s]\n",
            "requests-2.32.2      | 101 KB    | : 100% 1.0/1 [00:00<00:00,  3.67it/s]\n",
            "libgcc-ng-11.2.0     | 5.3 MB    | : 100% 1.0/1 [00:00<00:00,  1.94it/s]              \n",
            "cryptography-42.0.5  | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.99it/s]\n",
            "zlib-1.2.13          | 111 KB    | : 100% 1.0/1 [00:00<00:00,  4.79it/s]\n",
            "conda-package-stream | 27 KB     | : 100% 1.0/1 [00:00<00:00,  3.54it/s]\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.12.0\n",
            "  latest version: 24.5.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/myenv\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    certifi-2021.5.30          |   py36h06a4308_0         139 KB\n",
            "    openssl-1.1.1w             |       h7f8727e_0         3.7 MB\n",
            "    pip-21.2.2                 |   py36h06a4308_0         1.8 MB\n",
            "    python-3.6.13              |       h12debd9_1        32.5 MB\n",
            "    setuptools-58.0.4          |   py36h06a4308_0         788 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        39.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2024.3.11-h06a4308_0\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.5.30-py36h06a4308_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1\n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1w-h7f8727e_0\n",
            "  pip                pkgs/main/linux-64::pip-21.2.2-py36h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.6.13-h12debd9_1\n",
            "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-58.0.4-py36h06a4308_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.4.6-h5eee18b_1\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "certifi-2021.5.30    | 139 KB    | : 100% 1.0/1 [00:00<00:00, 11.24it/s]\n",
            "setuptools-58.0.4    | 788 KB    | : 100% 1.0/1 [00:00<00:00,  6.58it/s]\n",
            "openssl-1.1.1w       | 3.7 MB    | : 100% 1.0/1 [00:00<00:00,  6.25it/s]\n",
            "python-3.6.13        | 32.5 MB   | : 100% 1.0/1 [00:06<00:00,  6.41s/it]               \n",
            "pip-21.2.2           | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  3.12it/s]\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate myenv\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now install the dependencies"
      ],
      "metadata": {
        "id": "06SjG_HLZ293"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install MarkupSafe==1.1.1\n",
        "pip install absl-py==0.2.2\n",
        "pip install astor==0.7.1\n",
        "pip install gast==0.2.0\n",
        "pip install grpcio==1.13.0\n",
        "pip install Jinja2==2.10\n",
        "pip install Markdown==2.6.11\n",
        "pip install numpy==1.14.5\n",
        "pip install protobuf==3.6.0\n",
        "pip install six==1.11.0\n",
        "pip install tensorboard==1.9.0\n",
        "pip install tensorflow-gpu==1.9.0\n",
        "pip install tensorflow==1.9.0\n",
        "pip install termcolor==1.1.0\n",
        "pip install Werkzeug==0.14.1\n",
        "pip install matplotlib==3.3.0\n",
        "pip install ipykernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rJtdRZt_Z2KA",
        "outputId": "0cd0737b-6bcf-4fd3-eb1f-4152cb85c5ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe==1.1.1\n",
            "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux2010_x86_64.whl (32 kB)\n",
            "Installing collected packages: MarkupSafe\n",
            "Successfully installed MarkupSafe-1.1.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting absl-py==0.2.2\n",
            "  Downloading absl-py-0.2.2.tar.gz (82 kB)\n",
            "\u001b[K     || 82 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: absl-py\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for absl-py: filename=absl_py-0.2.2-py3-none-any.whl size=98945 sha256=5220bba3269c3d7d1a8e5989f9c3fdd07010b5d75117067613f19ebb3788a8f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/d0/0d/fe80a7cd6b46dc7a7f99a55d2823a38f4babbebff0b24a424a\n",
            "Successfully built absl-py\n",
            "Installing collected packages: six, absl-py\n",
            "Successfully installed absl-py-0.2.2 six-1.16.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting astor==0.7.1\n",
            "  Downloading astor-0.7.1-py2.py3-none-any.whl (27 kB)\n",
            "Installing collected packages: astor\n",
            "Successfully installed astor-0.7.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting gast==0.2.0\n",
            "  Downloading gast-0.2.0.tar.gz (9.4 kB)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.0-py3-none-any.whl size=6664 sha256=623311c0ebbaaf59a07cca5ab7dc28ded3938ff5d6561f2dd236b6cd8fd77b44\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/47/8b/196628a5926beb2b8c2f50c2050b18911a838bbf38e9532e67\n",
            "Successfully built gast\n",
            "Installing collected packages: gast\n",
            "Successfully installed gast-0.2.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting grpcio==1.13.0\n",
            "  Downloading grpcio-1.13.0-cp36-cp36m-manylinux1_x86_64.whl (9.1 MB)\n",
            "\u001b[K     || 9.1 MB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/envs/myenv/lib/python3.6/site-packages (from grpcio==1.13.0) (1.16.0)\n",
            "Installing collected packages: grpcio\n",
            "Successfully installed grpcio-1.13.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting Jinja2==2.10\n",
            "  Downloading Jinja2-2.10-py2.py3-none-any.whl (126 kB)\n",
            "\u001b[K     || 126 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/envs/myenv/lib/python3.6/site-packages (from Jinja2==2.10) (1.1.1)\n",
            "Installing collected packages: Jinja2\n",
            "Successfully installed Jinja2-2.10\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting Markdown==2.6.11\n",
            "  Downloading Markdown-2.6.11-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     || 78 kB 3.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: Markdown\n",
            "Successfully installed Markdown-2.6.11\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting numpy==1.14.5\n",
            "  Downloading numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2 MB)\n",
            "\u001b[K     || 12.2 MB 6.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "Successfully installed numpy-1.14.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting protobuf==3.6.0\n",
            "  Downloading protobuf-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     || 7.1 MB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/envs/myenv/lib/python3.6/site-packages (from protobuf==3.6.0) (58.0.4)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/envs/myenv/lib/python3.6/site-packages (from protobuf==3.6.0) (1.16.0)\n",
            "Installing collected packages: protobuf\n",
            "Successfully installed protobuf-3.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting six==1.11.0\n",
            "  Downloading six-1.11.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: six\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "Successfully installed six-1.11.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting tensorboard==1.9.0\n",
            "  Downloading tensorboard-1.9.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     || 3.3 MB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard==1.9.0) (0.37.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard==1.9.0) (1.11.0)\n",
            "Collecting werkzeug>=0.11.10\n",
            "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
            "\u001b[K     || 289 kB 51.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.4.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard==1.9.0) (3.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard==1.9.0) (2.6.11)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard==1.9.0) (1.14.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/myenv/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorboard==1.9.0) (58.0.4)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: dataclasses, werkzeug, tensorboard\n",
            "Successfully installed dataclasses-0.8 tensorboard-1.9.0 werkzeug-2.0.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting tensorflow-gpu==1.9.0\n",
            "  Downloading tensorflow_gpu-1.9.0-cp36-cp36m-manylinux1_x86_64.whl (229.6 MB)\n",
            "\u001b[K     || 229.6 MB 31 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard<1.10.0,>=1.9.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow-gpu==1.9.0) (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow-gpu==1.9.0) (1.14.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow-gpu==1.9.0) (0.37.1)\n",
            "Collecting setuptools<=39.1.0\n",
            "  Downloading setuptools-39.1.0-py2.py3-none-any.whl (566 kB)\n",
            "\u001b[K     || 566 kB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow-gpu==1.9.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow-gpu==1.9.0) (1.11.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow-gpu==1.9.0) (0.7.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow-gpu==1.9.0) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow-gpu==1.9.0) (3.6.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow-gpu==1.9.0) (1.13.0)\n",
            "Collecting termcolor>=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow-gpu==1.9.0) (2.6.11)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow-gpu==1.9.0) (2.0.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/envs/myenv/lib/python3.6/site-packages (from werkzeug>=0.11.10->tensorboard<1.10.0,>=1.9.0->tensorflow-gpu==1.9.0) (0.8)\n",
            "Building wheels for collected packages: termcolor\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=2bb04d7787f8c3a818014c88934f4a10f66752e3b4b9004c58d432f4dd7aaf2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
            "Successfully built termcolor\n",
            "Installing collected packages: setuptools, termcolor, tensorflow-gpu\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 58.0.4\n",
            "    Uninstalling setuptools-58.0.4:\n",
            "      Successfully uninstalled setuptools-58.0.4\n",
            "Successfully installed setuptools-39.1.0 tensorflow-gpu-1.9.0 termcolor-1.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting tensorflow==1.9.0\n",
            "  Downloading tensorflow-1.9.0-cp36-cp36m-manylinux1_x86_64.whl (51.1 MB)\n",
            "\u001b[K     || 51.1 MB 32 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.9.0) (0.37.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.9.0) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.9.0) (0.7.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.9.0) (1.14.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.9.0) (1.13.0)\n",
            "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.9.0) (39.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.9.0) (1.11.0)\n",
            "Requirement already satisfied: tensorboard<1.10.0,>=1.9.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.9.0) (1.9.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.9.0) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.9.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorflow==1.9.0) (3.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0) (2.6.11)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/envs/myenv/lib/python3.6/site-packages (from tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0) (2.0.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/envs/myenv/lib/python3.6/site-packages (from werkzeug>=0.11.10->tensorboard<1.10.0,>=1.9.0->tensorflow==1.9.0) (0.8)\n",
            "Installing collected packages: tensorflow\n",
            "Successfully installed tensorflow-1.9.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/envs/myenv/lib/python3.6/site-packages (1.1.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting Werkzeug==0.14.1\n",
            "  Downloading Werkzeug-0.14.1-py2.py3-none-any.whl (322 kB)\n",
            "\u001b[K     || 322 kB 5.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: Werkzeug\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 2.0.3\n",
            "    Uninstalling Werkzeug-2.0.3:\n",
            "      Successfully uninstalled Werkzeug-2.0.3\n",
            "Successfully installed Werkzeug-0.14.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting matplotlib==3.3.0\n",
            "  Downloading matplotlib-3.3.0-1-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n",
            "\u001b[K     || 11.5 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting python-dateutil>=2.1\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[K     || 229 kB 22.2 MB/s \n",
            "\u001b[?25hCollecting pillow>=6.2.0\n",
            "  Downloading Pillow-8.4.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     || 3.1 MB 30.4 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.15\n",
            "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     || 14.8 MB 12.9 MB/s \n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     || 1.1 MB 45.0 MB/s \n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
            "  Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
            "\u001b[K     || 103 kB 48.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/envs/myenv/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib==3.3.0) (1.11.0)\n",
            "Installing collected packages: python-dateutil, pyparsing, pillow, numpy, kiwisolver, cycler, matplotlib\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.14.5\n",
            "    Uninstalling numpy-1.14.5:\n",
            "      Successfully uninstalled numpy-1.14.5\n",
            "Successfully installed cycler-0.11.0 kiwisolver-1.3.1 matplotlib-3.3.0 numpy-1.19.5 pillow-8.4.0 pyparsing-3.1.2 python-dateutil-2.9.0.post0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-5.5.6-py3-none-any.whl (121 kB)\n",
            "\u001b[K     || 121 kB 9.7 MB/s \n",
            "\u001b[?25hCollecting jupyter-client\n",
            "  Downloading jupyter_client-7.1.2-py3-none-any.whl (130 kB)\n",
            "\u001b[K     || 130 kB 41.1 MB/s \n",
            "\u001b[?25hCollecting ipython-genutils\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting tornado>=4.2\n",
            "  Downloading tornado-6.1-cp36-cp36m-manylinux2010_x86_64.whl (427 kB)\n",
            "\u001b[K     || 427 kB 46.0 MB/s \n",
            "\u001b[?25hCollecting traitlets>=4.1.0\n",
            "  Downloading traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     || 75 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting ipython>=5.0.0\n",
            "  Downloading ipython-7.16.3-py3-none-any.whl (783 kB)\n",
            "\u001b[K     || 783 kB 42.0 MB/s \n",
            "\u001b[?25hCollecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\n",
            "\u001b[K     || 386 kB 51.3 MB/s \n",
            "\u001b[?25hCollecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting pexpect\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     || 63 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/envs/myenv/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel) (39.1.0)\n",
            "Collecting pygments\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     || 1.1 MB 39.7 MB/s \n",
            "\u001b[?25hCollecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting jedi<=0.17.2,>=0.10\n",
            "  Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     || 1.4 MB 39.4 MB/s \n",
            "\u001b[?25hCollecting parso<0.8.0,>=0.7.0\n",
            "  Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
            "\u001b[K     || 109 kB 48.2 MB/s \n",
            "\u001b[?25hCollecting wcwidth\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: six in /usr/local/envs/myenv/lib/python3.6/site-packages (from traitlets>=4.1.0->ipykernel) (1.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/envs/myenv/lib/python3.6/site-packages (from jupyter-client->ipykernel) (2.9.0.post0)\n",
            "Collecting pyzmq>=13\n",
            "  Downloading pyzmq-25.1.2-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     || 1.1 MB 39.0 MB/s \n",
            "\u001b[?25hCollecting jupyter-core>=4.6.0\n",
            "  Downloading jupyter_core-4.9.2-py3-none-any.whl (86 kB)\n",
            "\u001b[K     || 86 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting nest-asyncio>=1.5\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Collecting entrypoints\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Installing collected packages: ipython-genutils, decorator, wcwidth, traitlets, ptyprocess, parso, tornado, pyzmq, pygments, prompt-toolkit, pickleshare, pexpect, nest-asyncio, jupyter-core, jedi, entrypoints, backcall, jupyter-client, ipython, ipykernel\n",
            "Successfully installed backcall-0.2.0 decorator-5.1.1 entrypoints-0.4 ipykernel-5.5.6 ipython-7.16.3 ipython-genutils-0.2.0 jedi-0.17.2 jupyter-client-7.1.2 jupyter-core-4.9.2 nest-asyncio-1.6.0 parso-0.7.1 pexpect-4.9.0 pickleshare-0.7.5 prompt-toolkit-3.0.36 ptyprocess-0.7.0 pygments-2.14.0 pyzmq-25.1.2 tornado-6.1 traitlets-4.3.3 wcwidth-0.2.13\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Command generation\n",
        "To facilitate running the training code, we implemented a cell that generates the terminal commands with the required input options, especially since the code should executed from the terminal using Python 3.6 from the conda environment.\n",
        "\n",
        "The two python files that will be used for training are run_laftr.py and run_unf_clf.py that exit in /content/Representation_Learning/src\n",
        "\n",
        "For command generation, we take into account the following parameters:\n",
        "\n",
        "1. Exp_name: Name of the experiment, used for logging and saving purposes\n",
        "\n",
        "2. data: Dataset being used for the experiment ('adult' or 'ACSIncome')\n",
        "\n",
        "3. num_experiment: the number of experiments to run. It will be used to distinguish between experiments with different values of the fair_coeff (\\gamma).\n",
        "\n",
        "4. train_epochs: Number of epochs to train the model (for representation learning part)\n",
        "\n",
        "5. transfer_epochs: Number of epochs for training the naive classifier on the represenation.\n",
        "\n",
        "6. aud_steps: Number of adversarial update steps (the adversary parameters can be updated for more than one step while the encoder, decoder, and the classifer parameters are updated for one step)\n",
        "\n",
        "7. batch_size: Size of each batch for training\n",
        "\n",
        "\n",
        "8. recon_coeff: Coefficient for the reconstruction loss term\n",
        "\n",
        "\n",
        "9. fair_coeff: Coefficient for the fairness loss term (\\gamma)\n",
        "\n",
        "\n",
        "10. learning_rate: Learning rate for the optimizer\n",
        "\n",
        "11. transfer_epoch_number: Epoch number after which transfer learning starts\n",
        "transfer_epoch_number = 950\n",
        "\n",
        "12. New: Flag indicating whether the experiment is NEw (what we implemented with \\Delta_{NE}) or old with from the orginal code.\n",
        "\n",
        "\n",
        "13. index: Index of the feature to be used for non-exempt discrimination measure. (it is 35 for Adult dataset and 10 for ACSIncome dataset.)\n",
        "\n"
      ],
      "metadata": {
        "id": "KIFzAPZgZb8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Representation_Learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnGrwFNOlHZ9",
        "outputId": "d94acfc0-fdc1-47b0-daad-ace89f18f8c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Representation_Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_experiment_commands(Exp_name,num_experiments, train_epochs, transfer_epochs, aud_steps, batch_size, recon_coeff, fair_coeff, learning_rate, transfer_epoch_number, data, New, index):\n",
        "    commands = []\n",
        "    i = num_experiments\n",
        "    exp_name =Exp_name+ f\"_Exp_{i}\"\n",
        "    if New:\n",
        "      command1 = (\n",
        "            f\"python src/run_laftr.py conf/transfer/laftr_then_naive.json \"\n",
        "            f\"-o exp_name=\\\"laftr_example/{exp_name}\\\",\"\n",
        "            f\"train.n_epochs={train_epochs},\"\n",
        "            f\"train.aud_steps={aud_steps},\"\n",
        "            f\"train.batch_size={batch_size},\"\n",
        "            f\"model.class=WeightedEqoddsWassGanNEW,\"\n",
        "            f\"model.recon_coeff={recon_coeff},\"\n",
        "            f\"model.fair_coeff={fair_coeff},\"\n",
        "            f\"optim.learning_rate={learning_rate},\"\n",
        "            f\"transfer.n_epochs={transfer_epochs} \"\n",
        "            f\"-n new={New},\"\n",
        "            f\"index={index} \"\n",
        "            f\"--data {data} --dirs local\"\n",
        "        )\n",
        "\n",
        "      command2 = (\n",
        "            f\"python src/run_unf_clf.py conf/transfer/laftr_then_naive.json \"\n",
        "            f\"-o exp_name=\\\"laftr_example/{exp_name}/Exp_{i}_classification_transfer\\\",\"\n",
        "            f\"train.n_epochs={train_epochs},\"\n",
        "            f\"train.aud_steps={aud_steps},\"\n",
        "            f\"train.batch_size={batch_size},\"\n",
        "            f\"model.class=WeightedEqoddsWassGanNEW,\"\n",
        "            f\"model.recon_coeff={recon_coeff},\"\n",
        "            f\"model.fair_coeff={fair_coeff},\"\n",
        "            f\"optim.learning_rate={learning_rate},\"\n",
        "            f\"transfer.n_epochs={transfer_epochs},\"\n",
        "            f\"transfer.epoch_number={transfer_epoch_number} \"\n",
        "            f\"-n new={New},\"\n",
        "            f\"index={index} \"\n",
        "            f\"--data {data} --dirs local\"\n",
        "        )\n",
        "\n",
        "    else:\n",
        "      command1 = (\n",
        "            f\"python src/run_laftr.py conf/transfer/laftr_then_naive.json \"\n",
        "            f\"-o exp_name=\\\"laftr_example/{exp_name}\\\",\"\n",
        "            f\"train.n_epochs={train_epochs},\"\n",
        "            f\"train.aud_steps={aud_steps},\"\n",
        "            f\"train.batch_size={batch_size},\"\n",
        "            f\"model.recon_coeff={recon_coeff},\"\n",
        "            f\"model.fair_coeff={fair_coeff},\"\n",
        "            f\"optim.learning_rate={learning_rate},\"\n",
        "            f\"transfer.n_epochs={transfer_epochs} \"\n",
        "            f\"-n new={New},\"\n",
        "            f\"index={index} \"\n",
        "            f\"--data {data} --dirs local\"\n",
        "        )\n",
        "\n",
        "      command2 = (\n",
        "            f\"python src/run_unf_clf.py conf/transfer/laftr_then_naive.json \"\n",
        "            f\"-o exp_name=\\\"laftr_example/{exp_name}/Exp_{i}_classification_transfer\\\",\"\n",
        "            f\"train.n_epochs={train_epochs},\"\n",
        "            f\"train.aud_steps={aud_steps},\"\n",
        "            f\"train.batch_size={batch_size},\"\n",
        "            f\"model.recon_coeff={recon_coeff},\"\n",
        "            f\"model.fair_coeff={fair_coeff},\"\n",
        "            f\"optim.learning_rate={learning_rate},\"\n",
        "            f\"transfer.n_epochs={transfer_epochs},\"\n",
        "            f\"transfer.epoch_number={transfer_epoch_number} \"\n",
        "            f\"-n new={New},\"\n",
        "            f\"index={index} \"\n",
        "            f\"--data {data} --dirs local\"\n",
        "        )\n",
        "\n",
        "\n",
        "    commands.append((command1, command2))\n",
        "    return commands\n",
        "\n",
        "# # Example usage\n",
        "# Exp_name= 'Adult'\n",
        "# data = 'adult'\n",
        "# num_experiment = 3\n",
        "# train_epochs = 1000\n",
        "# transfer_epochs = 500\n",
        "# aud_steps = 3\n",
        "# batch_size = 128\n",
        "# recon_coeff = 1\n",
        "# fair_coeff = 1\n",
        "# learning_rate = 0.0002\n",
        "# transfer_epoch_number=950\n",
        "\n",
        "# New=False\n",
        "# index=35\n",
        "\n",
        "# commands = generate_experiment_commands(Exp_name, num_experiment, train_epochs, transfer_epochs, aud_steps, batch_size, recon_coeff, fair_coeff, learning_rate, transfer_epoch_number, data, New, index)\n",
        "\n",
        "# for command1, command2 in commands:\n",
        "#     print(command1)\n",
        "#     print(command2)\n",
        "#     print()\n",
        "\n",
        "experiments = [\n",
        "    {'Exp_name': 'Adult', 'data': 'adult', 'num_experiment': 1, 'train_epochs': 1000, 'transfer_epochs': 500, 'aud_steps': 2, 'batch_size': 128, 'recon_coeff': 1, 'fair_coeff': 0.1, 'learning_rate': 0.0005, 'transfer_epoch_number': 950, 'New': False, 'index': 35},\n",
        "    {'Exp_name': 'Adult', 'data': 'adult', 'num_experiment': 2, 'train_epochs': 1000, 'transfer_epochs': 500, 'aud_steps': 2, 'batch_size': 128, 'recon_coeff': 1, 'fair_coeff': 0.5, 'learning_rate': 0.0005, 'transfer_epoch_number': 950, 'New': False, 'index': 35},\n",
        "    {'Exp_name': 'Adult', 'data': 'adult', 'num_experiment': 3, 'train_epochs': 1000, 'transfer_epochs': 500, 'aud_steps': 3, 'batch_size': 128, 'recon_coeff': 1, 'fair_coeff': 1, 'learning_rate': 0.0002, 'transfer_epoch_number': 950, 'New': False, 'index': 35},\n",
        "    {'Exp_name': 'ACSIncome', 'data': 'ACSIncome', 'num_experiment': 1, 'train_epochs': 1000, 'transfer_epochs': 500, 'aud_steps': 2, 'batch_size': 128, 'recon_coeff': 1, 'fair_coeff': 0.1, 'learning_rate': 0.001, 'transfer_epoch_number': 950, 'New': False, 'index': 10},\n",
        "    {'Exp_name': 'ACSIncome', 'data': 'ACSIncome', 'num_experiment': 2, 'train_epochs': 1000, 'transfer_epochs': 500, 'aud_steps': 2, 'batch_size': 128, 'recon_coeff': 1, 'fair_coeff': 0.5, 'learning_rate': 0.0005, 'transfer_epoch_number': 950, 'New': False, 'index': 10},\n",
        "    {'Exp_name': 'ACSIncome', 'data': 'ACSIncome', 'num_experiment': 3, 'train_epochs': 1000, 'transfer_epochs': 500, 'aud_steps': 2, 'batch_size': 128, 'recon_coeff': 1, 'fair_coeff': 1, 'learning_rate': 0.0005, 'transfer_epoch_number': 950, 'New': False, 'index': 10},\n",
        "    {'Exp_name': 'AdultXc', 'data': 'adult', 'num_experiment': 1, 'train_epochs': 1000, 'transfer_epochs': 500, 'aud_steps': 2, 'batch_size': 128, 'recon_coeff': 1, 'fair_coeff': 0.1, 'learning_rate': 0.0005, 'transfer_epoch_number': 950, 'New': True, 'index': 35},\n",
        "    {'Exp_name': 'AdultXc', 'data': 'adult', 'num_experiment': 2, 'train_epochs': 1000, 'transfer_epochs': 500, 'aud_steps': 2, 'batch_size': 128, 'recon_coeff': 1, 'fair_coeff': 0.5, 'learning_rate': 0.0005, 'transfer_epoch_number': 950, 'New': True, 'index': 35},\n",
        "    {'Exp_name': 'AdultXc', 'data': 'adult', 'num_experiment': 3, 'train_epochs': 1000, 'transfer_epochs': 500, 'aud_steps': 3, 'batch_size': 128, 'recon_coeff': 1, 'fair_coeff': 1, 'learning_rate': 0.0002, 'transfer_epoch_number': 950, 'New': True, 'index': 35},\n",
        "    {'Exp_name': 'ACSIncomeXc', 'data': 'ACSIncome', 'num_experiment': 1, 'train_epochs': 1000, 'transfer_epochs': 500, 'aud_steps': 2, 'batch_size': 128, 'recon_coeff': 1, 'fair_coeff': 0.1, 'learning_rate': 0.001, 'transfer_epoch_number': 950, 'New': True, 'index': 10},\n",
        "    {'Exp_name': 'ACSIncomeXc', 'data': 'ACSIncome', 'num_experiment': 2, 'train_epochs': 1000, 'transfer_epochs': 500, 'aud_steps': 2, 'batch_size': 128, 'recon_coeff': 1, 'fair_coeff': 0.5, 'learning_rate': 0.0005, 'transfer_epoch_number': 950, 'New': True, 'index': 10},\n",
        "    {'Exp_name': 'ACSIncomeXc', 'data': 'ACSIncome', 'num_experiment': 3, 'train_epochs': 1000, 'transfer_epochs': 500, 'aud_steps': 2, 'batch_size': 128, 'recon_coeff': 1, 'fair_coeff': 1, 'learning_rate': 0.0005, 'transfer_epoch_number': 950, 'New': True, 'index': 10},\n",
        "]\n",
        "\n",
        "#example\n",
        "experiments =  [\n",
        "    {'Exp_name': 'Adult', 'data': 'adult', 'num_experiment': 1, 'train_epochs': 100, 'transfer_epochs': 100, 'aud_steps': 2, 'batch_size': 128, 'recon_coeff': 1, 'fair_coeff': 0.1, 'learning_rate': 0.0005, 'transfer_epoch_number': 50, 'New': False, 'index': 35}]\n",
        "\n",
        "for exp in experiments:\n",
        "    commands = generate_experiment_commands(\n",
        "        Exp_name=exp['Exp_name'],\n",
        "        num_experiments=exp['num_experiment'],\n",
        "        train_epochs=exp['train_epochs'],\n",
        "        transfer_epochs=exp['transfer_epochs'],\n",
        "        aud_steps=exp['aud_steps'],\n",
        "        batch_size=exp['batch_size'],\n",
        "        recon_coeff=exp['recon_coeff'],\n",
        "        fair_coeff=exp['fair_coeff'],\n",
        "        learning_rate=exp['learning_rate'],\n",
        "        transfer_epoch_number=exp['transfer_epoch_number'],\n",
        "        data=exp['data'],\n",
        "        New=exp['New'],\n",
        "        index=exp['index']\n",
        "    )\n",
        "    for command1, command2 in commands:\n",
        "\n",
        "        print('#_'+exp['Exp_name']+'_'+str(exp['num_experiment']))\n",
        "        print(command1)\n",
        "        print(command2)\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuZodiWpXiTN",
        "outputId": "9b37bb58-27f3-4b06-b629-45a546c9ff36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#_Adult_1\n",
            "python src/run_laftr.py conf/transfer/laftr_then_naive.json -o exp_name=\"laftr_example/Adult_Exp_1\",train.n_epochs=100,train.aud_steps=2,train.batch_size=128,model.recon_coeff=1,model.fair_coeff=0.1,optim.learning_rate=0.0005,transfer.n_epochs=100 -n new=False,index=35 --data adult --dirs local\n",
            "python src/run_unf_clf.py conf/transfer/laftr_then_naive.json -o exp_name=\"laftr_example/Adult_Exp_1/Exp_1_classification_transfer\",train.n_epochs=100,train.aud_steps=2,train.batch_size=128,model.recon_coeff=1,model.fair_coeff=0.1,optim.learning_rate=0.0005,transfer.n_epochs=100,transfer.epoch_number=50 -n new=False,index=35 --data adult --dirs local\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run commands in the terminal. For each pair of commands: The first one, train the representation model, and the second one train the naive classifier.\n",
        "\n",
        "To find the training figures and the final test metrics, for the example below:\n",
        "1. For first training part go to directly: /content/Representation_Learning/sxperiments/Adult_Exp_1. There you can find training loss figure and fairness metrics. File test_metrics.csv contant the test dataset evalution results.\n",
        "2. For the second training part (naive classifier from the represenation), go to directoy: /content/Representation_Learning/Exp_1_classification_transfer.   There you can find training loss figure and fairness metrics. File test_metrics.csv contant the test dataset evalution results. Reported data in the paper is from test_metrics.csv in this experiment."
      ],
      "metadata": {
        "id": "agS9YpfUYr6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "python src/run_laftr.py conf/transfer/laftr_then_naive.json -o exp_name=\"laftr_example/Adult_Exp_1\",train.n_epochs=100,train.aud_steps=2,train.batch_size=128,model.recon_coeff=1,model.fair_coeff=0.1,optim.learning_rate=0.0005,transfer.n_epochs=100 -n new=False,index=35 --data adult --dirs local\n",
        "python src/run_unf_clf.py conf/transfer/laftr_then_naive.json -o exp_name=\"laftr_example/Adult_Exp_1/Exp_1_classification_transfer\",train.n_epochs=100,train.aud_steps=2,train.batch_size=128,model.recon_coeff=1,model.fair_coeff=0.1,optim.learning_rate=0.0005,transfer.n_epochs=100,transfer.epoch_number=50 -n new=False,index=35 --data adult --dirs local\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s31Ik74QYuQ-",
        "outputId": "a1dae773-99a1-495f-d21c-183e4afcb5c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "{'exp_name': 'laftr_example/Adult_Exp_1', 'train': {'n_epochs': '100', 'aud_steps': '2', 'batch_size': '128'}, 'model': {'recon_coeff': '1', 'fair_coeff': '0.1'}, 'optim': {'learning_rate': '0.0005'}, 'transfer': {'n_epochs': '100'}}\n",
            "y shape (24157, 2)\n",
            "changing shape\n",
            "2024-06-19 17:39:06.542923: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "starting Epoch 0\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E0: trained class 150, trained aud 300\n",
            "DI:  0.014098703861236572\n",
            "DP:  0.004413619\n",
            "(4736, 1)\n",
            "(4736, 8)\n",
            "(4736, 1)\n",
            "(4736, 1)\n",
            "(4736, 1)\n",
            "Test score: Class CE: 0.271, Disc CE: 0.994, Ttl CE: -0.723, Class Err: 0.244 Disc Err: 0.670\n",
            "Error Rate: 0.244,  DI: 0.007, di_FP: 0.000, di_FN: 0.014\n",
            "Error Rate (A): 0.670\n",
            "\n",
            "Predicting Y\n",
            "A=?: Base PR: 0.247, Base NR: 0.753,  PR: 0.003, NR: 0.997, Err: 0.244, TPR: 0.012, FNR: 0.988, TNR: 1.000, FPR: 0.000\n",
            "A=1: Base PR: 0.112, Base NR: 0.888,  PR: 0.000, NR: 1.000, Err: 0.112, TPR: 0.000, FNR: 1.000, TNR: 1.000, FPR: 0.000\n",
            "A=0: Base PR: 0.313, Base NR: 0.687,  PR: 0.004, NR: 0.996, Err: 0.309, TPR: 0.014, FNR: 0.986, TNR: 1.000, FPR: 0.000\n",
            "ACor: Base PR: 0.112, Base NR: 0.888,  PR: 0.000, NR: 1.000, Err: 0.112, TPR: 0.000, FNR: 1.000, TNR: 1.000, FPR: 0.000\n",
            "AWro: Base PR: 0.313, Base NR: 0.687,  PR: 0.004, NR: 0.996, Err: 0.309, TPR: 0.014, FNR: 0.986, TNR: 1.000, FPR: 0.000\n",
            "\n",
            "Predicting A\n",
            "Y=?: Base-A1-rate: 0.330, Base-A0-rate: 0.670, Pred A1-rate: 0.999, Pred-A0-rate: 0.001, Err: 0.670, A1-Correct: 0.999, A1-Wrong: 0.001, A0-Correct: 0.001, A0-Wrong: 0.999\n",
            "Y=1: Base-A1-rate: 0.150, Base-A0-rate: 0.850, Pred A1-rate: 1.000, Pred-A0-rate: 0.000, Err: 0.850, A1-Correct: 1.000, A1-Wrong: 0.000, A0-Correct: 0.000, A0-Wrong: 1.000\n",
            "Y=0: Base-A1-rate: 0.389, Base-A0-rate: 0.611, Pred A1-rate: 0.999, Pred-A0-rate: 0.001, Err: 0.610, A1-Correct: 0.999, A1-Wrong: 0.001, A0-Correct: 0.001, A0-Wrong: 0.999\n",
            "YCor: Base-A1-rate: 0.388, Base-A0-rate: 0.612, Pred A1-rate: 0.999, Pred-A0-rate: 0.001, Err: 0.612, A1-Correct: 0.999, A1-Wrong: 0.001, A0-Correct: 0.001, A0-Wrong: 0.999\n",
            "YWro: Base-A1-rate: 0.152, Base-A0-rate: 0.848, Pred A1-rate: 1.000, Pred-A0-rate: 0.000, Err: 0.848, A1-Correct: 1.000, A1-Wrong: 0.000, A0-Correct: 0.000, A0-Wrong: 1.000\n",
            "Metrics saved to ./experiments/laftr_example/Adult_Exp_1/checkpoints/Epoch_0_Valid/test_metrics.csv\n",
            "(5888, 1)\n",
            "(5888, 8)\n",
            "(5888, 1)\n",
            "(5888, 1)\n",
            "(5888, 1)\n",
            "Test score: Class CE: 0.273, Disc CE: 1.001, Ttl CE: -0.728, Class Err: 0.248 Disc Err: 0.681\n",
            "Error Rate: 0.248,  DI: 0.004, di_FP: 0.000, di_FN: 0.009\n",
            "Error Rate (A): 0.681\n",
            "\n",
            "Predicting Y\n",
            "A=?: Base PR: 0.250, Base NR: 0.750,  PR: 0.002, NR: 0.998, Err: 0.248, TPR: 0.007, FNR: 0.993, TNR: 1.000, FPR: 0.000\n",
            "A=1: Base PR: 0.113, Base NR: 0.887,  PR: 0.000, NR: 1.000, Err: 0.113, TPR: 0.000, FNR: 1.000, TNR: 1.000, FPR: 0.000\n",
            "A=0: Base PR: 0.314, Base NR: 0.686,  PR: 0.003, NR: 0.997, Err: 0.311, TPR: 0.009, FNR: 0.991, TNR: 1.000, FPR: 0.000\n",
            "ACor: Base PR: 0.113, Base NR: 0.887,  PR: 0.000, NR: 1.000, Err: 0.113, TPR: 0.000, FNR: 1.000, TNR: 1.000, FPR: 0.000\n",
            "AWro: Base PR: 0.314, Base NR: 0.686,  PR: 0.003, NR: 0.997, Err: 0.311, TPR: 0.009, FNR: 0.991, TNR: 1.000, FPR: 0.000\n",
            "\n",
            "Predicting A\n",
            "Y=?: Base-A1-rate: 0.319, Base-A0-rate: 0.681, Pred A1-rate: 1.000, Pred-A0-rate: 0.000, Err: 0.681, A1-Correct: 1.000, A1-Wrong: 0.000, A0-Correct: 0.000, A0-Wrong: 1.000\n",
            "Y=1: Base-A1-rate: 0.144, Base-A0-rate: 0.856, Pred A1-rate: 1.000, Pred-A0-rate: 0.000, Err: 0.856, A1-Correct: 1.000, A1-Wrong: 0.000, A0-Correct: 0.000, A0-Wrong: 1.000\n",
            "Y=0: Base-A1-rate: 0.377, Base-A0-rate: 0.623, Pred A1-rate: 1.000, Pred-A0-rate: 0.000, Err: 0.623, A1-Correct: 1.000, A1-Wrong: 0.000, A0-Correct: 0.001, A0-Wrong: 0.999\n",
            "YCor: Base-A1-rate: 0.376, Base-A0-rate: 0.624, Pred A1-rate: 1.000, Pred-A0-rate: 0.000, Err: 0.624, A1-Correct: 1.000, A1-Wrong: 0.000, A0-Correct: 0.001, A0-Wrong: 0.999\n",
            "YWro: Base-A1-rate: 0.145, Base-A0-rate: 0.855, Pred A1-rate: 1.000, Pred-A0-rate: 0.000, Err: 0.855, A1-Correct: 1.000, A1-Wrong: 0.000, A0-Correct: 0.000, A0-Wrong: 1.000\n",
            "Metrics saved to ./experiments/laftr_example/Adult_Exp_1/checkpoints/Epoch_0_Test/test_metrics.csv\n",
            "E0: ClaCE:0.342, DisCE:1.034, TtlCE:-0.691, ClaErr:0.249, DisErr:0.669, RecLoss:1.022; E0: ClaCE:0.271, DisCE:0.994, TtlCE:-0.723, ClaErr:0.244, DisErr:0.670, RecLoss:0.961\n",
            "starting Epoch 1\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E1: trained class 150, trained aud 300\n",
            "DI:  0.10312303155660629\n",
            "DP:  0.047146868\n",
            "E1: ClaCE:0.247, DisCE:0.946, TtlCE:-0.698, ClaErr:0.237, DisErr:0.671, RecLoss:0.974; E1: ClaCE:0.226, DisCE:0.907, TtlCE:-0.681, ClaErr:0.217, DisErr:0.641, RecLoss:0.932\n",
            "starting Epoch 2\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E2: trained class 150, trained aud 300\n",
            "DI:  0.1373702585697174\n",
            "DP:  0.13930556\n",
            "E2: ClaCE:0.208, DisCE:0.913, TtlCE:-0.705, ClaErr:0.182, DisErr:0.615, RecLoss:0.948; E2: ClaCE:0.195, DisCE:0.929, TtlCE:-0.734, ClaErr:0.172, DisErr:0.599, RecLoss:0.911\n",
            "starting Epoch 3\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E3: trained class 150, trained aud 300\n",
            "DI:  0.07907269895076752\n",
            "DP:  0.14248958\n",
            "E3: ClaCE:0.182, DisCE:0.904, TtlCE:-0.722, ClaErr:0.165, DisErr:0.554, RecLoss:0.930; E3: ClaCE:0.182, DisCE:0.891, TtlCE:-0.709, ClaErr:0.167, DisErr:0.535, RecLoss:0.896\n",
            "starting Epoch 4\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E4: trained class 150, trained aud 300\n",
            "DI:  0.06583304703235626\n",
            "DP:  0.12525275\n",
            "E4: ClaCE:0.172, DisCE:0.858, TtlCE:-0.685, ClaErr:0.162, DisErr:0.520, RecLoss:0.917; E4: ClaCE:0.177, DisCE:0.846, TtlCE:-0.669, ClaErr:0.168, DisErr:0.511, RecLoss:0.884\n",
            "starting Epoch 5\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E5: trained class 150, trained aud 300\n",
            "DI:  0.07833400368690491\n",
            "DP:  0.114778295\n",
            "E5: ClaCE:0.168, DisCE:0.833, TtlCE:-0.665, ClaErr:0.161, DisErr:0.507, RecLoss:0.906; E5: ClaCE:0.176, DisCE:0.842, TtlCE:-0.666, ClaErr:0.169, DisErr:0.506, RecLoss:0.874\n",
            "starting Epoch 6\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E6: trained class 150, trained aud 300\n",
            "DI:  0.08892953395843506\n",
            "DP:  0.10587122\n",
            "E6: ClaCE:0.165, DisCE:0.845, TtlCE:-0.680, ClaErr:0.160, DisErr:0.512, RecLoss:0.897; E6: ClaCE:0.175, DisCE:0.857, TtlCE:-0.682, ClaErr:0.171, DisErr:0.513, RecLoss:0.866\n",
            "starting Epoch 7\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E7: trained class 150, trained aud 300\n",
            "DI:  0.08604755997657776\n",
            "DP:  0.11252714\n",
            "E7: ClaCE:0.163, DisCE:0.808, TtlCE:-0.645, ClaErr:0.157, DisErr:0.416, RecLoss:0.889; E7: ClaCE:0.174, DisCE:0.843, TtlCE:-0.669, ClaErr:0.169, DisErr:0.421, RecLoss:0.860\n",
            "starting Epoch 8\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E8: trained class 150, trained aud 300\n",
            "DI:  0.08365632593631744\n",
            "DP:  0.112247355\n",
            "E8: ClaCE:0.161, DisCE:0.860, TtlCE:-0.698, ClaErr:0.157, DisErr:0.447, RecLoss:0.884; E8: ClaCE:0.173, DisCE:0.912, TtlCE:-0.740, ClaErr:0.171, DisErr:0.504, RecLoss:0.856\n",
            "starting Epoch 9\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E9: trained class 150, trained aud 300\n",
            "DI:  0.09891906380653381\n",
            "DP:  0.10780713\n",
            "E9: ClaCE:0.161, DisCE:0.890, TtlCE:-0.730, ClaErr:0.156, DisErr:0.513, RecLoss:0.880; E9: ClaCE:0.173, DisCE:0.899, TtlCE:-0.726, ClaErr:0.174, DisErr:0.528, RecLoss:0.851\n",
            "starting Epoch 10\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E10: trained class 150, trained aud 300\n",
            "DI:  0.10822485387325287\n",
            "DP:  0.10622197\n",
            "E10: ClaCE:0.160, DisCE:0.883, TtlCE:-0.723, ClaErr:0.155, DisErr:0.531, RecLoss:0.875; E10: ClaCE:0.172, DisCE:0.891, TtlCE:-0.718, ClaErr:0.172, DisErr:0.535, RecLoss:0.847\n",
            "starting Epoch 11\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E11: trained class 150, trained aud 300\n",
            "DI:  0.10579930245876312\n",
            "DP:  0.103078246\n",
            "E11: ClaCE:0.159, DisCE:0.879, TtlCE:-0.721, ClaErr:0.154, DisErr:0.533, RecLoss:0.871; E11: ClaCE:0.172, DisCE:0.889, TtlCE:-0.717, ClaErr:0.172, DisErr:0.537, RecLoss:0.844\n",
            "starting Epoch 12\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E12: trained class 150, trained aud 300\n",
            "DI:  0.10442909598350525\n",
            "DP:  0.09897102\n",
            "E12: ClaCE:0.158, DisCE:0.880, TtlCE:-0.722, ClaErr:0.154, DisErr:0.535, RecLoss:0.868; E12: ClaCE:0.172, DisCE:0.890, TtlCE:-0.718, ClaErr:0.171, DisErr:0.539, RecLoss:0.841\n",
            "starting Epoch 13\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E13: trained class 150, trained aud 300\n",
            "DI:  0.11046317219734192\n",
            "DP:  0.092936754\n",
            "E13: ClaCE:0.157, DisCE:0.881, TtlCE:-0.724, ClaErr:0.154, DisErr:0.536, RecLoss:0.865; E13: ClaCE:0.172, DisCE:0.892, TtlCE:-0.720, ClaErr:0.172, DisErr:0.540, RecLoss:0.838\n",
            "starting Epoch 14\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E14: trained class 150, trained aud 300\n",
            "DI:  0.1100042462348938\n",
            "DP:  0.092621505\n",
            "E14: ClaCE:0.156, DisCE:0.882, TtlCE:-0.726, ClaErr:0.153, DisErr:0.535, RecLoss:0.862; E14: ClaCE:0.172, DisCE:0.894, TtlCE:-0.722, ClaErr:0.172, DisErr:0.538, RecLoss:0.836\n",
            "starting Epoch 15\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E15: trained class 150, trained aud 300\n",
            "DI:  0.11189479380846024\n",
            "DP:  0.09007282\n",
            "E15: ClaCE:0.156, DisCE:0.883, TtlCE:-0.727, ClaErr:0.153, DisErr:0.534, RecLoss:0.860; E15: ClaCE:0.172, DisCE:0.895, TtlCE:-0.723, ClaErr:0.171, DisErr:0.538, RecLoss:0.834\n",
            "starting Epoch 16\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E16: trained class 150, trained aud 300\n",
            "DI:  0.11499856412410736\n",
            "DP:  0.09134273\n",
            "E16: ClaCE:0.155, DisCE:0.884, TtlCE:-0.729, ClaErr:0.153, DisErr:0.534, RecLoss:0.858; E16: ClaCE:0.172, DisCE:0.895, TtlCE:-0.723, ClaErr:0.172, DisErr:0.537, RecLoss:0.832\n",
            "starting Epoch 17\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E17: trained class 150, trained aud 300\n",
            "DI:  0.11582721769809723\n",
            "DP:  0.09291902\n",
            "E17: ClaCE:0.155, DisCE:0.884, TtlCE:-0.729, ClaErr:0.152, DisErr:0.532, RecLoss:0.856; E17: ClaCE:0.172, DisCE:0.896, TtlCE:-0.724, ClaErr:0.173, DisErr:0.534, RecLoss:0.831\n",
            "starting Epoch 18\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E18: trained class 150, trained aud 300\n",
            "DI:  0.1211652159690857\n",
            "DP:  0.09418005\n",
            "E18: ClaCE:0.154, DisCE:0.882, TtlCE:-0.728, ClaErr:0.152, DisErr:0.527, RecLoss:0.855; E18: ClaCE:0.172, DisCE:0.900, TtlCE:-0.728, ClaErr:0.172, DisErr:0.529, RecLoss:0.829\n",
            "starting Epoch 19\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E19: trained class 150, trained aud 300\n",
            "DI:  0.12113255262374878\n",
            "DP:  0.09862027\n",
            "E19: ClaCE:0.154, DisCE:0.866, TtlCE:-0.712, ClaErr:0.151, DisErr:0.467, RecLoss:0.854; E19: ClaCE:0.171, DisCE:0.904, TtlCE:-0.732, ClaErr:0.171, DisErr:0.461, RecLoss:0.830\n",
            "starting Epoch 20\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E20: trained class 150, trained aud 300\n",
            "DI:  0.13463832437992096\n",
            "DP:  0.09704398\n",
            "E20: ClaCE:0.154, DisCE:0.902, TtlCE:-0.748, ClaErr:0.151, DisErr:0.486, RecLoss:0.855; E20: ClaCE:0.171, DisCE:0.942, TtlCE:-0.771, ClaErr:0.170, DisErr:0.541, RecLoss:0.831\n",
            "starting Epoch 21\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E21: trained class 150, trained aud 300\n",
            "DI:  0.14167286455631256\n",
            "DP:  0.093855925\n",
            "E21: ClaCE:0.153, DisCE:0.908, TtlCE:-0.755, ClaErr:0.151, DisErr:0.536, RecLoss:0.855; E21: ClaCE:0.172, DisCE:0.916, TtlCE:-0.745, ClaErr:0.172, DisErr:0.548, RecLoss:0.829\n",
            "starting Epoch 22\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E22: trained class 150, trained aud 300\n",
            "DI:  0.147846058011055\n",
            "DP:  0.0935318\n",
            "E22: ClaCE:0.153, DisCE:0.896, TtlCE:-0.743, ClaErr:0.150, DisErr:0.540, RecLoss:0.853; E22: ClaCE:0.172, DisCE:0.906, TtlCE:-0.734, ClaErr:0.172, DisErr:0.548, RecLoss:0.828\n",
            "starting Epoch 23\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E23: trained class 150, trained aud 300\n",
            "DI:  0.15019556879997253\n",
            "DP:  0.09129838\n",
            "E23: ClaCE:0.152, DisCE:0.890, TtlCE:-0.738, ClaErr:0.149, DisErr:0.537, RecLoss:0.851; E23: ClaCE:0.171, DisCE:0.900, TtlCE:-0.729, ClaErr:0.171, DisErr:0.544, RecLoss:0.826\n",
            "starting Epoch 24\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E24: trained class 150, trained aud 300\n",
            "DI:  0.15737581253051758\n",
            "DP:  0.09065899\n",
            "E24: ClaCE:0.152, DisCE:0.885, TtlCE:-0.733, ClaErr:0.149, DisErr:0.531, RecLoss:0.850; E24: ClaCE:0.172, DisCE:0.899, TtlCE:-0.727, ClaErr:0.171, DisErr:0.537, RecLoss:0.825\n",
            "starting Epoch 25\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E25: trained class 150, trained aud 300\n",
            "DI:  0.15360863506793976\n",
            "DP:  0.092244156\n",
            "E25: ClaCE:0.152, DisCE:0.886, TtlCE:-0.734, ClaErr:0.149, DisErr:0.522, RecLoss:0.849; E25: ClaCE:0.171, DisCE:0.906, TtlCE:-0.734, ClaErr:0.170, DisErr:0.538, RecLoss:0.825\n",
            "starting Epoch 26\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E26: trained class 150, trained aud 300\n",
            "DI:  0.1518816351890564\n",
            "DP:  0.09192003\n",
            "E26: ClaCE:0.151, DisCE:0.893, TtlCE:-0.742, ClaErr:0.149, DisErr:0.529, RecLoss:0.849; E26: ClaCE:0.171, DisCE:0.906, TtlCE:-0.735, ClaErr:0.170, DisErr:0.542, RecLoss:0.824\n",
            "starting Epoch 27\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E27: trained class 150, trained aud 300\n",
            "DI:  0.15087458491325378\n",
            "DP:  0.09223528\n",
            "E27: ClaCE:0.151, DisCE:0.893, TtlCE:-0.742, ClaErr:0.149, DisErr:0.535, RecLoss:0.848; E27: ClaCE:0.171, DisCE:0.902, TtlCE:-0.731, ClaErr:0.170, DisErr:0.543, RecLoss:0.823\n",
            "starting Epoch 28\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E28: trained class 150, trained aud 300\n",
            "DI:  0.1544438600540161\n",
            "DP:  0.09065899\n",
            "E28: ClaCE:0.150, DisCE:0.892, TtlCE:-0.742, ClaErr:0.148, DisErr:0.537, RecLoss:0.847; E28: ClaCE:0.171, DisCE:0.900, TtlCE:-0.729, ClaErr:0.171, DisErr:0.540, RecLoss:0.823\n",
            "starting Epoch 29\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E29: trained class 150, trained aud 300\n",
            "DI:  0.1534368097782135\n",
            "DP:  0.09097426\n",
            "E29: ClaCE:0.150, DisCE:0.892, TtlCE:-0.742, ClaErr:0.147, DisErr:0.537, RecLoss:0.846; E29: ClaCE:0.171, DisCE:0.900, TtlCE:-0.729, ClaErr:0.170, DisErr:0.541, RecLoss:0.822\n",
            "starting Epoch 30\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E30: trained class 150, trained aud 300\n",
            "DI:  0.1534368097782135\n",
            "DP:  0.09097426\n",
            "E30: ClaCE:0.150, DisCE:0.892, TtlCE:-0.742, ClaErr:0.147, DisErr:0.536, RecLoss:0.846; E30: ClaCE:0.171, DisCE:0.901, TtlCE:-0.730, ClaErr:0.170, DisErr:0.541, RecLoss:0.821\n",
            "starting Epoch 31\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E31: trained class 150, trained aud 300\n",
            "DI:  0.1591511070728302\n",
            "DP:  0.09033487\n",
            "E31: ClaCE:0.149, DisCE:0.893, TtlCE:-0.743, ClaErr:0.147, DisErr:0.536, RecLoss:0.845; E31: ClaCE:0.171, DisCE:0.901, TtlCE:-0.730, ClaErr:0.170, DisErr:0.541, RecLoss:0.821\n",
            "starting Epoch 32\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E32: trained class 150, trained aud 300\n",
            "DI:  0.1551899015903473\n",
            "DP:  0.090019606\n",
            "E32: ClaCE:0.149, DisCE:0.893, TtlCE:-0.744, ClaErr:0.147, DisErr:0.535, RecLoss:0.845; E32: ClaCE:0.171, DisCE:0.902, TtlCE:-0.731, ClaErr:0.171, DisErr:0.541, RecLoss:0.821\n",
            "starting Epoch 33\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E33: trained class 150, trained aud 300\n",
            "DI:  0.1537500023841858\n",
            "DP:  0.08874084\n",
            "E33: ClaCE:0.149, DisCE:0.894, TtlCE:-0.745, ClaErr:0.146, DisErr:0.534, RecLoss:0.844; E33: ClaCE:0.171, DisCE:0.904, TtlCE:-0.733, ClaErr:0.172, DisErr:0.541, RecLoss:0.820\n",
            "starting Epoch 34\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E34: trained class 150, trained aud 300\n",
            "DI:  0.16130658984184265\n",
            "DP:  0.08620103\n",
            "E34: ClaCE:0.149, DisCE:0.895, TtlCE:-0.746, ClaErr:0.146, DisErr:0.531, RecLoss:0.844; E34: ClaCE:0.171, DisCE:0.910, TtlCE:-0.739, ClaErr:0.172, DisErr:0.538, RecLoss:0.820\n",
            "starting Epoch 35\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E35: trained class 150, trained aud 300\n",
            "DI:  0.16098681092262268\n",
            "DP:  0.091595896\n",
            "E35: ClaCE:0.148, DisCE:0.895, TtlCE:-0.746, ClaErr:0.146, DisErr:0.501, RecLoss:0.844; E35: ClaCE:0.171, DisCE:0.926, TtlCE:-0.755, ClaErr:0.171, DisErr:0.534, RecLoss:0.821\n",
            "starting Epoch 36\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E36: trained class 150, trained aud 300\n",
            "DI:  0.15317580103874207\n",
            "DP:  0.09065012\n",
            "E36: ClaCE:0.148, DisCE:0.910, TtlCE:-0.761, ClaErr:0.146, DisErr:0.525, RecLoss:0.844; E36: ClaCE:0.171, DisCE:0.931, TtlCE:-0.760, ClaErr:0.171, DisErr:0.556, RecLoss:0.821\n",
            "starting Epoch 37\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E37: trained class 150, trained aud 300\n",
            "DI:  0.15827414393424988\n",
            "DP:  0.089406826\n",
            "E37: ClaCE:0.148, DisCE:0.908, TtlCE:-0.760, ClaErr:0.146, DisErr:0.552, RecLoss:0.844; E37: ClaCE:0.170, DisCE:0.916, TtlCE:-0.745, ClaErr:0.171, DisErr:0.557, RecLoss:0.820\n",
            "starting Epoch 38\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E38: trained class 150, trained aud 300\n",
            "DI:  0.1638166308403015\n",
            "DP:  0.08749754\n",
            "E38: ClaCE:0.148, DisCE:0.901, TtlCE:-0.753, ClaErr:0.145, DisErr:0.553, RecLoss:0.843; E38: ClaCE:0.170, DisCE:0.909, TtlCE:-0.739, ClaErr:0.171, DisErr:0.557, RecLoss:0.819\n",
            "starting Epoch 39\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E39: trained class 150, trained aud 300\n",
            "DI:  0.16462576389312744\n",
            "DP:  0.08719115\n",
            "E39: ClaCE:0.147, DisCE:0.898, TtlCE:-0.750, ClaErr:0.145, DisErr:0.553, RecLoss:0.843; E39: ClaCE:0.170, DisCE:0.906, TtlCE:-0.736, ClaErr:0.170, DisErr:0.556, RecLoss:0.819\n",
            "starting Epoch 40\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E40: trained class 150, trained aud 300\n",
            "DI:  0.16663986444473267\n",
            "DP:  0.08656064\n",
            "E40: ClaCE:0.147, DisCE:0.896, TtlCE:-0.749, ClaErr:0.145, DisErr:0.552, RecLoss:0.842; E40: ClaCE:0.170, DisCE:0.904, TtlCE:-0.734, ClaErr:0.171, DisErr:0.554, RecLoss:0.818\n",
            "starting Epoch 41\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E41: trained class 150, trained aud 300\n",
            "DI:  0.17579331994056702\n",
            "DP:  0.08558826\n",
            "E41: ClaCE:0.147, DisCE:0.895, TtlCE:-0.748, ClaErr:0.145, DisErr:0.551, RecLoss:0.842; E41: ClaCE:0.170, DisCE:0.903, TtlCE:-0.733, ClaErr:0.170, DisErr:0.553, RecLoss:0.818\n",
            "starting Epoch 42\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E42: trained class 150, trained aud 300\n",
            "DI:  0.16926990449428558\n",
            "DP:  0.08653402\n",
            "E42: ClaCE:0.147, DisCE:0.894, TtlCE:-0.747, ClaErr:0.145, DisErr:0.549, RecLoss:0.841; E42: ClaCE:0.170, DisCE:0.902, TtlCE:-0.731, ClaErr:0.171, DisErr:0.551, RecLoss:0.818\n",
            "starting Epoch 43\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E43: trained class 150, trained aud 300\n",
            "DI:  0.16926990449428558\n",
            "DP:  0.08653402\n",
            "E43: ClaCE:0.147, DisCE:0.894, TtlCE:-0.747, ClaErr:0.145, DisErr:0.548, RecLoss:0.841; E43: ClaCE:0.170, DisCE:0.901, TtlCE:-0.730, ClaErr:0.171, DisErr:0.550, RecLoss:0.817\n",
            "starting Epoch 44\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E44: trained class 150, trained aud 300\n",
            "DI:  0.17434686422348022\n",
            "DP:  0.087470934\n",
            "E44: ClaCE:0.147, DisCE:0.893, TtlCE:-0.747, ClaErr:0.145, DisErr:0.545, RecLoss:0.841; E44: ClaCE:0.171, DisCE:0.901, TtlCE:-0.730, ClaErr:0.171, DisErr:0.549, RecLoss:0.817\n",
            "starting Epoch 45\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E45: trained class 150, trained aud 300\n",
            "DI:  0.17934121191501617\n",
            "DP:  0.08619216\n",
            "E45: ClaCE:0.147, DisCE:0.894, TtlCE:-0.747, ClaErr:0.145, DisErr:0.543, RecLoss:0.840; E45: ClaCE:0.171, DisCE:0.902, TtlCE:-0.730, ClaErr:0.171, DisErr:0.548, RecLoss:0.817\n",
            "starting Epoch 46\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E46: trained class 150, trained aud 300\n",
            "DI:  0.18063536286354065\n",
            "DP:  0.084922254\n",
            "E46: ClaCE:0.147, DisCE:0.895, TtlCE:-0.748, ClaErr:0.144, DisErr:0.543, RecLoss:0.840; E46: ClaCE:0.171, DisCE:0.902, TtlCE:-0.731, ClaErr:0.172, DisErr:0.547, RecLoss:0.817\n",
            "starting Epoch 47\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E47: trained class 150, trained aud 300\n",
            "DI:  0.17411193251609802\n",
            "DP:  0.08586803\n",
            "E47: ClaCE:0.146, DisCE:0.896, TtlCE:-0.749, ClaErr:0.144, DisErr:0.543, RecLoss:0.840; E47: ClaCE:0.172, DisCE:0.904, TtlCE:-0.732, ClaErr:0.172, DisErr:0.546, RecLoss:0.816\n",
            "starting Epoch 48\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E48: trained class 150, trained aud 300\n",
            "DI:  0.16566362977027893\n",
            "DP:  0.08649856\n",
            "E48: ClaCE:0.146, DisCE:0.897, TtlCE:-0.751, ClaErr:0.145, DisErr:0.543, RecLoss:0.840; E48: ClaCE:0.172, DisCE:0.904, TtlCE:-0.733, ClaErr:0.172, DisErr:0.547, RecLoss:0.816\n",
            "starting Epoch 49\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E49: trained class 150, trained aud 300\n",
            "DI:  0.16347770392894745\n",
            "DP:  0.085859165\n",
            "E49: ClaCE:0.146, DisCE:0.897, TtlCE:-0.751, ClaErr:0.145, DisErr:0.543, RecLoss:0.840; E49: ClaCE:0.172, DisCE:0.907, TtlCE:-0.736, ClaErr:0.172, DisErr:0.547, RecLoss:0.816\n",
            "starting Epoch 50\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E50: trained class 150, trained aud 300\n",
            "DI:  0.1737273931503296\n",
            "DP:  0.08362575\n",
            "(4736, 1)\n",
            "(4736, 8)\n",
            "(4736, 1)\n",
            "(4736, 1)\n",
            "(4736, 1)\n",
            "Test score: Class CE: 0.172, Disc CE: 0.902, Ttl CE: -0.730, Class Err: 0.172 Disc Err: 0.518\n",
            "Error Rate: 0.172,  DI: 0.087, di_FP: 0.017, di_FN: 0.156\n",
            "Error Rate (A): 0.518\n",
            "\n",
            "Predicting Y\n",
            "A=?: Base PR: 0.247, Base NR: 0.753,  PR: 0.186, NR: 0.814, Err: 0.172, TPR: 0.530, FNR: 0.470, TNR: 0.926, FPR: 0.074\n",
            "A=1: Base PR: 0.112, Base NR: 0.888,  PR: 0.130, NR: 0.870, Err: 0.094, TPR: 0.663, FNR: 0.337, TNR: 0.937, FPR: 0.063\n",
            "A=0: Base PR: 0.313, Base NR: 0.687,  PR: 0.214, NR: 0.786, Err: 0.210, TPR: 0.507, FNR: 0.493, TNR: 0.919, FPR: 0.081\n",
            "ACor: Base PR: 0.313, Base NR: 0.687,  PR: 0.297, NR: 0.703, Err: 0.171, TPR: 0.701, FNR: 0.299, TNR: 0.888, FPR: 0.112\n",
            "AWro: Base PR: 0.184, Base NR: 0.816,  PR: 0.084, NR: 0.916, Err: 0.173, TPR: 0.259, FNR: 0.741, TNR: 0.956, FPR: 0.044\n",
            "\n",
            "Predicting A\n",
            "Y=?: Base-A1-rate: 0.330, Base-A0-rate: 0.670, Pred A1-rate: 0.688, Pred-A0-rate: 0.312, Err: 0.518, A1-Correct: 0.758, A1-Wrong: 0.242, A0-Correct: 0.346, A0-Wrong: 0.654\n",
            "Y=1: Base-A1-rate: 0.150, Base-A0-rate: 0.850, Pred A1-rate: 0.287, Pred-A0-rate: 0.713, Err: 0.387, A1-Correct: 0.166, A1-Wrong: 0.834, A0-Correct: 0.692, A0-Wrong: 0.308\n",
            "Y=0: Base-A1-rate: 0.389, Base-A0-rate: 0.611, Pred A1-rate: 0.820, Pred-A0-rate: 0.180, Err: 0.561, A1-Correct: 0.833, A1-Wrong: 0.167, A0-Correct: 0.189, A0-Wrong: 0.811\n",
            "YCor: Base-A1-rate: 0.361, Base-A0-rate: 0.639, Pred A1-rate: 0.745, Pred-A0-rate: 0.255, Err: 0.517, A1-Correct: 0.816, A1-Wrong: 0.184, A0-Correct: 0.294, A0-Wrong: 0.706\n",
            "YWro: Base-A1-rate: 0.181, Base-A0-rate: 0.819, Pred A1-rate: 0.413, Pred-A0-rate: 0.587, Err: 0.520, A1-Correct: 0.204, A1-Wrong: 0.796, A0-Correct: 0.541, A0-Wrong: 0.459\n",
            "Metrics saved to ./experiments/laftr_example/Adult_Exp_1/checkpoints/Epoch_50_Valid/test_metrics.csv\n",
            "(5888, 1)\n",
            "(5888, 8)\n",
            "(5888, 1)\n",
            "(5888, 1)\n",
            "(5888, 1)\n",
            "Test score: Class CE: 0.161, Disc CE: 0.898, Ttl CE: -0.737, Class Err: 0.160 Disc Err: 0.517\n",
            "Error Rate: 0.160,  DI: 0.063, di_FP: 0.008, di_FN: 0.117\n",
            "Error Rate (A): 0.517\n",
            "\n",
            "Predicting Y\n",
            "A=?: Base PR: 0.250, Base NR: 0.750,  PR: 0.193, NR: 0.807, Err: 0.160, TPR: 0.565, FNR: 0.435, TNR: 0.931, FPR: 0.069\n",
            "A=1: Base PR: 0.113, Base NR: 0.887,  PR: 0.132, NR: 0.868, Err: 0.094, TPR: 0.665, FNR: 0.335, TNR: 0.936, FPR: 0.064\n",
            "A=0: Base PR: 0.314, Base NR: 0.686,  PR: 0.221, NR: 0.779, Err: 0.191, TPR: 0.548, FNR: 0.452, TNR: 0.928, FPR: 0.072\n",
            "ACor: Base PR: 0.334, Base NR: 0.666,  PR: 0.312, NR: 0.688, Err: 0.161, TPR: 0.725, FNR: 0.275, TNR: 0.896, FPR: 0.104\n",
            "AWro: Base PR: 0.171, Base NR: 0.829,  PR: 0.081, NR: 0.919, Err: 0.159, TPR: 0.271, FNR: 0.729, TNR: 0.958, FPR: 0.042\n",
            "\n",
            "Predicting A\n",
            "Y=?: Base-A1-rate: 0.319, Base-A0-rate: 0.681, Pred A1-rate: 0.679, Pred-A0-rate: 0.321, Err: 0.517, A1-Correct: 0.754, A1-Wrong: 0.246, A0-Correct: 0.357, A0-Wrong: 0.643\n",
            "Y=1: Base-A1-rate: 0.144, Base-A0-rate: 0.856, Pred A1-rate: 0.261, Pred-A0-rate: 0.739, Err: 0.354, A1-Correct: 0.179, A1-Wrong: 0.821, A0-Correct: 0.725, A0-Wrong: 0.275\n",
            "Y=0: Base-A1-rate: 0.377, Base-A0-rate: 0.623, Pred A1-rate: 0.818, Pred-A0-rate: 0.182, Err: 0.571, A1-Correct: 0.828, A1-Wrong: 0.172, A0-Correct: 0.188, A0-Wrong: 0.812\n",
            "YCor: Base-A1-rate: 0.344, Base-A0-rate: 0.656, Pred A1-rate: 0.731, Pred-A0-rate: 0.269, Err: 0.517, A1-Correct: 0.810, A1-Wrong: 0.190, A0-Correct: 0.311, A0-Wrong: 0.689\n",
            "YWro: Base-A1-rate: 0.188, Base-A0-rate: 0.812, Pred A1-rate: 0.407, Pred-A0-rate: 0.593, Err: 0.514, A1-Correct: 0.215, A1-Wrong: 0.785, A0-Correct: 0.549, A0-Wrong: 0.451\n",
            "Metrics saved to ./experiments/laftr_example/Adult_Exp_1/checkpoints/Epoch_50_Test/test_metrics.csv\n",
            "E50: ClaCE:0.146, DisCE:0.896, TtlCE:-0.749, ClaErr:0.145, DisErr:0.537, RecLoss:0.839; E50: ClaCE:0.172, DisCE:0.902, TtlCE:-0.730, ClaErr:0.172, DisErr:0.518, RecLoss:0.816\n",
            "starting Epoch 51\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E51: trained class 150, trained aud 300\n",
            "DI:  0.17935249209403992\n",
            "DP:  0.08393213\n",
            "E51: ClaCE:0.146, DisCE:0.880, TtlCE:-0.734, ClaErr:0.145, DisErr:0.481, RecLoss:0.840; E51: ClaCE:0.172, DisCE:0.913, TtlCE:-0.742, ClaErr:0.172, DisErr:0.521, RecLoss:0.816\n",
            "starting Epoch 52\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E52: trained class 150, trained aud 300\n",
            "DI:  0.18027034401893616\n",
            "DP:  0.084562644\n",
            "E52: ClaCE:0.146, DisCE:0.897, TtlCE:-0.750, ClaErr:0.145, DisErr:0.515, RecLoss:0.840; E52: ClaCE:0.172, DisCE:0.925, TtlCE:-0.753, ClaErr:0.172, DisErr:0.542, RecLoss:0.816\n",
            "starting Epoch 53\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E53: trained class 150, trained aud 300\n",
            "DI:  0.18162761628627777\n",
            "DP:  0.08362575\n",
            "E53: ClaCE:0.147, DisCE:0.906, TtlCE:-0.760, ClaErr:0.145, DisErr:0.540, RecLoss:0.840; E53: ClaCE:0.172, DisCE:0.927, TtlCE:-0.756, ClaErr:0.172, DisErr:0.563, RecLoss:0.816\n",
            "starting Epoch 54\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E54: trained class 150, trained aud 300\n",
            "DI:  0.1799006164073944\n",
            "DP:  0.08330162\n",
            "E54: ClaCE:0.146, DisCE:0.909, TtlCE:-0.763, ClaErr:0.144, DisErr:0.553, RecLoss:0.840; E54: ClaCE:0.172, DisCE:0.922, TtlCE:-0.750, ClaErr:0.172, DisErr:0.562, RecLoss:0.816\n",
            "starting Epoch 55\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E55: trained class 150, trained aud 300\n",
            "DI:  0.18237364292144775\n",
            "DP:  0.082986355\n",
            "E55: ClaCE:0.146, DisCE:0.905, TtlCE:-0.759, ClaErr:0.144, DisErr:0.555, RecLoss:0.839; E55: ClaCE:0.172, DisCE:0.915, TtlCE:-0.743, ClaErr:0.172, DisErr:0.558, RecLoss:0.816\n",
            "starting Epoch 56\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E56: trained class 150, trained aud 300\n",
            "DI:  0.18401801586151123\n",
            "DP:  0.0810948\n",
            "E56: ClaCE:0.146, DisCE:0.901, TtlCE:-0.755, ClaErr:0.144, DisErr:0.553, RecLoss:0.839; E56: ClaCE:0.172, DisCE:0.910, TtlCE:-0.738, ClaErr:0.172, DisErr:0.555, RecLoss:0.815\n",
            "starting Epoch 57\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E57: trained class 150, trained aud 300\n",
            "DI:  0.18329808115959167\n",
            "DP:  0.08045542\n",
            "E57: ClaCE:0.146, DisCE:0.899, TtlCE:-0.753, ClaErr:0.144, DisErr:0.553, RecLoss:0.839; E57: ClaCE:0.172, DisCE:0.907, TtlCE:-0.735, ClaErr:0.173, DisErr:0.554, RecLoss:0.815\n",
            "starting Epoch 58\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E58: trained class 150, trained aud 300\n",
            "DI:  0.18973228335380554\n",
            "DP:  0.08045542\n",
            "E58: ClaCE:0.146, DisCE:0.899, TtlCE:-0.753, ClaErr:0.144, DisErr:0.552, RecLoss:0.839; E58: ClaCE:0.172, DisCE:0.906, TtlCE:-0.734, ClaErr:0.172, DisErr:0.552, RecLoss:0.815\n",
            "starting Epoch 59\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E59: trained class 150, trained aud 300\n",
            "DI:  0.1857040822505951\n",
            "DP:  0.08171646\n",
            "E59: ClaCE:0.146, DisCE:0.898, TtlCE:-0.753, ClaErr:0.144, DisErr:0.551, RecLoss:0.838; E59: ClaCE:0.172, DisCE:0.906, TtlCE:-0.734, ClaErr:0.171, DisErr:0.550, RecLoss:0.815\n",
            "starting Epoch 60\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E60: trained class 150, trained aud 300\n",
            "DI:  0.19089636206626892\n",
            "DP:  0.080428824\n",
            "E60: ClaCE:0.146, DisCE:0.898, TtlCE:-0.753, ClaErr:0.144, DisErr:0.550, RecLoss:0.838; E60: ClaCE:0.172, DisCE:0.906, TtlCE:-0.734, ClaErr:0.172, DisErr:0.550, RecLoss:0.814\n",
            "starting Epoch 61\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E61: trained class 150, trained aud 300\n",
            "DI:  0.19041132926940918\n",
            "DP:  0.08139232\n",
            "E61: ClaCE:0.146, DisCE:0.898, TtlCE:-0.753, ClaErr:0.144, DisErr:0.550, RecLoss:0.838; E61: ClaCE:0.172, DisCE:0.905, TtlCE:-0.733, ClaErr:0.171, DisErr:0.548, RecLoss:0.814\n",
            "starting Epoch 62\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E62: trained class 150, trained aud 300\n",
            "DI:  0.1867937594652176\n",
            "DP:  0.08361687\n",
            "E62: ClaCE:0.146, DisCE:0.898, TtlCE:-0.752, ClaErr:0.144, DisErr:0.549, RecLoss:0.838; E62: ClaCE:0.172, DisCE:0.905, TtlCE:-0.733, ClaErr:0.171, DisErr:0.548, RecLoss:0.814\n",
            "starting Epoch 63\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E63: trained class 150, trained aud 300\n",
            "DI:  0.176714226603508\n",
            "DP:  0.07981603\n",
            "E63: ClaCE:0.146, DisCE:0.898, TtlCE:-0.753, ClaErr:0.144, DisErr:0.549, RecLoss:0.838; E63: ClaCE:0.172, DisCE:0.905, TtlCE:-0.733, ClaErr:0.171, DisErr:0.548, RecLoss:0.814\n",
            "starting Epoch 64\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E64: trained class 150, trained aud 300\n",
            "DI:  0.17642712593078613\n",
            "DP:  0.080770686\n",
            "E64: ClaCE:0.145, DisCE:0.898, TtlCE:-0.753, ClaErr:0.144, DisErr:0.549, RecLoss:0.838; E64: ClaCE:0.171, DisCE:0.905, TtlCE:-0.734, ClaErr:0.171, DisErr:0.547, RecLoss:0.814\n",
            "starting Epoch 65\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E65: trained class 150, trained aud 300\n",
            "DI:  0.17731887102127075\n",
            "DP:  0.08267997\n",
            "E65: ClaCE:0.145, DisCE:0.899, TtlCE:-0.753, ClaErr:0.144, DisErr:0.549, RecLoss:0.837; E65: ClaCE:0.171, DisCE:0.905, TtlCE:-0.734, ClaErr:0.170, DisErr:0.549, RecLoss:0.814\n",
            "starting Epoch 66\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E66: trained class 150, trained aud 300\n",
            "DI:  0.17677074670791626\n",
            "DP:  0.083310485\n",
            "E66: ClaCE:0.145, DisCE:0.899, TtlCE:-0.754, ClaErr:0.144, DisErr:0.550, RecLoss:0.837; E66: ClaCE:0.171, DisCE:0.906, TtlCE:-0.735, ClaErr:0.170, DisErr:0.550, RecLoss:0.814\n",
            "starting Epoch 67\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E67: trained class 150, trained aud 300\n",
            "DI:  0.17794963717460632\n",
            "DP:  0.08426513\n",
            "E67: ClaCE:0.145, DisCE:0.899, TtlCE:-0.753, ClaErr:0.144, DisErr:0.549, RecLoss:0.837; E67: ClaCE:0.171, DisCE:0.906, TtlCE:-0.735, ClaErr:0.170, DisErr:0.548, RecLoss:0.813\n",
            "starting Epoch 68\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E68: trained class 150, trained aud 300\n",
            "DI:  0.1780388206243515\n",
            "DP:  0.08331935\n",
            "E68: ClaCE:0.145, DisCE:0.894, TtlCE:-0.749, ClaErr:0.144, DisErr:0.538, RecLoss:0.837; E68: ClaCE:0.171, DisCE:0.893, TtlCE:-0.722, ClaErr:0.170, DisErr:0.500, RecLoss:0.814\n",
            "starting Epoch 69\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E69: trained class 150, trained aud 300\n",
            "DI:  0.18171681463718414\n",
            "DP:  0.08267997\n",
            "E69: ClaCE:0.145, DisCE:0.875, TtlCE:-0.730, ClaErr:0.144, DisErr:0.480, RecLoss:0.837; E69: ClaCE:0.172, DisCE:0.906, TtlCE:-0.734, ClaErr:0.171, DisErr:0.529, RecLoss:0.814\n",
            "starting Epoch 70\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E70: trained class 150, trained aud 300\n",
            "DI:  0.18769210577011108\n",
            "DP:  0.08236471\n",
            "E70: ClaCE:0.145, DisCE:0.889, TtlCE:-0.744, ClaErr:0.144, DisErr:0.516, RecLoss:0.838; E70: ClaCE:0.171, DisCE:0.918, TtlCE:-0.747, ClaErr:0.171, DisErr:0.549, RecLoss:0.814\n",
            "starting Epoch 71\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E71: trained class 150, trained aud 300\n",
            "DI:  0.18070976436138153\n",
            "DP:  0.082995236\n",
            "E71: ClaCE:0.145, DisCE:0.900, TtlCE:-0.755, ClaErr:0.144, DisErr:0.540, RecLoss:0.838; E71: ClaCE:0.171, DisCE:0.921, TtlCE:-0.750, ClaErr:0.171, DisErr:0.554, RecLoss:0.814\n",
            "starting Epoch 72\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E72: trained class 150, trained aud 300\n",
            "DI:  0.17525649070739746\n",
            "DP:  0.083958745\n",
            "E72: ClaCE:0.145, DisCE:0.902, TtlCE:-0.757, ClaErr:0.144, DisErr:0.548, RecLoss:0.838; E72: ClaCE:0.171, DisCE:0.919, TtlCE:-0.748, ClaErr:0.171, DisErr:0.557, RecLoss:0.814\n",
            "starting Epoch 73\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E73: trained class 150, trained aud 300\n",
            "DI:  0.1759829968214035\n",
            "DP:  0.08143668\n",
            "E73: ClaCE:0.145, DisCE:0.901, TtlCE:-0.756, ClaErr:0.144, DisErr:0.552, RecLoss:0.838; E73: ClaCE:0.171, DisCE:0.915, TtlCE:-0.744, ClaErr:0.171, DisErr:0.555, RecLoss:0.814\n",
            "starting Epoch 74\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E74: trained class 150, trained aud 300\n",
            "DI:  0.17644192278385162\n",
            "DP:  0.08175194\n",
            "E74: ClaCE:0.145, DisCE:0.900, TtlCE:-0.755, ClaErr:0.144, DisErr:0.553, RecLoss:0.837; E74: ClaCE:0.171, DisCE:0.912, TtlCE:-0.741, ClaErr:0.171, DisErr:0.555, RecLoss:0.814\n",
            "starting Epoch 75\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E75: trained class 150, trained aud 300\n",
            "DI:  0.17370787262916565\n",
            "DP:  0.08174306\n",
            "E75: ClaCE:0.145, DisCE:0.898, TtlCE:-0.753, ClaErr:0.144, DisErr:0.551, RecLoss:0.837; E75: ClaCE:0.171, DisCE:0.910, TtlCE:-0.739, ClaErr:0.171, DisErr:0.552, RecLoss:0.814\n",
            "starting Epoch 76\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E76: trained class 150, trained aud 300\n",
            "DI:  0.1729879379272461\n",
            "DP:  0.08110368\n",
            "E76: ClaCE:0.145, DisCE:0.898, TtlCE:-0.753, ClaErr:0.144, DisErr:0.548, RecLoss:0.837; E76: ClaCE:0.171, DisCE:0.909, TtlCE:-0.738, ClaErr:0.171, DisErr:0.551, RecLoss:0.814\n",
            "starting Epoch 77\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E77: trained class 150, trained aud 300\n",
            "DI:  0.17962008714675903\n",
            "DP:  0.0810948\n",
            "E77: ClaCE:0.145, DisCE:0.898, TtlCE:-0.753, ClaErr:0.144, DisErr:0.548, RecLoss:0.837; E77: ClaCE:0.171, DisCE:0.909, TtlCE:-0.738, ClaErr:0.171, DisErr:0.547, RecLoss:0.813\n",
            "starting Epoch 78\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E78: trained class 150, trained aud 300\n",
            "DI:  0.17097383737564087\n",
            "DP:  0.081734195\n",
            "E78: ClaCE:0.145, DisCE:0.898, TtlCE:-0.753, ClaErr:0.143, DisErr:0.544, RecLoss:0.837; E78: ClaCE:0.171, DisCE:0.910, TtlCE:-0.739, ClaErr:0.170, DisErr:0.546, RecLoss:0.813\n",
            "starting Epoch 79\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E79: trained class 150, trained aud 300\n",
            "DI:  0.17016470432281494\n",
            "DP:  0.08204058\n",
            "E79: ClaCE:0.145, DisCE:0.898, TtlCE:-0.753, ClaErr:0.143, DisErr:0.541, RecLoss:0.837; E79: ClaCE:0.171, DisCE:0.912, TtlCE:-0.741, ClaErr:0.171, DisErr:0.546, RecLoss:0.813\n",
            "starting Epoch 80\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E80: trained class 150, trained aud 300\n",
            "DI:  0.17171987891197205\n",
            "DP:  0.0810948\n",
            "E80: ClaCE:0.145, DisCE:0.898, TtlCE:-0.753, ClaErr:0.143, DisErr:0.543, RecLoss:0.837; E80: ClaCE:0.171, DisCE:0.913, TtlCE:-0.742, ClaErr:0.171, DisErr:0.548, RecLoss:0.813\n",
            "starting Epoch 81\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E81: trained class 150, trained aud 300\n",
            "DI:  0.1793590784072876\n",
            "DP:  0.080770686\n",
            "E81: ClaCE:0.145, DisCE:0.899, TtlCE:-0.755, ClaErr:0.143, DisErr:0.547, RecLoss:0.837; E81: ClaCE:0.171, DisCE:0.914, TtlCE:-0.742, ClaErr:0.171, DisErr:0.552, RecLoss:0.813\n",
            "starting Epoch 82\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E82: trained class 150, trained aud 300\n",
            "DI:  0.17781047523021698\n",
            "DP:  0.078555\n",
            "E82: ClaCE:0.145, DisCE:0.900, TtlCE:-0.755, ClaErr:0.143, DisErr:0.550, RecLoss:0.837; E82: ClaCE:0.171, DisCE:0.914, TtlCE:-0.743, ClaErr:0.171, DisErr:0.554, RecLoss:0.813\n",
            "starting Epoch 83\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E83: trained class 150, trained aud 300\n",
            "DI:  0.17907854914665222\n",
            "DP:  0.07856387\n",
            "E83: ClaCE:0.145, DisCE:0.900, TtlCE:-0.755, ClaErr:0.143, DisErr:0.552, RecLoss:0.837; E83: ClaCE:0.171, DisCE:0.914, TtlCE:-0.743, ClaErr:0.171, DisErr:0.555, RecLoss:0.813\n",
            "starting Epoch 84\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E84: trained class 150, trained aud 300\n",
            "DI:  0.1661013513803482\n",
            "DP:  0.07762696\n",
            "E84: ClaCE:0.145, DisCE:0.901, TtlCE:-0.756, ClaErr:0.143, DisErr:0.553, RecLoss:0.837; E84: ClaCE:0.171, DisCE:0.914, TtlCE:-0.742, ClaErr:0.171, DisErr:0.557, RecLoss:0.813\n",
            "starting Epoch 85\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E85: trained class 150, trained aud 300\n",
            "DI:  0.17319242656230927\n",
            "DP:  0.077933356\n",
            "E85: ClaCE:0.145, DisCE:0.901, TtlCE:-0.756, ClaErr:0.143, DisErr:0.554, RecLoss:0.837; E85: ClaCE:0.171, DisCE:0.914, TtlCE:-0.743, ClaErr:0.171, DisErr:0.556, RecLoss:0.813\n",
            "starting Epoch 86\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E86: trained class 150, trained aud 300\n",
            "DI:  0.17163725197315216\n",
            "DP:  0.07887913\n",
            "E86: ClaCE:0.144, DisCE:0.901, TtlCE:-0.756, ClaErr:0.143, DisErr:0.553, RecLoss:0.837; E86: ClaCE:0.171, DisCE:0.913, TtlCE:-0.742, ClaErr:0.171, DisErr:0.556, RecLoss:0.813\n",
            "starting Epoch 87\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E87: trained class 150, trained aud 300\n",
            "DI:  0.17218537628650665\n",
            "DP:  0.07824862\n",
            "E87: ClaCE:0.144, DisCE:0.900, TtlCE:-0.756, ClaErr:0.143, DisErr:0.552, RecLoss:0.837; E87: ClaCE:0.171, DisCE:0.912, TtlCE:-0.741, ClaErr:0.171, DisErr:0.557, RecLoss:0.813\n",
            "starting Epoch 88\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E88: trained class 150, trained aud 300\n",
            "DI:  0.1741102784872055\n",
            "DP:  0.07856387\n",
            "E88: ClaCE:0.144, DisCE:0.900, TtlCE:-0.756, ClaErr:0.143, DisErr:0.548, RecLoss:0.837; E88: ClaCE:0.171, DisCE:0.912, TtlCE:-0.741, ClaErr:0.172, DisErr:0.557, RecLoss:0.813\n",
            "starting Epoch 89\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E89: trained class 150, trained aud 300\n",
            "DI:  0.16239461302757263\n",
            "DP:  0.080797285\n",
            "E89: ClaCE:0.144, DisCE:0.900, TtlCE:-0.756, ClaErr:0.143, DisErr:0.551, RecLoss:0.837; E89: ClaCE:0.171, DisCE:0.911, TtlCE:-0.740, ClaErr:0.172, DisErr:0.558, RecLoss:0.813\n",
            "starting Epoch 90\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E90: trained class 150, trained aud 300\n",
            "DI:  0.16810888051986694\n",
            "DP:  0.080157906\n",
            "E90: ClaCE:0.144, DisCE:0.901, TtlCE:-0.756, ClaErr:0.143, DisErr:0.552, RecLoss:0.837; E90: ClaCE:0.171, DisCE:0.911, TtlCE:-0.740, ClaErr:0.171, DisErr:0.558, RecLoss:0.813\n",
            "starting Epoch 91\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E91: trained class 150, trained aud 300\n",
            "DI:  0.16940303146839142\n",
            "DP:  0.078888\n",
            "E91: ClaCE:0.144, DisCE:0.901, TtlCE:-0.757, ClaErr:0.143, DisErr:0.552, RecLoss:0.837; E91: ClaCE:0.172, DisCE:0.912, TtlCE:-0.740, ClaErr:0.172, DisErr:0.558, RecLoss:0.813\n",
            "starting Epoch 92\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E92: trained class 150, trained aud 300\n",
            "DI:  0.16029131412506104\n",
            "DP:  0.082373574\n",
            "E92: ClaCE:0.144, DisCE:0.900, TtlCE:-0.756, ClaErr:0.143, DisErr:0.552, RecLoss:0.837; E92: ClaCE:0.172, DisCE:0.910, TtlCE:-0.738, ClaErr:0.171, DisErr:0.557, RecLoss:0.813\n",
            "starting Epoch 93\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E93: trained class 150, trained aud 300\n",
            "DI:  0.1615854650735855\n",
            "DP:  0.08110368\n",
            "E93: ClaCE:0.144, DisCE:0.900, TtlCE:-0.756, ClaErr:0.143, DisErr:0.553, RecLoss:0.836; E93: ClaCE:0.172, DisCE:0.911, TtlCE:-0.739, ClaErr:0.172, DisErr:0.557, RecLoss:0.813\n",
            "starting Epoch 94\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E94: trained class 150, trained aud 300\n",
            "DI:  0.1526930034160614\n",
            "DP:  0.08240019\n",
            "E94: ClaCE:0.144, DisCE:0.900, TtlCE:-0.756, ClaErr:0.143, DisErr:0.553, RecLoss:0.836; E94: ClaCE:0.172, DisCE:0.910, TtlCE:-0.738, ClaErr:0.172, DisErr:0.557, RecLoss:0.813\n",
            "starting Epoch 95\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E95: trained class 150, trained aud 300\n",
            "DI:  0.15613219141960144\n",
            "DP:  0.08206719\n",
            "E95: ClaCE:0.144, DisCE:0.899, TtlCE:-0.755, ClaErr:0.143, DisErr:0.552, RecLoss:0.836; E95: ClaCE:0.172, DisCE:0.910, TtlCE:-0.738, ClaErr:0.172, DisErr:0.556, RecLoss:0.813\n",
            "starting Epoch 96\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E96: trained class 150, trained aud 300\n",
            "DI:  0.15021997690200806\n",
            "DP:  0.08271545\n",
            "E96: ClaCE:0.144, DisCE:0.898, TtlCE:-0.754, ClaErr:0.143, DisErr:0.552, RecLoss:0.836; E96: ClaCE:0.172, DisCE:0.910, TtlCE:-0.738, ClaErr:0.171, DisErr:0.557, RecLoss:0.813\n",
            "starting Epoch 97\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E97: trained class 150, trained aud 300\n",
            "DI:  0.1614701747894287\n",
            "DP:  0.08332823\n",
            "E97: ClaCE:0.144, DisCE:0.898, TtlCE:-0.755, ClaErr:0.143, DisErr:0.552, RecLoss:0.836; E97: ClaCE:0.172, DisCE:0.908, TtlCE:-0.737, ClaErr:0.171, DisErr:0.556, RecLoss:0.813\n",
            "starting Epoch 98\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E98: trained class 150, trained aud 300\n",
            "DI:  0.1585160195827484\n",
            "DP:  0.082697704\n",
            "E98: ClaCE:0.144, DisCE:0.898, TtlCE:-0.754, ClaErr:0.143, DisErr:0.552, RecLoss:0.836; E98: ClaCE:0.172, DisCE:0.907, TtlCE:-0.734, ClaErr:0.173, DisErr:0.554, RecLoss:0.813\n",
            "starting Epoch 99\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E99: trained class 150, trained aud 300\n",
            "DI:  0.16348427534103394\n",
            "DP:  0.082697704\n",
            "E99: ClaCE:0.144, DisCE:0.898, TtlCE:-0.753, ClaErr:0.143, DisErr:0.552, RecLoss:0.836; E99: ClaCE:0.172, DisCE:0.907, TtlCE:-0.734, ClaErr:0.172, DisErr:0.555, RecLoss:0.813\n",
            "Finished training: min validation loss was -0.771 in epoch 20\n",
            "(5888, 1)\n",
            "(5888, 8)\n",
            "(5888, 1)\n",
            "(5888, 1)\n",
            "(5888, 1)\n",
            "Test score: Class CE: 0.160, Disc CE: 0.910, Ttl CE: -0.750, Class Err: 0.160 Disc Err: 0.562\n",
            "Error Rate: 0.160,  DI: 0.058, di_FP: 0.006, di_FN: 0.110\n",
            "Error Rate (A): 0.562\n",
            "\n",
            "Predicting Y\n",
            "A=?: Base PR: 0.250, Base NR: 0.750,  PR: 0.191, NR: 0.809, Err: 0.160, TPR: 0.562, FNR: 0.438, TNR: 0.932, FPR: 0.068\n",
            "A=1: Base PR: 0.113, Base NR: 0.887,  PR: 0.131, NR: 0.869, Err: 0.095, TPR: 0.656, FNR: 0.344, TNR: 0.936, FPR: 0.064\n",
            "A=0: Base PR: 0.314, Base NR: 0.686,  PR: 0.219, NR: 0.781, Err: 0.190, TPR: 0.546, FNR: 0.454, TNR: 0.930, FPR: 0.070\n",
            "ACor: Base PR: 0.305, Base NR: 0.695,  PR: 0.342, NR: 0.658, Err: 0.118, TPR: 0.867, FNR: 0.133, TNR: 0.889, FPR: 0.111\n",
            "AWro: Base PR: 0.206, Base NR: 0.794,  PR: 0.074, NR: 0.926, Err: 0.193, TPR: 0.211, FNR: 0.789, TNR: 0.962, FPR: 0.038\n",
            "\n",
            "Predicting A\n",
            "Y=?: Base-A1-rate: 0.319, Base-A0-rate: 0.681, Pred A1-rate: 0.788, Pred-A0-rate: 0.212, Err: 0.562, A1-Correct: 0.854, A1-Wrong: 0.146, A0-Correct: 0.243, A0-Wrong: 0.757\n",
            "Y=1: Base-A1-rate: 0.144, Base-A0-rate: 0.856, Pred A1-rate: 0.407, Pred-A0-rate: 0.593, Err: 0.465, A1-Correct: 0.302, A1-Wrong: 0.698, A0-Correct: 0.575, A0-Wrong: 0.425\n",
            "Y=0: Base-A1-rate: 0.377, Base-A0-rate: 0.623, Pred A1-rate: 0.914, Pred-A0-rate: 0.086, Err: 0.594, A1-Correct: 0.925, A1-Wrong: 0.075, A0-Correct: 0.092, A0-Wrong: 0.908\n",
            "YCor: Base-A1-rate: 0.343, Base-A0-rate: 0.657, Pred A1-rate: 0.816, Pred-A0-rate: 0.184, Err: 0.540, A1-Correct: 0.902, A1-Wrong: 0.098, A0-Correct: 0.229, A0-Wrong: 0.771\n",
            "YWro: Base-A1-rate: 0.190, Base-A0-rate: 0.810, Pred A1-rate: 0.641, Pred-A0-rate: 0.359, Err: 0.678, A1-Correct: 0.402, A1-Wrong: 0.598, A0-Correct: 0.304, A0-Wrong: 0.696\n",
            "Metrics saved to ./experiments/laftr_example/Adult_Exp_1/test_metrics.csv\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/envs/myenv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "{'exp_name': 'laftr_example/Adult_Exp_1/Exp_1_classification_transfer', 'train': {'n_epochs': '100', 'aud_steps': '2', 'batch_size': '128'}, 'model': {'recon_coeff': '1', 'fair_coeff': '0.1'}, 'optim': {'learning_rate': '0.0005'}, 'transfer': {'n_epochs': '100', 'epoch_number': '50'}}\n",
            "opt_filename ./experiments/laftr_example/Adult_Exp_1/opt.json\n",
            "done_filename_txt ./experiments/laftr_example/Adult_Exp_1/done.txt\n",
            "done_filename_json ./experiments/laftr_example/Adult_Exp_1/done.json\n",
            "./experiments/laftr_example/Adult_Exp_1/checkpoints/Epoch_50_Test/npz\n",
            "./experiments/laftr_example/Adult_Exp_1/checkpoints/Epoch_50_Test/npz\n",
            "shapes (5888, 8) (5888, 1) (5888, 1)\n",
            "y shape (24157, 2)\n",
            "changing shape\n",
            "(5888, 8) (5888, 1) (5888, 1)\n",
            "2024-06-19 17:40:32.506361: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "starting Epoch 0\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E0: trained class 25, trained aud 0\n",
            "DI:  0.1684049367904663\n",
            "DP:  0.05672127\n",
            "E0: ClaCE:6.923, DisCE:5.135, TtlCE:1.788, ClaErr:0.825, DisErr:0.651, RecLoss:10.840; E0: ClaCE:6.807, DisCE:5.013, TtlCE:1.794, ClaErr:0.824, DisErr:0.638, RecLoss:10.418\n",
            "Test score: Class CE: 6.751, Disc CE: 5.095, Ttl CE: 1.656, Class Err: 0.834 Disc Err: 0.645\n",
            "starting Epoch 1\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E1: trained class 25, trained aud 0\n",
            "DI:  0.16993215680122375\n",
            "DP:  0.052571893\n",
            "E1: ClaCE:6.451, DisCE:4.905, TtlCE:1.546, ClaErr:0.825, DisErr:0.652, RecLoss:10.297; E1: ClaCE:6.309, DisCE:4.786, TtlCE:1.522, ClaErr:0.826, DisErr:0.641, RecLoss:9.927\n",
            "Test score: Class CE: 6.272, Disc CE: 4.865, Ttl CE: 1.407, Class Err: 0.834 Disc Err: 0.647\n",
            "starting Epoch 2\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E2: trained class 25, trained aud 0\n",
            "DI:  0.15542727708816528\n",
            "DP:  0.058264494\n",
            "E2: ClaCE:5.958, DisCE:4.662, TtlCE:1.296, ClaErr:0.825, DisErr:0.654, RecLoss:9.857; E2: ClaCE:5.796, DisCE:4.537, TtlCE:1.259, ClaErr:0.827, DisErr:0.645, RecLoss:9.543\n",
            "Test score: Class CE: 5.766, Disc CE: 4.613, Ttl CE: 1.153, Class Err: 0.835 Disc Err: 0.650\n",
            "starting Epoch 3\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E3: trained class 25, trained aud 0\n",
            "DI:  0.15261828899383545\n",
            "DP:  0.060162067\n",
            "E3: ClaCE:5.470, DisCE:4.418, TtlCE:1.053, ClaErr:0.824, DisErr:0.655, RecLoss:9.531; E3: ClaCE:5.296, DisCE:4.309, TtlCE:0.987, ClaErr:0.826, DisErr:0.645, RecLoss:9.277\n",
            "Test score: Class CE: 5.279, Disc CE: 4.371, Ttl CE: 0.908, Class Err: 0.836 Disc Err: 0.651\n",
            "starting Epoch 4\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E4: trained class 25, trained aud 0\n",
            "DI:  0.15565723180770874\n",
            "DP:  0.060162067\n",
            "E4: ClaCE:4.993, DisCE:4.180, TtlCE:0.813, ClaErr:0.823, DisErr:0.657, RecLoss:9.329; E4: ClaCE:4.824, DisCE:4.063, TtlCE:0.761, ClaErr:0.823, DisErr:0.650, RecLoss:9.135\n",
            "Test score: Class CE: 4.813, Disc CE: 4.135, Ttl CE: 0.678, Class Err: 0.835 Disc Err: 0.653\n",
            "starting Epoch 5\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E5: trained class 25, trained aud 0\n",
            "DI:  0.14980930089950562\n",
            "DP:  0.06205958\n",
            "E5: ClaCE:4.542, DisCE:3.958, TtlCE:0.584, ClaErr:0.822, DisErr:0.659, RecLoss:9.253; E5: ClaCE:4.372, DisCE:3.843, TtlCE:0.529, ClaErr:0.824, DisErr:0.652, RecLoss:9.119\n",
            "Test score: Class CE: 4.368, Disc CE: 3.923, Ttl CE: 0.445, Class Err: 0.837 Disc Err: 0.653\n",
            "starting Epoch 6\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E6: trained class 25, trained aud 0\n",
            "DI:  0.13987064361572266\n",
            "DP:  0.063602805\n",
            "E6: ClaCE:4.111, DisCE:3.750, TtlCE:0.361, ClaErr:0.822, DisErr:0.661, RecLoss:9.303; E6: ClaCE:3.947, DisCE:3.647, TtlCE:0.300, ClaErr:0.824, DisErr:0.652, RecLoss:9.228\n",
            "Test score: Class CE: 3.953, Disc CE: 3.727, Ttl CE: 0.225, Class Err: 0.836 Disc Err: 0.653\n",
            "starting Epoch 7\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E7: trained class 25, trained aud 0\n",
            "DI:  0.08879810571670532\n",
            "DP:  0.07154727\n",
            "E7: ClaCE:3.710, DisCE:3.568, TtlCE:0.143, ClaErr:0.822, DisErr:0.662, RecLoss:9.483; E7: ClaCE:3.547, DisCE:3.477, TtlCE:0.070, ClaErr:0.820, DisErr:0.654, RecLoss:9.467\n",
            "Test score: Class CE: 3.556, Disc CE: 3.560, Ttl CE: -0.003, Class Err: 0.837 Disc Err: 0.656\n",
            "starting Epoch 8\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E8: trained class 25, trained aud 0\n",
            "DI:  0.040304601192474365\n",
            "DP:  0.07569665\n",
            "E8: ClaCE:3.328, DisCE:3.410, TtlCE:-0.082, ClaErr:0.821, DisErr:0.664, RecLoss:9.798; E8: ClaCE:3.172, DisCE:3.335, TtlCE:-0.163, ClaErr:0.822, DisErr:0.655, RecLoss:9.846\n",
            "Test score: Class CE: 3.182, Disc CE: 3.414, Ttl CE: -0.232, Class Err: 0.835 Disc Err: 0.658\n",
            "starting Epoch 9\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E9: trained class 25, trained aud 0\n",
            "DI:  0.03621387481689453\n",
            "DP:  0.0753423\n",
            "E9: ClaCE:2.965, DisCE:3.279, TtlCE:-0.314, ClaErr:0.821, DisErr:0.665, RecLoss:10.264; E9: ClaCE:2.811, DisCE:3.216, TtlCE:-0.405, ClaErr:0.820, DisErr:0.655, RecLoss:10.383\n",
            "Test score: Class CE: 2.827, Disc CE: 3.296, Ttl CE: -0.469, Class Err: 0.831 Disc Err: 0.660\n",
            "starting Epoch 10\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E10: trained class 25, trained aud 0\n",
            "DI:  0.023236185312271118\n",
            "DP:  0.07688552\n",
            "E10: ClaCE:2.618, DisCE:3.175, TtlCE:-0.557, ClaErr:0.821, DisErr:0.665, RecLoss:10.897; E10: ClaCE:2.465, DisCE:3.127, TtlCE:-0.662, ClaErr:0.823, DisErr:0.658, RecLoss:11.092\n",
            "Test score: Class CE: 2.487, Disc CE: 3.205, Ttl CE: -0.718, Class Err: 0.828 Disc Err: 0.660\n",
            "starting Epoch 11\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E11: trained class 25, trained aud 0\n",
            "DI:  0.02394166588783264\n",
            "DP:  0.07427937\n",
            "E11: ClaCE:2.285, DisCE:3.097, TtlCE:-0.812, ClaErr:0.817, DisErr:0.666, RecLoss:11.711; E11: ClaCE:2.135, DisCE:3.060, TtlCE:-0.925, ClaErr:0.816, DisErr:0.658, RecLoss:11.986\n",
            "Test score: Class CE: 2.158, Disc CE: 3.140, Ttl CE: -0.982, Class Err: 0.816 Disc Err: 0.662\n",
            "starting Epoch 12\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E12: trained class 25, trained aud 0\n",
            "DI:  0.1105894148349762\n",
            "DP:  0.029116511\n",
            "E12: ClaCE:1.967, DisCE:3.043, TtlCE:-1.076, ClaErr:0.812, DisErr:0.666, RecLoss:12.713; E12: ClaCE:1.821, DisCE:3.014, TtlCE:-1.193, ClaErr:0.801, DisErr:0.658, RecLoss:13.060\n",
            "Test score: Class CE: 1.845, Disc CE: 3.094, Ttl CE: -1.249, Class Err: 0.798 Disc Err: 0.662\n",
            "starting Epoch 13\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E13: trained class 25, trained aud 0\n",
            "DI:  0.2281496822834015\n",
            "DP:  0.0053697824\n",
            "E13: ClaCE:1.667, DisCE:3.005, TtlCE:-1.338, ClaErr:0.792, DisErr:0.666, RecLoss:13.887; E13: ClaCE:1.528, DisCE:2.980, TtlCE:-1.452, ClaErr:0.764, DisErr:0.658, RecLoss:14.295\n",
            "Test score: Class CE: 1.555, Disc CE: 3.064, Ttl CE: -1.509, Class Err: 0.784 Disc Err: 0.661\n",
            "starting Epoch 14\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E14: trained class 25, trained aud 0\n",
            "DI:  0.17524129152297974\n",
            "DP:  0.05561894\n",
            "E14: ClaCE:1.393, DisCE:2.981, TtlCE:-1.588, ClaErr:0.751, DisErr:0.666, RecLoss:15.207; E14: ClaCE:1.267, DisCE:2.961, TtlCE:-1.695, ClaErr:0.725, DisErr:0.658, RecLoss:15.651\n",
            "Test score: Class CE: 1.295, Disc CE: 3.044, Ttl CE: -1.749, Class Err: 0.730 Disc Err: 0.662\n",
            "starting Epoch 15\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E15: trained class 25, trained aud 0\n",
            "DI:  0.2581021189689636\n",
            "DP:  0.07123226\n",
            "E15: ClaCE:1.154, DisCE:2.967, TtlCE:-1.813, ClaErr:0.699, DisErr:0.666, RecLoss:16.623; E15: ClaCE:1.046, DisCE:2.952, TtlCE:-1.906, ClaErr:0.651, DisErr:0.658, RecLoss:17.073\n",
            "Test score: Class CE: 1.075, Disc CE: 3.034, Ttl CE: -1.959, Class Err: 0.656 Disc Err: 0.662\n",
            "starting Epoch 16\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E16: trained class 25, trained aud 0\n",
            "DI:  0.23689693212509155\n",
            "DP:  0.087554246\n",
            "E16: ClaCE:0.958, DisCE:2.961, TtlCE:-2.003, ClaErr:0.615, DisErr:0.666, RecLoss:18.068; E16: ClaCE:0.873, DisCE:2.950, TtlCE:-2.077, ClaErr:0.556, DisErr:0.658, RecLoss:18.483\n",
            "Test score: Class CE: 0.902, Disc CE: 3.032, Ttl CE: -2.130, Class Err: 0.564 Disc Err: 0.662\n",
            "starting Epoch 17\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E17: trained class 25, trained aud 0\n",
            "DI:  0.1564810574054718\n",
            "DP:  0.11976504\n",
            "E17: ClaCE:0.810, DisCE:2.962, TtlCE:-2.153, ClaErr:0.514, DisErr:0.666, RecLoss:19.465; E17: ClaCE:0.746, DisCE:2.953, TtlCE:-2.207, ClaErr:0.430, DisErr:0.658, RecLoss:19.812\n",
            "Test score: Class CE: 0.774, Disc CE: 3.035, Ttl CE: -2.261, Class Err: 0.458 Disc Err: 0.662\n",
            "starting Epoch 18\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E18: trained class 25, trained aud 0\n",
            "DI:  0.1223362386226654\n",
            "DP:  0.11807223\n",
            "E18: ClaCE:0.703, DisCE:2.968, TtlCE:-2.264, ClaErr:0.400, DisErr:0.666, RecLoss:20.756; E18: ClaCE:0.656, DisCE:2.959, TtlCE:-2.303, ClaErr:0.335, DisErr:0.658, RecLoss:21.019\n",
            "Test score: Class CE: 0.682, Disc CE: 3.041, Ttl CE: -2.359, Class Err: 0.361 Disc Err: 0.661\n",
            "starting Epoch 19\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E19: trained class 25, trained aud 0\n",
            "DI:  0.15020625293254852\n",
            "DP:  0.1477005\n",
            "E19: ClaCE:0.629, DisCE:2.975, TtlCE:-2.346, ClaErr:0.327, DisErr:0.666, RecLoss:21.916; E19: ClaCE:0.592, DisCE:2.968, TtlCE:-2.375, ClaErr:0.292, DisErr:0.658, RecLoss:22.093\n",
            "Test score: Class CE: 0.617, Disc CE: 3.051, Ttl CE: -2.435, Class Err: 0.308 Disc Err: 0.661\n",
            "starting Epoch 20\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E20: trained class 25, trained aud 0\n",
            "DI:  0.22767511010169983\n",
            "DP:  0.15847945\n",
            "E20: ClaCE:0.576, DisCE:2.984, TtlCE:-2.408, ClaErr:0.286, DisErr:0.666, RecLoss:22.944; E20: ClaCE:0.547, DisCE:2.977, TtlCE:-2.430, ClaErr:0.272, DisErr:0.658, RecLoss:23.043\n",
            "Test score: Class CE: 0.569, Disc CE: 3.061, Ttl CE: -2.491, Class Err: 0.275 Disc Err: 0.661\n",
            "starting Epoch 21\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E21: trained class 25, trained aud 0\n",
            "DI:  0.16390565037727356\n",
            "DP:  0.12467817\n",
            "E21: ClaCE:0.539, DisCE:2.994, TtlCE:-2.455, ClaErr:0.263, DisErr:0.666, RecLoss:23.854; E21: ClaCE:0.514, DisCE:2.986, TtlCE:-2.472, ClaErr:0.255, DisErr:0.658, RecLoss:23.885\n",
            "Test score: Class CE: 0.534, Disc CE: 3.070, Ttl CE: -2.536, Class Err: 0.260 Disc Err: 0.661\n",
            "starting Epoch 22\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E22: trained class 25, trained aud 0\n",
            "DI:  0.09844186156988144\n",
            "DP:  0.11020652\n",
            "E22: ClaCE:0.512, DisCE:3.003, TtlCE:-2.491, ClaErr:0.249, DisErr:0.666, RecLoss:24.661; E22: ClaCE:0.489, DisCE:2.996, TtlCE:-2.506, ClaErr:0.234, DisErr:0.658, RecLoss:24.633\n",
            "Test score: Class CE: 0.508, Disc CE: 3.079, Ttl CE: -2.572, Class Err: 0.246 Disc Err: 0.661\n",
            "starting Epoch 23\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E23: trained class 25, trained aud 0\n",
            "DI:  0.11973016709089279\n",
            "DP:  0.11850528\n",
            "E23: ClaCE:0.492, DisCE:3.013, TtlCE:-2.521, ClaErr:0.236, DisErr:0.666, RecLoss:25.380; E23: ClaCE:0.471, DisCE:3.008, TtlCE:-2.537, ClaErr:0.221, DisErr:0.658, RecLoss:25.301\n",
            "Test score: Class CE: 0.487, Disc CE: 3.088, Ttl CE: -2.601, Class Err: 0.237 Disc Err: 0.661\n",
            "starting Epoch 24\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E24: trained class 25, trained aud 0\n",
            "DI:  0.10919967293739319\n",
            "DP:  0.1135213\n",
            "E24: ClaCE:0.477, DisCE:3.022, TtlCE:-2.545, ClaErr:0.228, DisErr:0.666, RecLoss:26.023; E24: ClaCE:0.457, DisCE:3.017, TtlCE:-2.560, ClaErr:0.210, DisErr:0.658, RecLoss:25.899\n",
            "Test score: Class CE: 0.472, Disc CE: 3.097, Ttl CE: -2.626, Class Err: 0.234 Disc Err: 0.662\n",
            "starting Epoch 25\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E25: trained class 25, trained aud 0\n",
            "DI:  0.03800423815846443\n",
            "DP:  0.09608919\n",
            "E25: ClaCE:0.465, DisCE:3.030, TtlCE:-2.565, ClaErr:0.217, DisErr:0.666, RecLoss:26.599; E25: ClaCE:0.446, DisCE:3.025, TtlCE:-2.579, ClaErr:0.204, DisErr:0.658, RecLoss:26.437\n",
            "Test score: Class CE: 0.459, Disc CE: 3.106, Ttl CE: -2.646, Class Err: 0.230 Disc Err: 0.662\n",
            "starting Epoch 26\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E26: trained class 25, trained aud 0\n",
            "DI:  0.05200934782624245\n",
            "DP:  0.083995365\n",
            "E26: ClaCE:0.457, DisCE:3.038, TtlCE:-2.582, ClaErr:0.214, DisErr:0.666, RecLoss:27.118; E26: ClaCE:0.437, DisCE:3.032, TtlCE:-2.595, ClaErr:0.202, DisErr:0.658, RecLoss:26.921\n",
            "Test score: Class CE: 0.450, Disc CE: 3.113, Ttl CE: -2.663, Class Err: 0.225 Disc Err: 0.662\n",
            "starting Epoch 27\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E27: trained class 25, trained aud 0\n",
            "DI:  0.048148591071367264\n",
            "DP:  0.08245214\n",
            "E27: ClaCE:0.450, DisCE:3.045, TtlCE:-2.595, ClaErr:0.211, DisErr:0.666, RecLoss:27.585; E27: ClaCE:0.431, DisCE:3.039, TtlCE:-2.609, ClaErr:0.197, DisErr:0.658, RecLoss:27.359\n",
            "Test score: Class CE: 0.442, Disc CE: 3.120, Ttl CE: -2.678, Class Err: 0.221 Disc Err: 0.662\n",
            "starting Epoch 28\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E28: trained class 25, trained aud 0\n",
            "DI:  0.07348020374774933\n",
            "DP:  0.076405235\n",
            "E28: ClaCE:0.444, DisCE:3.052, TtlCE:-2.607, ClaErr:0.208, DisErr:0.666, RecLoss:28.007; E28: ClaCE:0.425, DisCE:3.045, TtlCE:-2.620, ClaErr:0.189, DisErr:0.658, RecLoss:27.754\n",
            "Test score: Class CE: 0.436, Disc CE: 3.126, Ttl CE: -2.690, Class Err: 0.216 Disc Err: 0.662\n",
            "starting Epoch 29\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E29: trained class 25, trained aud 0\n",
            "DI:  0.07804641127586365\n",
            "DP:  0.08055461\n",
            "E29: ClaCE:0.440, DisCE:3.058, TtlCE:-2.618, ClaErr:0.203, DisErr:0.666, RecLoss:28.389; E29: ClaCE:0.421, DisCE:3.051, TtlCE:-2.630, ClaErr:0.188, DisErr:0.658, RecLoss:28.113\n",
            "Test score: Class CE: 0.431, Disc CE: 3.132, Ttl CE: -2.701, Class Err: 0.212 Disc Err: 0.662\n",
            "starting Epoch 30\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E30: trained class 25, trained aud 0\n",
            "DI:  0.07804641127586365\n",
            "DP:  0.08055461\n",
            "E30: ClaCE:0.437, DisCE:3.064, TtlCE:-2.627, ClaErr:0.202, DisErr:0.667, RecLoss:28.735; E30: ClaCE:0.417, DisCE:3.057, TtlCE:-2.640, ClaErr:0.188, DisErr:0.658, RecLoss:28.438\n",
            "Test score: Class CE: 0.427, Disc CE: 3.137, Ttl CE: -2.711, Class Err: 0.206 Disc Err: 0.662\n",
            "starting Epoch 31\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E31: trained class 25, trained aud 0\n",
            "DI:  0.06833773106336594\n",
            "DP:  0.08090892\n",
            "E31: ClaCE:0.434, DisCE:3.069, TtlCE:-2.635, ClaErr:0.198, DisErr:0.667, RecLoss:29.049; E31: ClaCE:0.414, DisCE:3.065, TtlCE:-2.651, ClaErr:0.181, DisErr:0.658, RecLoss:28.733\n",
            "Test score: Class CE: 0.423, Disc CE: 3.142, Ttl CE: -2.719, Class Err: 0.202 Disc Err: 0.662\n",
            "starting Epoch 32\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E32: trained class 25, trained aud 0\n",
            "DI:  0.06274540722370148\n",
            "DP:  0.07711386\n",
            "E32: ClaCE:0.431, DisCE:3.074, TtlCE:-2.642, ClaErr:0.198, DisErr:0.667, RecLoss:29.334; E32: ClaCE:0.412, DisCE:3.069, TtlCE:-2.658, ClaErr:0.178, DisErr:0.658, RecLoss:29.002\n",
            "Test score: Class CE: 0.420, Disc CE: 3.146, Ttl CE: -2.726, Class Err: 0.199 Disc Err: 0.662\n",
            "starting Epoch 33\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E33: trained class 25, trained aud 0\n",
            "DI:  0.0655287429690361\n",
            "DP:  0.07901139\n",
            "E33: ClaCE:0.430, DisCE:3.078, TtlCE:-2.648, ClaErr:0.193, DisErr:0.667, RecLoss:29.593; E33: ClaCE:0.410, DisCE:3.073, TtlCE:-2.664, ClaErr:0.180, DisErr:0.658, RecLoss:29.246\n",
            "Test score: Class CE: 0.418, Disc CE: 3.150, Ttl CE: -2.733, Class Err: 0.198 Disc Err: 0.662\n",
            "starting Epoch 34\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E34: trained class 25, trained aud 0\n",
            "DI:  0.0642470195889473\n",
            "DP:  0.085058294\n",
            "E34: ClaCE:0.428, DisCE:3.081, TtlCE:-2.654, ClaErr:0.190, DisErr:0.667, RecLoss:29.829; E34: ClaCE:0.408, DisCE:3.077, TtlCE:-2.669, ClaErr:0.177, DisErr:0.658, RecLoss:29.468\n",
            "Test score: Class CE: 0.416, Disc CE: 3.154, Ttl CE: -2.738, Class Err: 0.197 Disc Err: 0.662\n",
            "starting Epoch 35\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E35: trained class 25, trained aud 0\n",
            "DI:  0.058399029076099396\n",
            "DP:  0.08695584\n",
            "E35: ClaCE:0.427, DisCE:3.085, TtlCE:-2.659, ClaErr:0.189, DisErr:0.667, RecLoss:30.043; E35: ClaCE:0.406, DisCE:3.080, TtlCE:-2.674, ClaErr:0.176, DisErr:0.658, RecLoss:29.671\n",
            "Test score: Class CE: 0.414, Disc CE: 3.157, Ttl CE: -2.744, Class Err: 0.195 Disc Err: 0.661\n",
            "starting Epoch 36\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E36: trained class 25, trained aud 0\n",
            "DI:  0.05255109816789627\n",
            "DP:  0.08885337\n",
            "E36: ClaCE:0.425, DisCE:3.089, TtlCE:-2.664, ClaErr:0.187, DisErr:0.667, RecLoss:30.238; E36: ClaCE:0.405, DisCE:3.083, TtlCE:-2.679, ClaErr:0.174, DisErr:0.658, RecLoss:29.856\n",
            "Test score: Class CE: 0.412, Disc CE: 3.160, Ttl CE: -2.748, Class Err: 0.191 Disc Err: 0.660\n",
            "starting Epoch 37\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E37: trained class 25, trained aud 0\n",
            "DI:  0.04213690012693405\n",
            "DP:  0.08660152\n",
            "E37: ClaCE:0.424, DisCE:3.092, TtlCE:-2.668, ClaErr:0.187, DisErr:0.666, RecLoss:30.416; E37: ClaCE:0.403, DisCE:3.086, TtlCE:-2.683, ClaErr:0.174, DisErr:0.658, RecLoss:30.024\n",
            "Test score: Class CE: 0.411, Disc CE: 3.164, Ttl CE: -2.754, Class Err: 0.190 Disc Err: 0.660\n",
            "starting Epoch 38\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E38: trained class 25, trained aud 0\n",
            "DI:  0.049512095749378204\n",
            "DP:  0.09264844\n",
            "E38: ClaCE:0.423, DisCE:3.094, TtlCE:-2.671, ClaErr:0.185, DisErr:0.666, RecLoss:30.578; E38: ClaCE:0.402, DisCE:3.088, TtlCE:-2.686, ClaErr:0.174, DisErr:0.658, RecLoss:30.178\n",
            "Test score: Class CE: 0.409, Disc CE: 3.167, Ttl CE: -2.757, Class Err: 0.189 Disc Err: 0.660\n",
            "starting Epoch 39\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E39: trained class 25, trained aud 0\n",
            "DI:  0.05232108384370804\n",
            "DP:  0.09454597\n",
            "E39: ClaCE:0.422, DisCE:3.097, TtlCE:-2.674, ClaErr:0.184, DisErr:0.666, RecLoss:30.726; E39: ClaCE:0.401, DisCE:3.090, TtlCE:-2.689, ClaErr:0.176, DisErr:0.658, RecLoss:30.319\n",
            "Test score: Class CE: 0.408, Disc CE: 3.169, Ttl CE: -2.761, Class Err: 0.188 Disc Err: 0.660\n",
            "starting Epoch 40\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E40: trained class 25, trained aud 0\n",
            "DI:  0.04647315293550491\n",
            "DP:  0.0964435\n",
            "E40: ClaCE:0.422, DisCE:3.099, TtlCE:-2.677, ClaErr:0.184, DisErr:0.665, RecLoss:30.860; E40: ClaCE:0.400, DisCE:3.092, TtlCE:-2.692, ClaErr:0.174, DisErr:0.658, RecLoss:30.447\n",
            "Test score: Class CE: 0.407, Disc CE: 3.171, Ttl CE: -2.763, Class Err: 0.187 Disc Err: 0.660\n",
            "starting Epoch 41\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E41: trained class 25, trained aud 0\n",
            "DI:  0.04647315293550491\n",
            "DP:  0.0964435\n",
            "E41: ClaCE:0.421, DisCE:3.100, TtlCE:-2.679, ClaErr:0.183, DisErr:0.666, RecLoss:30.983; E41: ClaCE:0.399, DisCE:3.094, TtlCE:-2.694, ClaErr:0.174, DisErr:0.658, RecLoss:30.564\n",
            "Test score: Class CE: 0.406, Disc CE: 3.172, Ttl CE: -2.766, Class Err: 0.185 Disc Err: 0.660\n",
            "starting Epoch 42\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E42: trained class 25, trained aud 0\n",
            "DI:  0.04062522202730179\n",
            "DP:  0.09834104\n",
            "E42: ClaCE:0.420, DisCE:3.102, TtlCE:-2.682, ClaErr:0.183, DisErr:0.666, RecLoss:31.095; E42: ClaCE:0.399, DisCE:3.095, TtlCE:-2.697, ClaErr:0.173, DisErr:0.658, RecLoss:30.670\n",
            "Test score: Class CE: 0.405, Disc CE: 3.174, Ttl CE: -2.768, Class Err: 0.184 Disc Err: 0.660\n",
            "starting Epoch 43\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E43: trained class 25, trained aud 0\n",
            "DI:  0.04062522202730179\n",
            "DP:  0.09834104\n",
            "E43: ClaCE:0.420, DisCE:3.103, TtlCE:-2.684, ClaErr:0.183, DisErr:0.666, RecLoss:31.197; E43: ClaCE:0.398, DisCE:3.096, TtlCE:-2.698, ClaErr:0.173, DisErr:0.658, RecLoss:30.768\n",
            "Test score: Class CE: 0.405, Disc CE: 3.175, Ttl CE: -2.771, Class Err: 0.184 Disc Err: 0.660\n",
            "starting Epoch 44\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E44: trained class 25, trained aud 0\n",
            "DI:  0.04343421012163162\n",
            "DP:  0.10023857\n",
            "E44: ClaCE:0.419, DisCE:3.105, TtlCE:-2.685, ClaErr:0.183, DisErr:0.666, RecLoss:31.290; E44: ClaCE:0.397, DisCE:3.097, TtlCE:-2.700, ClaErr:0.174, DisErr:0.658, RecLoss:30.857\n",
            "Test score: Class CE: 0.404, Disc CE: 3.176, Ttl CE: -2.772, Class Err: 0.183 Disc Err: 0.660\n",
            "starting Epoch 45\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E45: trained class 25, trained aud 0\n",
            "DI:  0.03758621960878372\n",
            "DP:  0.1021361\n",
            "E45: ClaCE:0.419, DisCE:3.106, TtlCE:-2.687, ClaErr:0.182, DisErr:0.666, RecLoss:31.374; E45: ClaCE:0.396, DisCE:3.098, TtlCE:-2.702, ClaErr:0.173, DisErr:0.655, RecLoss:30.938\n",
            "Test score: Class CE: 0.403, Disc CE: 3.177, Ttl CE: -2.774, Class Err: 0.183 Disc Err: 0.660\n",
            "starting Epoch 46\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E46: trained class 25, trained aud 0\n",
            "DI:  0.029981069266796112\n",
            "DP:  0.10178179\n",
            "E46: ClaCE:0.418, DisCE:3.106, TtlCE:-2.689, ClaErr:0.183, DisErr:0.666, RecLoss:31.451; E46: ClaCE:0.396, DisCE:3.099, TtlCE:-2.703, ClaErr:0.174, DisErr:0.655, RecLoss:31.012\n",
            "Test score: Class CE: 0.402, Disc CE: 3.178, Ttl CE: -2.776, Class Err: 0.182 Disc Err: 0.660\n",
            "starting Epoch 47\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E47: trained class 25, trained aud 0\n",
            "DI:  0.024133138358592987\n",
            "DP:  0.10367932\n",
            "E47: ClaCE:0.417, DisCE:3.107, TtlCE:-2.690, ClaErr:0.182, DisErr:0.665, RecLoss:31.521; E47: ClaCE:0.395, DisCE:3.100, TtlCE:-2.705, ClaErr:0.173, DisErr:0.655, RecLoss:31.079\n",
            "Test score: Class CE: 0.402, Disc CE: 3.179, Ttl CE: -2.777, Class Err: 0.181 Disc Err: 0.660\n",
            "starting Epoch 48\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E48: trained class 25, trained aud 0\n",
            "DI:  0.022375915199518204\n",
            "DP:  0.10142747\n",
            "E48: ClaCE:0.417, DisCE:3.108, TtlCE:-2.691, ClaErr:0.181, DisErr:0.665, RecLoss:31.584; E48: ClaCE:0.395, DisCE:3.100, TtlCE:-2.706, ClaErr:0.176, DisErr:0.655, RecLoss:31.140\n",
            "Test score: Class CE: 0.401, Disc CE: 3.179, Ttl CE: -2.778, Class Err: 0.180 Disc Err: 0.660\n",
            "starting Epoch 49\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E49: trained class 25, trained aud 0\n",
            "DI:  0.017809703946113586\n",
            "DP:  0.097278096\n",
            "E49: ClaCE:0.417, DisCE:3.108, TtlCE:-2.692, ClaErr:0.182, DisErr:0.665, RecLoss:31.642; E49: ClaCE:0.394, DisCE:3.101, TtlCE:-2.707, ClaErr:0.177, DisErr:0.655, RecLoss:31.196\n",
            "Test score: Class CE: 0.401, Disc CE: 3.180, Ttl CE: -2.779, Class Err: 0.180 Disc Err: 0.660\n",
            "starting Epoch 50\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E50: trained class 25, trained aud 0\n",
            "DI:  0.02061869576573372\n",
            "DP:  0.09917564\n",
            "E50: ClaCE:0.416, DisCE:3.109, TtlCE:-2.693, ClaErr:0.181, DisErr:0.665, RecLoss:31.695; E50: ClaCE:0.393, DisCE:3.101, TtlCE:-2.708, ClaErr:0.178, DisErr:0.655, RecLoss:31.247\n",
            "Test score: Class CE: 0.400, Disc CE: 3.180, Ttl CE: -2.780, Class Err: 0.179 Disc Err: 0.660\n",
            "starting Epoch 51\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E51: trained class 25, trained aud 0\n",
            "DI:  0.02061869576573372\n",
            "DP:  0.09917564\n",
            "E51: ClaCE:0.416, DisCE:3.109, TtlCE:-2.694, ClaErr:0.182, DisErr:0.665, RecLoss:31.742; E51: ClaCE:0.393, DisCE:3.101, TtlCE:-2.709, ClaErr:0.178, DisErr:0.655, RecLoss:31.293\n",
            "Test score: Class CE: 0.400, Disc CE: 3.180, Ttl CE: -2.781, Class Err: 0.179 Disc Err: 0.660\n",
            "starting Epoch 52\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E52: trained class 25, trained aud 0\n",
            "DI:  0.023427683860063553\n",
            "DP:  0.10107317\n",
            "E52: ClaCE:0.415, DisCE:3.110, TtlCE:-2.694, ClaErr:0.181, DisErr:0.665, RecLoss:31.785; E52: ClaCE:0.392, DisCE:3.102, TtlCE:-2.709, ClaErr:0.180, DisErr:0.655, RecLoss:31.335\n",
            "Test score: Class CE: 0.399, Disc CE: 3.181, Ttl CE: -2.782, Class Err: 0.178 Disc Err: 0.660\n",
            "starting Epoch 53\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E53: trained class 25, trained aud 0\n",
            "DI:  0.023427683860063553\n",
            "DP:  0.10107317\n",
            "E53: ClaCE:0.415, DisCE:3.110, TtlCE:-2.695, ClaErr:0.180, DisErr:0.665, RecLoss:31.824; E53: ClaCE:0.392, DisCE:3.102, TtlCE:-2.710, ClaErr:0.180, DisErr:0.655, RecLoss:31.373\n",
            "Test score: Class CE: 0.399, Disc CE: 3.181, Ttl CE: -2.782, Class Err: 0.178 Disc Err: 0.660\n",
            "starting Epoch 54\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E54: trained class 25, trained aud 0\n",
            "DI:  0.018861476331949234\n",
            "DP:  0.09692379\n",
            "E54: ClaCE:0.414, DisCE:3.110, TtlCE:-2.696, ClaErr:0.181, DisErr:0.665, RecLoss:31.859; E54: ClaCE:0.391, DisCE:3.102, TtlCE:-2.711, ClaErr:0.181, DisErr:0.655, RecLoss:31.408\n",
            "Test score: Class CE: 0.398, Disc CE: 3.181, Ttl CE: -2.783, Class Err: 0.179 Disc Err: 0.659\n",
            "starting Epoch 55\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E55: trained class 25, trained aud 0\n",
            "DI:  0.01710425317287445\n",
            "DP:  0.09467194\n",
            "E55: ClaCE:0.414, DisCE:3.110, TtlCE:-2.696, ClaErr:0.178, DisErr:0.665, RecLoss:31.890; E55: ClaCE:0.391, DisCE:3.102, TtlCE:-2.711, ClaErr:0.184, DisErr:0.655, RecLoss:31.439\n",
            "Test score: Class CE: 0.398, Disc CE: 3.181, Ttl CE: -2.783, Class Err: 0.179 Disc Err: 0.659\n",
            "starting Epoch 56\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E56: trained class 25, trained aud 0\n",
            "DI:  0.02272222936153412\n",
            "DP:  0.098467015\n",
            "E56: ClaCE:0.414, DisCE:3.110, TtlCE:-2.697, ClaErr:0.178, DisErr:0.665, RecLoss:31.919; E56: ClaCE:0.390, DisCE:3.102, TtlCE:-2.712, ClaErr:0.186, DisErr:0.655, RecLoss:31.467\n",
            "Test score: Class CE: 0.397, Disc CE: 3.181, Ttl CE: -2.784, Class Err: 0.178 Disc Err: 0.659\n",
            "starting Epoch 57\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E57: trained class 25, trained aud 0\n",
            "DI:  0.02272222936153412\n",
            "DP:  0.098467015\n",
            "E57: ClaCE:0.413, DisCE:3.110, TtlCE:-2.697, ClaErr:0.178, DisErr:0.665, RecLoss:31.944; E57: ClaCE:0.390, DisCE:3.102, TtlCE:-2.712, ClaErr:0.186, DisErr:0.655, RecLoss:31.492\n",
            "Test score: Class CE: 0.397, Disc CE: 3.181, Ttl CE: -2.784, Class Err: 0.177 Disc Err: 0.659\n",
            "starting Epoch 58\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E58: trained class 25, trained aud 0\n",
            "DI:  0.016874238848686218\n",
            "DP:  0.10036454\n",
            "E58: ClaCE:0.413, DisCE:3.110, TtlCE:-2.697, ClaErr:0.177, DisErr:0.665, RecLoss:31.967; E58: ClaCE:0.390, DisCE:3.102, TtlCE:-2.712, ClaErr:0.185, DisErr:0.655, RecLoss:31.515\n",
            "Test score: Class CE: 0.397, Disc CE: 3.181, Ttl CE: -2.785, Class Err: 0.176 Disc Err: 0.659\n",
            "starting Epoch 59\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E59: trained class 25, trained aud 0\n",
            "DI:  0.05191465839743614\n",
            "DP:  0.09396332\n",
            "E59: ClaCE:0.413, DisCE:3.110, TtlCE:-2.698, ClaErr:0.177, DisErr:0.665, RecLoss:31.987; E59: ClaCE:0.389, DisCE:3.102, TtlCE:-2.713, ClaErr:0.184, DisErr:0.655, RecLoss:31.535\n",
            "Test score: Class CE: 0.396, Disc CE: 3.181, Ttl CE: -2.785, Class Err: 0.177 Disc Err: 0.659\n",
            "starting Epoch 60\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E60: trained class 25, trained aud 0\n",
            "DI:  0.04606666788458824\n",
            "DP:  0.09586086\n",
            "E60: ClaCE:0.412, DisCE:3.110, TtlCE:-2.698, ClaErr:0.177, DisErr:0.665, RecLoss:32.005; E60: ClaCE:0.389, DisCE:3.102, TtlCE:-2.713, ClaErr:0.182, DisErr:0.655, RecLoss:31.553\n",
            "Test score: Class CE: 0.396, Disc CE: 3.181, Ttl CE: -2.785, Class Err: 0.177 Disc Err: 0.659\n",
            "starting Epoch 61\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E61: trained class 25, trained aud 0\n",
            "DI:  0.04606666788458824\n",
            "DP:  0.09586086\n",
            "E61: ClaCE:0.412, DisCE:3.110, TtlCE:-2.698, ClaErr:0.176, DisErr:0.665, RecLoss:32.020; E61: ClaCE:0.388, DisCE:3.101, TtlCE:-2.713, ClaErr:0.182, DisErr:0.655, RecLoss:31.569\n",
            "Test score: Class CE: 0.396, Disc CE: 3.181, Ttl CE: -2.785, Class Err: 0.177 Disc Err: 0.659\n",
            "starting Epoch 62\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E62: trained class 25, trained aud 0\n",
            "DI:  0.04606666788458824\n",
            "DP:  0.09586086\n",
            "E62: ClaCE:0.412, DisCE:3.110, TtlCE:-2.698, ClaErr:0.175, DisErr:0.665, RecLoss:32.034; E62: ClaCE:0.388, DisCE:3.101, TtlCE:-2.713, ClaErr:0.182, DisErr:0.654, RecLoss:31.584\n",
            "Test score: Class CE: 0.395, Disc CE: 3.181, Ttl CE: -2.785, Class Err: 0.178 Disc Err: 0.659\n",
            "starting Epoch 63\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E63: trained class 25, trained aud 0\n",
            "DI:  0.0356525257229805\n",
            "DP:  0.09360901\n",
            "E63: ClaCE:0.411, DisCE:3.110, TtlCE:-2.699, ClaErr:0.175, DisErr:0.665, RecLoss:32.046; E63: ClaCE:0.387, DisCE:3.101, TtlCE:-2.714, ClaErr:0.182, DisErr:0.654, RecLoss:31.596\n",
            "Test score: Class CE: 0.395, Disc CE: 3.180, Ttl CE: -2.785, Class Err: 0.176 Disc Err: 0.659\n",
            "starting Epoch 64\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E64: trained class 25, trained aud 0\n",
            "DI:  0.0356525257229805\n",
            "DP:  0.09360901\n",
            "E64: ClaCE:0.411, DisCE:3.110, TtlCE:-2.699, ClaErr:0.175, DisErr:0.665, RecLoss:32.056; E64: ClaCE:0.387, DisCE:3.101, TtlCE:-2.714, ClaErr:0.182, DisErr:0.654, RecLoss:31.607\n",
            "Test score: Class CE: 0.395, Disc CE: 3.180, Ttl CE: -2.786, Class Err: 0.176 Disc Err: 0.659\n",
            "starting Epoch 65\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E65: trained class 25, trained aud 0\n",
            "DI:  0.029804594814777374\n",
            "DP:  0.09550654\n",
            "E65: ClaCE:0.411, DisCE:3.110, TtlCE:-2.699, ClaErr:0.175, DisErr:0.665, RecLoss:32.065; E65: ClaCE:0.387, DisCE:3.101, TtlCE:-2.714, ClaErr:0.181, DisErr:0.654, RecLoss:31.616\n",
            "Test score: Class CE: 0.394, Disc CE: 3.180, Ttl CE: -2.786, Class Err: 0.175 Disc Err: 0.659\n",
            "starting Epoch 66\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E66: trained class 25, trained aud 0\n",
            "DI:  0.023956604301929474\n",
            "DP:  0.097404085\n",
            "E66: ClaCE:0.410, DisCE:3.110, TtlCE:-2.699, ClaErr:0.174, DisErr:0.665, RecLoss:32.072; E66: ClaCE:0.386, DisCE:3.100, TtlCE:-2.714, ClaErr:0.180, DisErr:0.654, RecLoss:31.624\n",
            "Test score: Class CE: 0.394, Disc CE: 3.180, Ttl CE: -2.786, Class Err: 0.174 Disc Err: 0.659\n",
            "starting Epoch 67\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E67: trained class 25, trained aud 0\n",
            "DI:  0.026765592396259308\n",
            "DP:  0.099301614\n",
            "E67: ClaCE:0.410, DisCE:3.109, TtlCE:-2.699, ClaErr:0.172, DisErr:0.665, RecLoss:32.078; E67: ClaCE:0.386, DisCE:3.100, TtlCE:-2.714, ClaErr:0.181, DisErr:0.655, RecLoss:31.631\n",
            "Test score: Class CE: 0.394, Disc CE: 3.179, Ttl CE: -2.786, Class Err: 0.174 Disc Err: 0.658\n",
            "starting Epoch 68\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E68: trained class 25, trained aud 0\n",
            "DI:  0.026765592396259308\n",
            "DP:  0.099301614\n",
            "E68: ClaCE:0.410, DisCE:3.110, TtlCE:-2.700, ClaErr:0.172, DisErr:0.665, RecLoss:32.082; E68: ClaCE:0.386, DisCE:3.100, TtlCE:-2.714, ClaErr:0.181, DisErr:0.655, RecLoss:31.637\n",
            "Test score: Class CE: 0.393, Disc CE: 3.179, Ttl CE: -2.786, Class Err: 0.174 Disc Err: 0.659\n",
            "starting Epoch 69\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E69: trained class 25, trained aud 0\n",
            "DI:  0.029574580490589142\n",
            "DP:  0.10119914\n",
            "E69: ClaCE:0.409, DisCE:3.110, TtlCE:-2.700, ClaErr:0.172, DisErr:0.665, RecLoss:32.086; E69: ClaCE:0.385, DisCE:3.100, TtlCE:-2.714, ClaErr:0.182, DisErr:0.656, RecLoss:31.641\n",
            "Test score: Class CE: 0.393, Disc CE: 3.179, Ttl CE: -2.786, Class Err: 0.174 Disc Err: 0.659\n",
            "starting Epoch 70\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E70: trained class 25, trained aud 0\n",
            "DI:  0.029574580490589142\n",
            "DP:  0.10119914\n",
            "E70: ClaCE:0.409, DisCE:3.109, TtlCE:-2.700, ClaErr:0.172, DisErr:0.665, RecLoss:32.088; E70: ClaCE:0.385, DisCE:3.099, TtlCE:-2.714, ClaErr:0.182, DisErr:0.656, RecLoss:31.644\n",
            "Test score: Class CE: 0.393, Disc CE: 3.179, Ttl CE: -2.786, Class Err: 0.173 Disc Err: 0.659\n",
            "starting Epoch 71\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E71: trained class 25, trained aud 0\n",
            "DI:  0.019160442054271698\n",
            "DP:  0.098947294\n",
            "E71: ClaCE:0.409, DisCE:3.109, TtlCE:-2.700, ClaErr:0.172, DisErr:0.665, RecLoss:32.089; E71: ClaCE:0.385, DisCE:3.099, TtlCE:-2.714, ClaErr:0.182, DisErr:0.656, RecLoss:31.647\n",
            "Test score: Class CE: 0.393, Disc CE: 3.178, Ttl CE: -2.786, Class Err: 0.173 Disc Err: 0.659\n",
            "starting Epoch 72\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E72: trained class 25, trained aud 0\n",
            "DI:  0.019160442054271698\n",
            "DP:  0.098947294\n",
            "E72: ClaCE:0.409, DisCE:3.109, TtlCE:-2.700, ClaErr:0.172, DisErr:0.665, RecLoss:32.090; E72: ClaCE:0.384, DisCE:3.099, TtlCE:-2.714, ClaErr:0.182, DisErr:0.656, RecLoss:31.648\n",
            "Test score: Class CE: 0.392, Disc CE: 3.178, Ttl CE: -2.786, Class Err: 0.174 Disc Err: 0.659\n",
            "starting Epoch 73\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E73: trained class 25, trained aud 0\n",
            "DI:  0.013312511146068573\n",
            "DP:  0.10084484\n",
            "E73: ClaCE:0.408, DisCE:3.109, TtlCE:-2.700, ClaErr:0.172, DisErr:0.664, RecLoss:32.089; E73: ClaCE:0.384, DisCE:3.098, TtlCE:-2.714, ClaErr:0.181, DisErr:0.656, RecLoss:31.649\n",
            "Test score: Class CE: 0.392, Disc CE: 3.178, Ttl CE: -2.786, Class Err: 0.173 Disc Err: 0.659\n",
            "starting Epoch 74\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E74: trained class 25, trained aud 0\n",
            "DI:  0.013312511146068573\n",
            "DP:  0.10084484\n",
            "E74: ClaCE:0.408, DisCE:3.108, TtlCE:-2.700, ClaErr:0.172, DisErr:0.664, RecLoss:32.088; E74: ClaCE:0.384, DisCE:3.098, TtlCE:-2.714, ClaErr:0.181, DisErr:0.656, RecLoss:31.649\n",
            "Test score: Class CE: 0.392, Disc CE: 3.177, Ttl CE: -2.786, Class Err: 0.172 Disc Err: 0.659\n",
            "starting Epoch 75\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E75: trained class 25, trained aud 0\n",
            "DI:  0.013312511146068573\n",
            "DP:  0.10084484\n",
            "E75: ClaCE:0.408, DisCE:3.108, TtlCE:-2.700, ClaErr:0.173, DisErr:0.664, RecLoss:32.086; E75: ClaCE:0.383, DisCE:3.098, TtlCE:-2.714, ClaErr:0.181, DisErr:0.656, RecLoss:31.648\n",
            "Test score: Class CE: 0.392, Disc CE: 3.177, Ttl CE: -2.786, Class Err: 0.172 Disc Err: 0.659\n",
            "starting Epoch 76\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E76: trained class 25, trained aud 0\n",
            "DI:  0.013312511146068573\n",
            "DP:  0.10084484\n",
            "E76: ClaCE:0.408, DisCE:3.108, TtlCE:-2.700, ClaErr:0.174, DisErr:0.664, RecLoss:32.083; E76: ClaCE:0.383, DisCE:3.097, TtlCE:-2.714, ClaErr:0.181, DisErr:0.656, RecLoss:31.647\n",
            "Test score: Class CE: 0.391, Disc CE: 3.177, Ttl CE: -2.785, Class Err: 0.171 Disc Err: 0.659\n",
            "starting Epoch 77\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E77: trained class 25, trained aud 0\n",
            "DI:  0.007464520633220673\n",
            "DP:  0.10274237\n",
            "E77: ClaCE:0.407, DisCE:3.107, TtlCE:-2.700, ClaErr:0.173, DisErr:0.664, RecLoss:32.080; E77: ClaCE:0.383, DisCE:3.097, TtlCE:-2.714, ClaErr:0.180, DisErr:0.656, RecLoss:31.645\n",
            "Test score: Class CE: 0.391, Disc CE: 3.176, Ttl CE: -2.785, Class Err: 0.171 Disc Err: 0.659\n",
            "starting Epoch 78\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E78: trained class 25, trained aud 0\n",
            "DI:  0.007464520633220673\n",
            "DP:  0.104639895\n",
            "E78: ClaCE:0.407, DisCE:3.107, TtlCE:-2.700, ClaErr:0.173, DisErr:0.664, RecLoss:32.076; E78: ClaCE:0.383, DisCE:3.097, TtlCE:-2.714, ClaErr:0.178, DisErr:0.656, RecLoss:31.642\n",
            "Test score: Class CE: 0.391, Disc CE: 3.176, Ttl CE: -2.785, Class Err: 0.170 Disc Err: 0.659\n",
            "starting Epoch 79\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E79: trained class 25, trained aud 0\n",
            "DI:  0.007464520633220673\n",
            "DP:  0.104639895\n",
            "E79: ClaCE:0.407, DisCE:3.107, TtlCE:-2.700, ClaErr:0.173, DisErr:0.664, RecLoss:32.071; E79: ClaCE:0.382, DisCE:3.096, TtlCE:-2.714, ClaErr:0.178, DisErr:0.656, RecLoss:31.639\n",
            "Test score: Class CE: 0.391, Disc CE: 3.176, Ttl CE: -2.785, Class Err: 0.171 Disc Err: 0.659\n",
            "starting Epoch 80\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E80: trained class 25, trained aud 0\n",
            "DI:  0.007464520633220673\n",
            "DP:  0.104639895\n",
            "E80: ClaCE:0.407, DisCE:3.107, TtlCE:-2.700, ClaErr:0.173, DisErr:0.664, RecLoss:32.066; E80: ClaCE:0.382, DisCE:3.096, TtlCE:-2.714, ClaErr:0.178, DisErr:0.656, RecLoss:31.635\n",
            "Test score: Class CE: 0.391, Disc CE: 3.176, Ttl CE: -2.785, Class Err: 0.170 Disc Err: 0.659\n",
            "starting Epoch 81\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E81: trained class 25, trained aud 0\n",
            "DI:  0.007464520633220673\n",
            "DP:  0.104639895\n",
            "E81: ClaCE:0.407, DisCE:3.106, TtlCE:-2.700, ClaErr:0.172, DisErr:0.663, RecLoss:32.061; E81: ClaCE:0.382, DisCE:3.096, TtlCE:-2.714, ClaErr:0.178, DisErr:0.656, RecLoss:31.631\n",
            "Test score: Class CE: 0.390, Disc CE: 3.175, Ttl CE: -2.785, Class Err: 0.169 Disc Err: 0.659\n",
            "starting Epoch 82\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E82: trained class 25, trained aud 0\n",
            "DI:  0.007464520633220673\n",
            "DP:  0.104639895\n",
            "E82: ClaCE:0.406, DisCE:3.106, TtlCE:-2.700, ClaErr:0.172, DisErr:0.663, RecLoss:32.055; E82: ClaCE:0.381, DisCE:3.096, TtlCE:-2.714, ClaErr:0.178, DisErr:0.656, RecLoss:31.626\n",
            "Test score: Class CE: 0.390, Disc CE: 3.175, Ttl CE: -2.785, Class Err: 0.168 Disc Err: 0.659\n",
            "starting Epoch 83\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E83: trained class 25, trained aud 0\n",
            "DI:  0.047071121633052826\n",
            "DP:  0.10049052\n",
            "E83: ClaCE:0.406, DisCE:3.106, TtlCE:-2.700, ClaErr:0.172, DisErr:0.663, RecLoss:32.048; E83: ClaCE:0.381, DisCE:3.095, TtlCE:-2.714, ClaErr:0.177, DisErr:0.656, RecLoss:31.621\n",
            "Test score: Class CE: 0.390, Disc CE: 3.175, Ttl CE: -2.785, Class Err: 0.168 Disc Err: 0.659\n",
            "starting Epoch 84\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E84: trained class 25, trained aud 0\n",
            "DI:  0.04403214901685715\n",
            "DP:  0.10428559\n",
            "E84: ClaCE:0.406, DisCE:3.106, TtlCE:-2.700, ClaErr:0.172, DisErr:0.663, RecLoss:32.041; E84: ClaCE:0.381, DisCE:3.095, TtlCE:-2.714, ClaErr:0.177, DisErr:0.656, RecLoss:31.615\n",
            "Test score: Class CE: 0.390, Disc CE: 3.175, Ttl CE: -2.785, Class Err: 0.167 Disc Err: 0.659\n",
            "starting Epoch 85\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E85: trained class 25, trained aud 0\n",
            "DI:  0.03946594148874283\n",
            "DP:  0.10013621\n",
            "E85: ClaCE:0.406, DisCE:3.106, TtlCE:-2.700, ClaErr:0.172, DisErr:0.663, RecLoss:32.034; E85: ClaCE:0.381, DisCE:3.095, TtlCE:-2.714, ClaErr:0.178, DisErr:0.656, RecLoss:31.609\n",
            "Test score: Class CE: 0.390, Disc CE: 3.174, Ttl CE: -2.785, Class Err: 0.166 Disc Err: 0.659\n",
            "starting Epoch 86\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E86: trained class 25, trained aud 0\n",
            "DI:  0.027770020067691803\n",
            "DP:  0.103931285\n",
            "E86: ClaCE:0.406, DisCE:3.105, TtlCE:-2.700, ClaErr:0.172, DisErr:0.663, RecLoss:32.027; E86: ClaCE:0.380, DisCE:3.095, TtlCE:-2.714, ClaErr:0.176, DisErr:0.656, RecLoss:31.603\n",
            "Test score: Class CE: 0.389, Disc CE: 3.174, Ttl CE: -2.785, Class Err: 0.166 Disc Err: 0.659\n",
            "starting Epoch 87\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E87: trained class 25, trained aud 0\n",
            "DI:  0.021922089159488678\n",
            "DP:  0.105828814\n",
            "E87: ClaCE:0.405, DisCE:3.105, TtlCE:-2.700, ClaErr:0.172, DisErr:0.663, RecLoss:32.019; E87: ClaCE:0.380, DisCE:3.094, TtlCE:-2.714, ClaErr:0.174, DisErr:0.656, RecLoss:31.596\n",
            "Test score: Class CE: 0.389, Disc CE: 3.174, Ttl CE: -2.785, Class Err: 0.166 Disc Err: 0.659\n",
            "starting Epoch 88\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E88: trained class 25, trained aud 0\n",
            "DI:  0.02473108470439911\n",
            "DP:  0.10772634\n",
            "E88: ClaCE:0.405, DisCE:3.105, TtlCE:-2.700, ClaErr:0.173, DisErr:0.663, RecLoss:32.010; E88: ClaCE:0.380, DisCE:3.094, TtlCE:-2.714, ClaErr:0.176, DisErr:0.656, RecLoss:31.589\n",
            "Test score: Class CE: 0.389, Disc CE: 3.174, Ttl CE: -2.785, Class Err: 0.167 Disc Err: 0.659\n",
            "starting Epoch 89\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E89: trained class 25, trained aud 0\n",
            "DI:  0.018883123993873596\n",
            "DP:  0.10962387\n",
            "E89: ClaCE:0.405, DisCE:3.105, TtlCE:-2.700, ClaErr:0.173, DisErr:0.663, RecLoss:32.002; E89: ClaCE:0.380, DisCE:3.094, TtlCE:-2.714, ClaErr:0.174, DisErr:0.656, RecLoss:31.582\n",
            "Test score: Class CE: 0.389, Disc CE: 3.173, Ttl CE: -2.785, Class Err: 0.167 Disc Err: 0.659\n",
            "starting Epoch 90\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E90: trained class 25, trained aud 0\n",
            "DI:  0.013035163283348083\n",
            "DP:  0.111521415\n",
            "E90: ClaCE:0.405, DisCE:3.104, TtlCE:-2.700, ClaErr:0.174, DisErr:0.663, RecLoss:31.993; E90: ClaCE:0.380, DisCE:3.094, TtlCE:-2.714, ClaErr:0.173, DisErr:0.656, RecLoss:31.575\n",
            "Test score: Class CE: 0.389, Disc CE: 3.173, Ttl CE: -2.785, Class Err: 0.168 Disc Err: 0.659\n",
            "starting Epoch 91\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E91: trained class 25, trained aud 0\n",
            "DI:  0.013035163283348083\n",
            "DP:  0.111521415\n",
            "E91: ClaCE:0.405, DisCE:3.104, TtlCE:-2.700, ClaErr:0.173, DisErr:0.663, RecLoss:31.984; E91: ClaCE:0.379, DisCE:3.094, TtlCE:-2.715, ClaErr:0.173, DisErr:0.656, RecLoss:31.567\n",
            "Test score: Class CE: 0.388, Disc CE: 3.173, Ttl CE: -2.785, Class Err: 0.168 Disc Err: 0.659\n",
            "starting Epoch 92\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E92: trained class 25, trained aud 0\n",
            "DI:  0.013035163283348083\n",
            "DP:  0.111521415\n",
            "E92: ClaCE:0.404, DisCE:3.104, TtlCE:-2.700, ClaErr:0.173, DisErr:0.663, RecLoss:31.975; E92: ClaCE:0.379, DisCE:3.094, TtlCE:-2.715, ClaErr:0.173, DisErr:0.656, RecLoss:31.559\n",
            "Test score: Class CE: 0.388, Disc CE: 3.173, Ttl CE: -2.785, Class Err: 0.168 Disc Err: 0.659\n",
            "starting Epoch 93\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E93: trained class 25, trained aud 0\n",
            "DI:  0.009845390915870667\n",
            "DP:  0.11531647\n",
            "E93: ClaCE:0.404, DisCE:3.104, TtlCE:-2.700, ClaErr:0.172, DisErr:0.663, RecLoss:31.965; E93: ClaCE:0.379, DisCE:3.093, TtlCE:-2.715, ClaErr:0.171, DisErr:0.656, RecLoss:31.551\n",
            "Test score: Class CE: 0.388, Disc CE: 3.173, Ttl CE: -2.785, Class Err: 0.168 Disc Err: 0.659\n",
            "starting Epoch 94\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E94: trained class 25, trained aud 0\n",
            "DI:  0.009845390915870667\n",
            "DP:  0.11531647\n",
            "E94: ClaCE:0.404, DisCE:3.104, TtlCE:-2.700, ClaErr:0.172, DisErr:0.663, RecLoss:31.955; E94: ClaCE:0.379, DisCE:3.093, TtlCE:-2.715, ClaErr:0.171, DisErr:0.656, RecLoss:31.542\n",
            "Test score: Class CE: 0.388, Disc CE: 3.172, Ttl CE: -2.785, Class Err: 0.168 Disc Err: 0.659\n",
            "starting Epoch 95\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E95: trained class 25, trained aud 0\n",
            "DI:  0.01569335162639618\n",
            "DP:  0.11721402\n",
            "E95: ClaCE:0.404, DisCE:3.104, TtlCE:-2.700, ClaErr:0.172, DisErr:0.663, RecLoss:31.945; E95: ClaCE:0.378, DisCE:3.093, TtlCE:-2.715, ClaErr:0.169, DisErr:0.656, RecLoss:31.534\n",
            "Test score: Class CE: 0.388, Disc CE: 3.173, Ttl CE: -2.785, Class Err: 0.169 Disc Err: 0.659\n",
            "starting Epoch 96\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E96: trained class 25, trained aud 0\n",
            "DI:  0.01569335162639618\n",
            "DP:  0.11721402\n",
            "E96: ClaCE:0.404, DisCE:3.103, TtlCE:-2.700, ClaErr:0.172, DisErr:0.663, RecLoss:31.935; E96: ClaCE:0.378, DisCE:3.093, TtlCE:-2.715, ClaErr:0.169, DisErr:0.656, RecLoss:31.525\n",
            "Test score: Class CE: 0.388, Disc CE: 3.172, Ttl CE: -2.785, Class Err: 0.168 Disc Err: 0.659\n",
            "starting Epoch 97\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E97: trained class 25, trained aud 0\n",
            "DI:  0.01569335162639618\n",
            "DP:  0.11721402\n",
            "E97: ClaCE:0.404, DisCE:3.103, TtlCE:-2.700, ClaErr:0.172, DisErr:0.663, RecLoss:31.925; E97: ClaCE:0.378, DisCE:3.093, TtlCE:-2.715, ClaErr:0.169, DisErr:0.656, RecLoss:31.516\n",
            "Test score: Class CE: 0.387, Disc CE: 3.172, Ttl CE: -2.785, Class Err: 0.168 Disc Err: 0.659\n",
            "starting Epoch 98\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E98: trained class 25, trained aud 0\n",
            "DI:  0.01569335162639618\n",
            "DP:  0.11721402\n",
            "E98: ClaCE:0.403, DisCE:3.103, TtlCE:-2.700, ClaErr:0.172, DisErr:0.663, RecLoss:31.914; E98: ClaCE:0.378, DisCE:3.093, TtlCE:-2.715, ClaErr:0.169, DisErr:0.656, RecLoss:31.506\n",
            "Test score: Class CE: 0.387, Disc CE: 3.172, Ttl CE: -2.785, Class Err: 0.168 Disc Err: 0.659\n",
            "starting Epoch 99\n",
            "Class DP last epoch: 100000.000; Disc DP Bound last epoch: 100000.000\n",
            "E99: trained class 25, trained aud 0\n",
            "DI:  0.01569335162639618\n",
            "DP:  0.11721402\n",
            "E99: ClaCE:0.403, DisCE:3.103, TtlCE:-2.700, ClaErr:0.171, DisErr:0.663, RecLoss:31.904; E99: ClaCE:0.378, DisCE:3.092, TtlCE:-2.715, ClaErr:0.169, DisErr:0.656, RecLoss:31.497\n",
            "Test score: Class CE: 0.387, Disc CE: 3.172, Ttl CE: -2.785, Class Err: 0.168 Disc Err: 0.659\n",
            "Finished training: min validation loss was 0.378 in epoch 99\n",
            "(1664, 1)\n",
            "(1664, 4)\n",
            "(1664, 1)\n",
            "(1664, 1)\n",
            "(1664, 1)\n",
            "Test score: Class CE: 0.387, Disc CE: 3.172, Ttl CE: -2.785, Class Err: 0.168 Disc Err: 0.659\n",
            "Error Rate: 0.168,  DI: 0.049, di_FP: 0.000, di_FN: 0.098\n",
            "Error Rate (A): 0.659\n",
            "\n",
            "Predicting Y\n",
            "A=?: Base PR: 0.248, Base NR: 0.752,  PR: 0.207, NR: 0.793, Err: 0.168, TPR: 0.578, FNR: 0.422, TNR: 0.915, FPR: 0.085\n",
            "A=1: Base PR: 0.119, Base NR: 0.881,  PR: 0.154, NR: 0.846, Err: 0.115, TPR: 0.661, FNR: 0.339, TNR: 0.915, FPR: 0.085\n",
            "A=0: Base PR: 0.306, Base NR: 0.694,  PR: 0.231, NR: 0.769, Err: 0.192, TPR: 0.563, FNR: 0.437, TNR: 0.916, FPR: 0.084\n",
            "ACor: Base PR: 0.195, Base NR: 0.805,  PR: 0.224, NR: 0.776, Err: 0.102, TPR: 0.811, FNR: 0.189, TNR: 0.919, FPR: 0.081\n",
            "AWro: Base PR: 0.275, Base NR: 0.725,  PR: 0.198, NR: 0.802, Err: 0.203, TPR: 0.492, FNR: 0.508, TNR: 0.913, FPR: 0.087\n",
            "\n",
            "Predicting A\n",
            "Y=?: Base-A1-rate: 0.313, Base-A0-rate: 0.687, Pred A1-rate: 0.947, Pred-A0-rate: 0.053, Err: 0.659, A1-Correct: 0.960, A1-Wrong: 0.040, A0-Correct: 0.059, A0-Wrong: 0.941\n",
            "Y=1: Base-A1-rate: 0.150, Base-A0-rate: 0.850, Pred A1-rate: 0.808, Pred-A0-rate: 0.192, Err: 0.731, A1-Correct: 0.758, A1-Wrong: 0.242, A0-Correct: 0.183, A0-Wrong: 0.817\n",
            "Y=0: Base-A1-rate: 0.367, Base-A0-rate: 0.633, Pred A1-rate: 0.992, Pred-A0-rate: 0.008, Err: 0.635, A1-Correct: 0.987, A1-Wrong: 0.013, A0-Correct: 0.005, A0-Wrong: 0.995\n",
            "YCor: Base-A1-rate: 0.333, Base-A0-rate: 0.667, Pred A1-rate: 0.944, Pred-A0-rate: 0.056, Err: 0.632, A1-Correct: 0.970, A1-Wrong: 0.030, A0-Correct: 0.068, A0-Wrong: 0.932\n",
            "YWro: Base-A1-rate: 0.214, Base-A0-rate: 0.786, Pred A1-rate: 0.957, Pred-A0-rate: 0.043, Err: 0.793, A1-Correct: 0.883, A1-Wrong: 0.117, A0-Correct: 0.023, A0-Wrong: 0.977\n",
            "Metrics saved to ./experiments/laftr_example/Adult_Exp_1/Exp_1_classification_transfer/test_metrics.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}